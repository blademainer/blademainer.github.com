<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Go解坑指南]]></title>
    <url>%2F2020%2F03%2F24%2Fgo-hit-the-bit%2F</url>
    <content type="text"><![CDATA[Go解坑指南日常踩坑：for-range这个循环会停止吗？123456func main() &#123; v := []int&#123;1, 2, 3&#125; for i, _ := range v &#123; v = append(v, i) &#125;&#125;先来看看for-range（two-value）底层实现12345678for_temp := v // for_temp是slice v的值拷贝len_temp := len(for_temp)for index_temp = 0; index_temp &lt; len_temp; index_temp++ &#123; value_temp = for_temp[index_temp] // value_temp也是元素的值拷贝 index = index_temp value = value_temp original body&#125;所以，上述的代码只会循环3次。再来个常见的，copys数组里是什么？[&quot;alice&quot;, &quot;bob&quot;]?1234567var dogs = []Dog&#123;&#125;dogs = append(dogs, Dog&#123;Name: "alice"&#125;, Dog&#123;Name: "bob"&#125;)var copys []*Dogfor _, d := range dogs &#123; copys = append(copys, &amp;d)&#125;答案[&quot;bob&quot;, &quot;bob&quot;]原因d是一个临时变量，在循环开始前声明，d会被重复利用。扩展：map的for-range是怎样的呢？为什么是无序的？1234567for mapiterinit(type, range, &amp;hiter); hiter.key != nil; mapiternext(&amp;hiter) &#123; index_temp = *hiter.key value_temp = *hiter.val index = index_temp value = value_temp original body&#125;答：mapiterinit被做了手脚，迭代器初始位置是随机的。但是，迭代出来的相对位置是固定的。深度解惑：defer优雅的释放资源或关闭与recover配合捕获程序异常结合闭包在return前做一些处理…函数f1与f2的返回值分别是什么？1234567891011121314func f1() (result int) &#123; defer func() &#123; result *= 7 &#125;() return 6&#125;func f2() (result int) &#123; tmp := 5 defer func() &#123; tmp = tmp + 5 &#125;() return tmp&#125;解答上述问题，需要了解这些知识defer原理Go闭包逃逸分析（escape analyze）defer原理defer的对象一定是函数调用defer的函数调用顺序LIFO(后进先出)defer与return的关系：return语句并不是原子指令，可以分解为以下3条语句：123返回值 = xxx调用defer函数空的returnGo闭包闭包是由函数及其相关引用环境组合而成的实体(即：闭包=函数+引用环境)123456func f(i int) func() int &#123; return func() int &#123; i++ return i &#125;&#125;1234c1 := f(0)c2 := f(0)c1() // reference to i, i = 0, return 1c2() // reference to another i, i = 0, return 1c1跟c2引用的是不同的环境，函数f每进入一次，就形成了一个新的环境。逃逸分析（escape analyze）12345678910func getCursor() *Cursor &#123; var c Cursor c.X = 500 noinline() return &amp;c&#125;~/closure ✗ go build -gcflags '-l -m'./main.go:12:9: func literal escapes to heap./main.go:19:6: moved to heap: c编译器会识别出变量需要在堆上分配。分享一段defer+闭包的实战代码12345678910111213var code stringdefer func() &#123; Publish(&amp;Message&#123;Request: "bind", Code: code&#125;)&#125;()// defer Publish(&amp;Message&#123;Request: "bind", Code: code&#125;)if condition0 &#123; code = DBError&#125;if condition1 &#123; code = InternalError&#125;code = OK错觉瞬间：Go到底有没引用？错觉1123456789func test(s []int) &#123; s[0] = 999&#125;func main() &#123; s := []int&#123;1, 2, 3&#125; test(s) fmt.Println(s)&#125;输出[999 2 3]，s被修改了！引用实锤！错觉2123456789func test(s []int) &#123; s = append(s, 999)&#125;func main() &#123; s := []int&#123;1, 2, 3&#125; test(s) fmt.Println(s)&#125;输出[1 2 3]，s没被修改，那究竟还是不是引用呢？其实，它只是一个指针12345type slice struct &#123; array unsafe.Pointer // 底层数组指针 len int cap int&#125;另外，Go的函数传参是值传递的。There is no pass-by-reference in Go— Dave Cheney]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s优雅关闭]]></title>
    <url>%2F2020%2F03%2F24%2Fgracefully-terminate%2F</url>
    <content type="text"><![CDATA[k8s如何保障服务健壮性 之 实现优雅关闭必要性没有graceful的关闭将导致请求连接异常；数据统计短时间内出现大量错误；实现两类信号SIGTERM：通知进程进行graceful信号；SIGKILL：硬终止信息；k8s中关闭pod时的流程https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods简而言之就是：先把pod标记为Terminating，此时service就会把该pod去除了；发送SIGTERM给pod内的所有容器；pod等待grace period结束或者pod提前处理完SIGTERM；pod发送SIGKILL给所有容器；确保信号正确传递到进程CMD的坑1CMD myapp相当于：1/bin/sh -c myapp以上的写法，容器接收到信号的进程是/bin/sh而不是myapp，这种写法会依赖于真正使用的shell，有些shell是不会传递信号给子进程的。比如基础镜像使用的是Alpine Linux下的基础shell就不会，但是bash就可以。使用EXEC的方式1CMD ["myapp"]上面的方式将会直接执行myapp，但是这种就不能把环境变量当做参数传递了？？？base方式1CMD ["/bin/bash", "-c", "myapp --arg=$ENV_VAR"]解决以上问题。k8s支持的几种方式1、yaml中修改1terminationGracePeriodSeconds: 602、delete命令1kubectl delete pod-name --grace-peroid=603、preStop Hook12345lifecycle: preStop: exec: # SIGTERM triggers a quick exit; gracefully terminate instead command: ["/usr/sbin/nginx","-s","quit"]4、validating webhook指到资源清理完成才返回true，否则返回false，这样pod就能保证清理完才推出，而不会因为grace peroid被强制清除。程序支持（最重要）思路首先关闭所有的监听，如果有使用服务注册之类的话，应该也把该服务从注册中去除；然后关闭所有的空闲连接；然后无限期等待连接处理完毕转为空闲，并关闭；如果提供了带有超时的Context，将在服务关闭前返回Context的超时错误；httpgo http的server.Shutdown如果你的服务是被其他服务调用的，那么关闭会比较复杂，约定调用者的keep-alive timeout 时间，默认为30秒服务关闭时，先设置 keep-alive 为 false服务关闭时，再等待30秒再调用server.Shutdowngrpc123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185package mainimport ( "context" "flag" "fmt" "log" "net" "net/http" _ "net/http/pprof" "os" "os/signal" "syscall" "time" "github.com/blademainer/commons/pkg/logger" "golang.org/x/sync/errgroup" "google.golang.org/grpc" pb "google.golang.org/grpc/examples/helloworld/helloworld" "google.golang.org/grpc/health" healthpb "google.golang.org/grpc/health/grpc_health_v1" "google.golang.org/grpc/keepalive")const serviceName = "myserviced"var ( version = "no version" debugPort = flag.Int("debugPort", 16161, "debug port") httpPort = flag.Int("httpPort", 8888, "http port") grpcPort = flag.Int("grpcPort", 9200, "grpc port") healthPort = flag.Int("healthPort", 6666, "grpc health port"))type server struct &#123;&#125;func (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) &#123; log.Printf("Received: %v", in.GetName()) return &amp;pb.HelloReply&#123;Message: "Hello " + in.GetName()&#125;, nil&#125;func main() &#123; flag.Parse() logger.Infof("Starting app, version: %v", version) // shutdown functions shutdownFunctions := make([]func(context.Context), 0) ctx, cancel := context.WithCancel(context.Background()) shutdownFunctions = append(shutdownFunctions, func(ctx context.Context) &#123; cancel() &#125;) defer cancel() interrupt := make(chan os.Signal, 1) signal.Notify(interrupt, os.Interrupt, syscall.SIGTERM) defer signal.Stop(interrupt) g, ctx := errgroup.WithContext(ctx) g.Go(func() error &#123; //profiles := pprof.Profiles() httpServer := &amp;http.Server&#123; Addr: fmt.Sprintf(":%d", *debugPort), ReadTimeout: 10 * time.Second, WriteTimeout: 10 * time.Second, Handler: nil, &#125; shutdownFunctions = append(shutdownFunctions, func(ctx context.Context) &#123; err := httpServer.Shutdown(ctx) if err != nil &#123; logger.Errorf("failed to shutdown pprof server! error: %v", err.Error()) &#125; &#125;) logger.Infof("pprof server serving at :%d", *debugPort) if err := httpServer.ListenAndServe(); err != nil &amp;&amp; err != http.ErrServerClosed &#123; logger.Errorf("failed to listen: %v", err.Error()) return err &#125; return nil &#125;) // web server metrics g.Go(func() error &#123; httpServer := &amp;http.Server&#123; Addr: fmt.Sprintf(":%d", *httpPort), ReadTimeout: 10 * time.Second, WriteTimeout: 10 * time.Second, &#125; shutdownFunctions = append(shutdownFunctions, func(ctx context.Context) &#123; err := httpServer.Shutdown(ctx) if err != nil &#123; logger.Errorf("failed to shutdown pprof server! error: %v", err.Error()) &#125; &#125;) logger.Infof("HTTP Metrics server serving at :%d", *httpPort) if err := httpServer.ListenAndServe(); err != http.ErrServerClosed &#123; return err &#125; return nil &#125;) // gRPC Health Server healthServer := health.NewServer() g.Go(func() error &#123; grpcHealthServer := grpc.NewServer() shutdownFunctions = append(shutdownFunctions, func(ctx context.Context) &#123; healthServer.SetServingStatus(fmt.Sprintf("grpc.health.v1.%s", serviceName), healthpb.HealthCheckResponse_NOT_SERVING) grpcHealthServer.GracefulStop() &#125;) healthpb.RegisterHealthServer(grpcHealthServer, healthServer) haddr := fmt.Sprintf(":%d", *healthPort) hln, err := net.Listen("tcp", haddr) if err != nil &#123; logger.Errorf("gRPC Health server: failed to listen, error: %v", err) os.Exit(2) &#125; logger.Infof("gRPC health server serving at %s", haddr) return grpcHealthServer.Serve(hln) &#125;) // gRPC server g.Go(func() error &#123; addr := fmt.Sprintf(":%d", *grpcPort) ln, err := net.Listen("tcp", addr) if err != nil &#123; logger.Errorf("gRPC server: failed to listen, error: %v", err) os.Exit(2) &#125; server := &amp;server&#123; &#125; grpcServer := grpc.NewServer( // MaxConnectionAge is just to avoid long connection, to facilitate load balancing // MaxConnectionAgeGrace will torn them, default to infinity grpc.KeepaliveParams(keepalive.ServerParameters&#123;MaxConnectionAge: 2 * time.Minute&#125;), ) pb.RegisterGreeterServer(grpcServer, server) shutdownFunctions = append(shutdownFunctions, func(ctx context.Context) &#123; healthServer.SetServingStatus(fmt.Sprintf("grpc.health.v1.%s", serviceName), healthpb.HealthCheckResponse_NOT_SERVING) grpcServer.GracefulStop() &#125;) logger.Infof("gRPC server serving at %s", addr) healthServer.SetServingStatus(fmt.Sprintf("grpc.health.v1.%s", serviceName), healthpb.HealthCheckResponse_SERVING) return grpcServer.Serve(ln) &#125;) select &#123; case &lt;-interrupt: break case &lt;-ctx.Done(): break &#125; logger.Warnf("received shutdown signal") // 创建一个新的Context，等待各个服务释放资源 timeout, cancelFunc := context.WithTimeout(context.Background(), 10*time.Second) defer cancelFunc() for _, shutdown := range shutdownFunctions &#123; shutdown(timeout) &#125; err := g.Wait() if err != nil &#123; logger.Errorf("server returning an error, error: %v", err) os.Exit(2) &#125;&#125;tcp1234567891011121314151617181920212223242526272829303132cmdAddr, _ := net.ResolveTCPAddr("tcp", n.cfg.Addr)lcmd, err := net.ListenTCP("tcp", cmdAddr)if err != nil &#123; log.Fatalln(err)&#125;defer lcmd.Close()quitChan := make(chan os.Signal, 1)signal.Notify(quitChan, os.Interrupt, os.Kill, syscall.SIGTERM)wg := sync.WaitGroup&#123;&#125;for &#123; select &#123; case &lt;-quitChan: lcmd.Close() wg.Wait() return default: &#125; lcmd.SetDeadline(time.Now().Add(1e9)) conn, err := lcmd.AcceptTCP() if opErr, ok := err.(*net.OpError); ok &amp;&amp; opErr.Timeout() &#123; continue &#125; if err != nil &#123; log.WithError(err).Errorln("Listener accept") continue &#125; wg.Add(1) go func()&#123; wg.Done() n.handleRequest(conn) &#125; &#125;]]></content>
      <categories>
        <category>cloud</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>k8s</tag>
        <tag>gracefully</tag>
        <tag>terminate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s入门指引]]></title>
    <url>%2F2020%2F03%2F24%2Fhow-to-k8s%2F</url>
    <content type="text"><![CDATA[帮助刚接触k8s的同学，快速和部署健壮的服务到k8s。如何开始(准备/前提)? 学前班前期准备前期知识: 容器(如: docker)?如何抢先体验K8S？ kubernetes.io/docs/tutorials可以尝试运行以下命令：123$ kubectl get pods$ kubectl get ns如何搭建自己的 MiniKube？TODO[color=red]如何管理配置？环境相关配置，放到configmap。多个deploy同时引用同个configmap即可。业务相关配置，管理端写etcd/redis，服务端监听etcd/redis的配置变更。ToC端应用，务必不要每次都读取etcd/redis的配置，而应当读取本地内存；只有在应用启动或接收到配置变更事件之后才缓存到本地内存。更新configmap之后，deploy需要重启才能使配置生效（除非程序自动读取配置进行刷新）如何处理日志？打日志运用日志日志在容器内，务必输出到终端(stdout)，然后使用统一机制，收集到ES(联系运维)；管理端的日志属于：运营、产品、商户、代理商的操作日志产生日志相对较少(一般而言);具备审计和安全日志的意义，备监管部门审查;须保留半年、一年(甚至更久);服务端的日志属于：用户端的访问日志，是应用内部状态的日志，产生日志较多，甚至海量;具备系统分析意义，用于：问题排查(性能、错误等)、生成统计/分析;仅保留一周；若因实际情况，需在容器内临时落盘，请映射日志路径到emptydir。如此，可避免程序受限与所在node主机存储限制。如何保障服务健壮性？给pod加上健康检查(liveness、readiness、startup)：liveness: 用于提供给k8s判断pod应当存活生命周期决策: 若不存活，将被集群移除，并(按照预设分数)重新拉起；readiness: 用于提供给k8s判断该pod是否就绪接入流量决策: 若未就绪，不会有流量到达该pod;(能有效防止，在上线/重启过程，发生504错误)startup: 用于启动时间较长的podliveness可以使用探测端口是否可达或者判断程序是否存活的形式。保证启动的过程中不会被k8s快速杀掉。例如：[ -z &quot;\ps -p 1 | awk ‘NR&gt;1 {print $0}’`“ ] &amp;&amp; exit 1`使用readiness来确保服务启动之后才导入流量。比如，curl业务接口，确保只有服务准备好之后才能有流量进来具体可选方法:httpGet.{path, port}: HTTP协议，提供待测路径、端口;tcpSocket.port: 提供，待检测端口exec.command: 提供可执行工具, 可发起自定义检测参考：liveness-readiness-startup-probes==Pod关闭==前保证服务流量正确处理：参考：实现优雅关闭 ToC业务务必加上hpa以应对流量爆发或运营活动。资源策略：cpu、内存的request/limit，记为[cpu_req, cpu_lim)、[mem_req, mem_lim)。参考: manage-compute-resources-containerHPA依赖服务的cpu和内存指标进行扩/缩容；配置request/limit有利于k8s的合理、高效调度；高IO型应用，应当把内存比cpu比例设置在4:1~8:1；计算密集型应用应当设置在2:1~4:1cpu=10 和 cpu=10m 的区别！内存：Mi、Gi例如，网关服务配置: cpu_req=1000m, cpu_lim=2000m。我们配置hpa: targetCPUUtilizationPercentage=60，那么当pod的cpu从1000m上升到1600m时，k8s会调大pod份数直到：每个pod的cpu&lt;=1600m或者该deploy的总副本数达到maxReplicasliveness如果使用的shell来判断进程是否存活，务必使用在command最开始加上’sh -c’。例如：command: [&quot;sh&quot;, &quot;-c&quot;, &quot;sleep 120; /app/main --stop&quot;]如何对集群进行调优？TODO列举：手段、涵盖事项(点到即止，若需展开，另起问题)[color=red]如何搭有状态集群？优先使用现有helm内提供的模板来搭建类似 etcd/zk/kafka 集群：阿里云集群可以使用自动创建云盘的策略有状态服务-动态云盘使用最佳实践]]></content>
      <categories>
        <category>cloud</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>k8s</tag>
        <tag>gracefully</tag>
        <tag>terminate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[open-source-projects]]></title>
    <url>%2F2019%2F06%2F27%2Fopen-source-projects%2F</url>
    <content type="text"><![CDATA[consistencyraftmiddlewaremqkafka go client: saramalanguagegogovalidatorgo-grpc-middlewaremicro-servicetracingskywalkingopentracing-gojaegercncfsecurityvaultacmego-oidcci/cdjenkins-xsso-operatordrone-vaultdronedraftgocdservlessspring-cloud-functionfissionservingkubelesskubernetescert-manageringress-nginxkanikocorednschartmuseumhelm-pushexternal-storageclient-gojava kubernetes-clientaitensorflow-jsDenseNetPaddlep2p/blockchaingo-libp2pgo-ethereumdbgh-ostgoleveldbgo-mysqlgormmysql-operatoruivue-element-admindesignplantumlplantumlgithub.com/plantumlAzure-PlantUMLMaterialDesignaws-icons-for-plantumlAWS-PlantUMLefficiencycodimdapipayalipay]]></content>
      <categories>
        <category>share</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>kubernetes</tag>
        <tag>opensource</tag>
        <tag>projects</tag>
        <tag>cncf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[In Search of an Understandable Consensus Algorithm (Extended Version)]]></title>
    <url>%2F2019%2F03%2F16%2Fin-search-of-an-understandable-consensus-algorithm%2F</url>
    <content type="text"><![CDATA[Raft一致性算法论文(in search of an understandable consensus algorithm)寻找一种易于理解的一致性算法（扩展版）摘要Raft 是一种为了管理复制日志的一致性算法。它提供了和 Paxos 算法相同的功能和性能，但是它的算法结构和 Paxos 不同，使得 Raft 算法更加容易理解并且更容易构建实际的系统。为了提升可理解性，Raft 将一致性算法分解成了几个关键模块，例如领导人选举、日志复制和安全性。同时它通过实施一个更强的一致性来减少需要考虑的状态的数量。从一个用户研究的结果可以证明，对于学生而言，Raft 算法比 Paxos 算法更加容易学习。Raft 算法还包括一个新的机制来允许集群成员的动态改变，它利用重叠的大多数来保证安全性。1 介绍一致性算法允许一组机器像一个整体一样工作，即使其中一些机器出现故障也能够继续工作下去。正因为如此，一致性算法在构建可信赖的大规模软件系统中扮演着重要的角色。在过去的 10 年里，Paxos 算法统治着一致性算法这一领域：绝大多数的实现都是基于 Paxos 或者受其影响。同时 Paxos 也成为了教学领域里讲解一致性问题时的示例。但是不幸的是，尽管有很多工作都在尝试降低它的复杂性，但是 Paxos 算法依然十分难以理解。并且，Paxos 自身的算法结构需要进行大幅的修改才能够应用到实际的系统中。这些都导致了工业界和学术界都对 Paxos 算法感到十分头疼。和 Paxos 算法进行过努力之后，我们开始寻找一种新的一致性算法，可以为构建实际的系统和教学提供更好的基础。我们的做法是不寻常的，我们的首要目标是可理解性：我们是否可以在实际系统中定义一个一致性算法，并且能够比 Paxos 算法以一种更加容易的方式来学习。此外，我们希望该算法方便系统构建者的直觉的发展。不仅一个算法能够工作很重要，而且能够显而易见的知道为什么能工作也很重要。Raft 一致性算法就是这些工作的结果。在设计 Raft 算法的时候，我们使用一些特别的技巧来提升它的可理解性，包括算法分解（Raft 主要被分成了领导人选举，日志复制和安全三个模块）和减少状态机的状态（相对于 Paxos，Raft 减少了非确定性和服务器互相处于非一致性的方式）。一份针对两所大学 43 个学生的研究表明 Raft 明显比 Paxos 算法更加容易理解。在这些学生同时学习了这两种算法之后，和 Paxos 比起来，其中 33 个学生能够回答有关于 Raft 的问题。Raft 算法在许多方面和现有的一致性算法都很相似（主要是 Oki 和 Liskov 的 Viewstamped Replication），但是它也有一些独特的特性：强领导者：和其他一致性算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导者发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。领导选举：Raft 算法使用一个随机计时器来选举领导者。这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。成员关系调整：Raft 使用一种共同一致的方法来处理集群成员变换的问题，在这种方法下，处于调整过程中的两种不同的配置集群中大多数机器会有重叠，这就使得集群在成员变换的时候依然可以继续工作。我们相信，Raft 算法不论出于教学目的还是作为实践项目的基础都是要比 Paxos 或者其他一致性算法要优异的。它比其他算法更加简单，更加容易理解；它的算法描述足以实现一个现实的系统；它有好多开源的实现并且在很多公司里使用；它的安全性已经被证明；它的效率和其他算法比起来也不相上下。接下来，这篇论文会介绍以下内容：复制状态机问题（第 2 节），讨论 Paxos 的优点和缺点（第 3 节），讨论我们为了可理解性而采取的方法（第 4 节），阐述 Raft 一致性算法（第 5-8 节），评价 Raft 算法（第 9 节），以及一些相关的工作（第 10 节）。2 复制状态机一致性算法是从复制状态机的背景下提出的（参考英文原文引用37）。在这种方法中，一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。复制状态机在分布式系统中被用于解决很多容错的问题。例如，大规模的系统中通常都有一个集群领导者，像 GFS、HDFS 和 RAMCloud，典型应用就是一个独立的的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。图 1 ：复制状态机的结构。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的。复制状态机通常都是基于复制日志实现的，如图 1。每一个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令，所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。保证复制日志相同就是一致性算法的工作了。在一台服务器上，一致性模块接收客户端发送来的指令然后增加到自己的日志中去。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，尽管有些服务器会宕机。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成一个高可靠的状态机。实际系统中使用的一致性算法通常含有以下特性：安全性保证（绝对不会返回一个错误的结果）：在非拜占庭错误情况下，包括网络延迟、分区、丢包、冗余和乱序等错误都可以保证正确。可用性：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信，就可以保证可用。因此，一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。他们当有稳定的存储的时候可以从状态中恢复回来并重新加入集群。不依赖时序来保证一致性：物理时钟错误或者极端的消息延迟只有在最坏情况下才会导致可用性问题。通常情况下，一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。3 Paxos 算法的问题在过去的 10 年里，Leslie Lamport 的 Paxos 算法几乎已经成为一致性的代名词：Paxos 是在课程教学中最经常使用的算法，同时也是大多数一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，比如单条的复制日志项。我们把这一子集叫做单决策 Paxos。然后通过组合多个 Paxos 协议的实例来促进一系列决策的达成。Paxos 保证安全性和活性，同时也支持集群成员关系的变更。Paxos 的正确性已经被证明，在通常情况下也很高效。不幸的是，Paxos 有两个明显的缺点。第一个缺点是 Paxos 算法特别的难以理解。完整的解释是出了名的不透明；通过极大的努力之后，也只有少数人成功理解了这个算法。因此，有了几次用更简单的术语来解释 Paxos 的尝试。尽管这些解释都只关注了单决策的子集问题，但依然很具有挑战性。在 2012 年 NSDI 的会议中的一次调查显示，很少有人对 Paxos 算法感到满意，甚至在经验老道的研究者中也是如此。我们自己也尝试去理解 Paxos；我们一直没能理解 Paxos 直到我们读了很多对 Paxos 的简化解释并且设计了我们自己的算法之后，这一过程花了近一年时间。我们假设 Paxos 的不透明性来自它选择单决策问题作为它的基础。单决策 Paxos 是晦涩微妙的，它被划分成了两种没有简单直观解释和无法独立理解的情景。因此，这导致了很难建立起直观的感受为什么单决策 Paxos 算法能够工作。构成多决策 Paxos 增加了很多错综复杂的规则。我们相信，在多决策上达成一致性的问题（一份日志而不是单一的日志记录）能够被分解成其他的方式并且更加直接和明显。Paxos算法的第二个问题就是它没有提供一个足够好的用来构建一个现实系统的基础。一个原因是还没有一种被广泛认同的多决策问题的算法。Lamport 的描述基本上都是关于单决策 Paxos 的；他简要描述了实施多决策 Paxos 的方法，但是缺乏很多细节。当然也有很多具体化 Paxos 的尝试，但是他们都互相不一样，和 Paxos 的概述也不同。例如 Chubby 这样的系统实现了一个类似于 Paxos 的算法，但是大多数的细节并没有被公开。而且，Paxos 算法的结构也不是十分易于构建实践的系统；单决策分解也会产生其他的结果。例如，独立的选择一组日志条目然后合并成一个序列化的日志并没有带来太多的好处，仅仅增加了不少复杂性。围绕着日志来设计一个系统是更加简单高效的；新日志条目以严格限制的顺序增添到日志中去。另一个问题是，Paxos 使用了一种对等的点对点的方式作为它的核心（尽管它最终提议了一种弱领导人的方法来优化性能）。在只有一个决策会被制定的简化世界中是很有意义的，但是很少有现实的系统使用这种方式。如果有一系列的决策需要被制定，首先选择一个领导人，然后让他去协调所有的决议，会更加简单快速。因此，实际的系统中很少有和 Paxos 相似的实践。每一种实现都是从 Paxos 开始研究，然后发现很多实现上的难题，再然后开发了一种和 Paxos 明显不一样的结构。这样是非常费时和容易出错的，并且理解 Paxos 的难度使得这个问题更加糟糕。Paxos 算法在理论上被证明是正确可行的，但是现实的系统和 Paxos 差别是如此的大，以至于这些证明没有什么太大的价值。下面来自 Chubby 实现非常典型：在Paxos算法描述和实现现实系统中间有着巨大的鸿沟。最终的系统建立在一种没有经过证明的算法之上。由于以上问题，我们认为 Paxos 算法既没有提供一个良好的基础给实践的系统，也没有给教学很好的帮助。基于一致性问题在大规模软件系统中的重要性，我们决定看看我们是否可以设计一个拥有更好特性的替代 Paxos 的一致性算法。Raft算法就是这次实验的结果。4 为了可理解性的设计设计 Raft 算法我们有几个初衷：它必须提供一个完整的实际的系统实现基础，这样才能大大减少开发者的工作；它必须在任何情况下都是安全的并且在大多数的情况下都是可用的；并且它的大部分操作必须是高效的。但是我们最重要也是最大的挑战是可理解性。它必须保证对于普遍的人群都可以十分容易的去理解。另外，它必须能够让人形成直观的认识，这样系统的构建者才能够在现实中进行必然的扩展。在设计 Raft 算法的时候，有很多的点需要我们在各种备选方案中进行选择。在这种情况下，我们评估备选方案基于可理解性原则：解释各个备选方案有多大的难度（例如，Raft 的状态空间有多复杂，是否有微妙的暗示）？对于一个读者而言，完全理解这个方案和暗示是否容易？我们意识到对这种可理解性分析上具有高度的主观性；尽管如此，我们使用了两种通常适用的技术来解决这个问题。第一个技术就是众所周知的问题分解：只要有可能，我们就将问题分解成几个相对独立的，可被解决的、可解释的和可理解的子问题。例如，Raft 算法被我们分成领导人选举，日志复制，安全性和角色改变几个部分。我们使用的第二个方法是通过减少状态的数量来简化需要考虑的状态空间，使得系统更加连贯并且在可能的时候消除不确定性。特别的，所有的日志是不允许有空洞的，并且 Raft 限制了日志之间变成不一致状态的可能。尽管在大多数情况下我们都试图去消除不确定性，但是也有一些情况下不确定性可以提升可理解性。尤其是，随机化方法增加了不确定性，但是他们有利于减少状态空间数量，通过处理所有可能选择时使用相似的方法。我们使用随机化去简化 Raft 中领导人选举算法。5 Raft 一致性算法Raft 是一种用来管理章节 2 中描述的复制日志的算法。图 2 为了参考之用，总结这个算法的简略版本，图 3 列举了这个算法的一些关键特性。图中的这些元素会在剩下的章节逐一介绍。Raft 通过选举一个高贵的领导人，然后给予他全部的管理复制日志的责任来实现一致性。领导人从客户端接收日志条目，把日志条目复制到其他服务器上，并且当保证安全性的时候告诉其他的服务器应用日志条目到他们的状态机中。拥有一个领导人大大简化了对复制日志的管理。例如，领导人可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都从领导人流向其他服务器。一个领导人可以宕机，可以和其他服务器失去连接，这时一个新的领导人会被选举出来。通过领导人的方式，Raft 将一致性问题分解成了三个相对独立的子问题，这些问题会在接下来的子章节中进行讨论：领导选举：一个新的领导人需要被选举出来，当现存的领导人宕机的时候（章节 5.2）日志复制：领导人必须从客户端接收日志然后复制到集群中的其他节点，并且强制要求其他节点的日志保持和自己相同。安全性：在 Raft 中安全性的关键是在图 3 中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。章节 5.4 阐述了 Raft 算法是如何保证这个特性的；这个解决方案涉及到一个额外的选举机制（5.2 节）上的限制。在展示一致性算法之后，这一章节会讨论可用性的一些问题和计时在系统的作用。状态：状态所有服务器上持久存在的currentTerm服务器最后一次知道的任期号（初始化为 0，持续递增）votedFor在当前获得选票的候选人的 Idlog[]日志条目集；每一个条目包含一个用户状态机执行的指令，和收到时的任期号状态所有服务器上经常变的commitIndex已知的最大的已经被提交的日志条目的索引值lastApplied最后被应用到状态机的日志条目索引值（初始化为 0，持续递增）状态在领导人里经常改变的 （选举后重新初始化）nextIndex[]对于每一个服务器，需要发送给他的下一个日志条目的索引值（初始化为领导人最后索引值加一）matchIndex[]对于每一个服务器，已经复制给他的日志的最高索引值附加日志 RPC：由领导人负责调用来复制日志指令；也会用作heartbeat参数解释term领导人的任期号leaderId领导人的 Id，以便于跟随者重定向请求prevLogIndex新的日志条目紧随之前的索引值prevLogTermprevLogIndex 条目的任期号entries[]准备存储的日志条目（表示心跳时为空；一次性发送多个是为了提高效率）leaderCommit领导人已经提交的日志的索引值返回值解释term当前的任期号，用于领导人去更新自己success跟随者包含了匹配上 prevLogIndex 和 prevLogTerm 的日志时为真接收者实现：如果 term &lt; currentTerm 就返回 false （5.1 节）如果日志在 prevLogIndex 位置处的日志条目的任期号和 prevLogTerm 不匹配，则返回 false （5.3 节）如果已经存在的日志条目和新的产生冲突（索引值相同但是任期号不同），删除这一条和之后所有的 （5.3 节）附加日志中尚未存在的任何新条目如果 leaderCommit &gt; commitIndex，令 commitIndex 等于 leaderCommit 和 新日志条目索引值中较小的一个请求投票 RPC：由候选人负责调用用来征集选票（5.2 节）参数解释term候选人的任期号candidateId请求选票的候选人的 IdlastLogIndex候选人的最后日志条目的索引值lastLogTerm候选人最后日志条目的任期号返回值解释term当前任期号，以便于候选人去更新自己的任期号voteGranted候选人赢得了此张选票时为真接收者实现：如果term &lt; currentTerm返回 false （5.2 节）如果 votedFor 为空或者为 candidateId，并且候选人的日志至少和自己一样新，那么就投票给他（5.2 节，5.4 节）所有服务器需遵守的规则：所有服务器：如果commitIndex &gt; lastApplied，那么就 lastApplied 加一，并把log[lastApplied]应用到状态机中（5.3 节）如果接收到的 RPC 请求或响应中，任期号T &gt; currentTerm，那么就令 currentTerm 等于 T，并切换状态为跟随者（5.1 节）跟随者（5.2 节）：响应来自候选人和领导者的请求如果在超过选举超时时间的情况之前都没有收到领导人的心跳，或者是候选人请求投票的，就自己变成候选人候选人（5.2 节）：在转变成候选人后就立即开始选举过程自增当前的任期号（currentTerm）给自己投票重置选举超时计时器发送请求投票的 RPC 给其他所有服务器如果接收到大多数服务器的选票，那么就变成领导人如果接收到来自新的领导人的附加日志 RPC，转变成跟随者如果选举过程超时，再次发起一轮选举领导人：一旦成为领导人：发送空的附加日志 RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送，以阻止跟随者超时（5.2 节）如果接收到来自客户端的请求：附加条目到本地日志中，在条目被应用到状态机后响应客户端（5.3 节）如果对于一个跟随者，最后日志条目的索引值大于等于 nextIndex，那么：发送从 nextIndex 开始的所有日志条目：如果成功：更新相应跟随者的 nextIndex 和 matchIndex如果因为日志不一致而失败，减少 nextIndex 重试如果存在一个满足N &gt; commitIndex的 N，并且大多数的matchIndex[i] ≥ N成立，并且log[N].term == currentTerm成立，那么令 commitIndex 等于这个 N （5.3 和 5.4 节）图 2：一个关于 Raft 一致性算法的浓缩总结（不包括成员变换和日志压缩）。特性解释选举安全特性对于一个给定的任期号，最多只会有一个领导人被选举出来（5.2 节）领导人只附加原则领导人绝对不会删除或者覆盖自己的日志，只会增加（5.3 节）日志匹配原则如果两个日志在相同的索引位置的日志条目的任期号相同，那么我们就认为这个日志从头到这个索引位置之间全部完全相同（5.3 节）领导人完全特性如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中（5.4 节）状态机安全特性如果一个领导人已经在给定的索引值位置的日志条目应用到状态机中，那么其他任何的服务器在这个索引位置不会提交一个不同的日志（5.4.3 节）图 3：Raft 在任何时候都保证以上的各个特性。5.1 Raft 基础一个 Raft 集群包含若干个服务器节点；通常是 5 个，这允许整个系统容忍 2 个节点的失效。在任何时刻，每一个服务器节点都处于这三个状态之一：领导人、跟随者或者候选人。在通常情况下，系统中只有一个领导人并且其他的节点全部都是跟随者。跟随者都是被动的：他们不会发送任何请求，只是简单的响应来自领导者或者候选人的请求。领导人处理所有的客户端请求（如果一个客户端和跟随者联系，那么跟随者会把请求重定向给领导人）。第三种状态，候选人，是用来在 5.2 节描述的选举新领导人时使用。图 4 展示了这些状态和他们之间的转换关系；这些转换关系会在接下来进行讨论。图 4：服务器状态。跟随者只响应来自其他服务器的请求。如果跟随者接收不到消息，那么他就会变成候选人并发起一次选举。获得集群中大多数选票的候选人将成为领导者。在一个任期内，领导人一直都会是领导人直到自己宕机了。图 5：时间被划分成一个个的任期，每个任期开始都是一次选举。在选举成功后，领导人会管理整个集群直到任期结束。有时候选举会失败，那么这个任期就会没有领导人而结束。任期之间的切换可以在不同的时间不同的服务器上观察到。Raft 把时间分割成任意长度的任期，如图 5。任期用连续的整数标记。每一段任期从一次选举开始，就像章节 5.2 描述的一样，一个或者多个候选人尝试成为领导者。如果一个候选人赢得选举，然后他就在接下来的任期内充当领导人的职责。在某些情况下，一次选举过程会造成选票的瓜分。在这种情况下，这一任期会以没有领导人结束；一个新的任期（和一次新的选举）会很快重新开始。Raft 保证了在一个给定的任期内，最多只有一个领导者。不同的服务器节点可能多次观察到任期之间的转换，但在某些情况下，一个节点也可能观察不到任何一次选举或者整个任期全程。任期在 Raft 算法中充当逻辑时钟的作用，这会允许服务器节点查明一些过期的信息比如陈旧的领导者。每一个节点存储一个当前任期号，这一编号在整个时期内单调的增长。当服务器之间通信的时候会交换当前任期号；如果一个服务器的当前任期号比其他人小，那么他会更新自己的编号到较大的编号值。如果一个候选人或者领导者发现自己的任期号过期了，那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。Raft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs。请求投票（RequestVote） RPCs 由候选人在选举期间发起（章节 5.2），然后附加条目（AppendEntries）RPCs 由领导人发起，用来复制日志和提供一种心跳机制（章节 5.3）。第 7 节为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时，会进行重试， 并且他们能够并行的发起 RPCs 来获得最佳的性能。5.2 领导人选举Raft 使用一种心跳机制来触发领导人选举。当服务器程序启动时，他们都是跟随者身份。一个服务器节点继续保持着跟随者状态只要他从领导人或者候选者处接收到有效的 RPCs。领导者周期性的向所有跟随者发送心跳包（即不包含日志项内容的附加日志项 RPCs）来维持自己的权威。如果一个跟随者在一段时间里没有接收到任何消息，也就是选举超时，那么他就会认为系统中没有可用的领导者,并且发起选举以选出新的领导者。要开始一次选举过程，跟随者先要增加自己的当前任期号并且转换到候选人状态。然后他会并行的向集群中的其他服务器节点发送请求投票的 RPCs 来给自己投票。候选人会继续保持着当前状态直到以下三件事情之一发生：(a) 他自己赢得了这次的选举，(b) 其他的服务器成为领导者，(c) 一段时间之后没有任何一个获胜的人。这些结果会分别的在下面的段落里进行讨论。当一个候选人从整个集群的大多数服务器节点获得了针对同一个任期号的选票，那么他就赢得了这次选举并成为领导人。每一个服务器最多会对一个任期号投出一张选票，按照先来先服务的原则（注意：5.4 节在投票上增加了一点额外的限制）。要求大多数选票的规则确保了最多只会有一个候选人赢得此次选举（图 3 中的选举安全性）。一旦候选人赢得选举，他就立即成为领导人。然后他会向其他的服务器发送心跳消息来建立自己的权威并且阻止新的领导人的产生。在等待投票的时候，候选人可能会从其他的服务器接收到声明它是领导人的附加日志项 RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号，那么候选人会承认领导人合法并回到跟随者状态。 如果此次 RPC 中的任期号比自己小，那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。第三种可能的结果是候选人既没有赢得选举也没有输：如果有多个跟随者同时成为候选人，那么选票可能会被瓜分以至于没有候选人可以赢得大多数人的支持。当这种情况发生的时候，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时；然后他赢得选举并在其他服务器超时之前发送心跳包。同样的机制被用在选票瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。9.3 节展示了这种方案能够快速的选出一个领导人。领导人选举这个例子，体现了可理解性原则是如何指导我们进行方案设计的。起初我们计划使用一种排名系统：每一个候选人都被赋予一个唯一的排名，供候选人之间竞争时进行选择。如果一个候选人发现另一个候选人拥有更高的排名，那么他就会回到跟随者状态，这样高排名的候选人能够更加容易的赢得下一次选举。但是我们发现这种方法在可用性方面会有一点问题（如果高排名的服务器宕机了，那么低排名的服务器可能会超时并再次进入候选人状态。而且如果这个行为发生得足够快，则可能会导致整个选举过程都被重置掉）。我们针对算法进行了多次调整，但是每次调整之后都会有新的问题。最终我们认为随机重试的方法是更加明显和易于理解的。5.3 日志复制一旦一个领导人被选举出来，他就开始为客户端提供服务。客户端的每一个请求都包含一条被复制状态机执行的指令。领导人把这条指令作为一条新的日志条目附加到日志中去，然后并行的发起附加条目 RPCs 给其他的服务器，让他们复制这条日志条目。当这条日志条目被安全的复制（下面会介绍），领导人会应用这条日志条目到它的状态机中然后把执行的结果返回给客户端。如果跟随者崩溃或者运行缓慢，再或者网络丢包，领导人会不断的重复尝试附加日志条目 RPCs （尽管已经回复了客户端）直到所有的跟随者都最终存储了所有的日志条目。图 6：日志由有序序号标记的条目组成。每个条目都包含创建时的任期号（图中框中的数字），和一个状态机需要执行的指令。一个条目当可以安全的被应用到状态机中去的时候，就认为是可以提交了。日志以图 6 展示的方式组织。每一个日志条目存储一条状态机指令和从领导人收到这条指令时的任期号。日志中的任期号用来检查是否出现不一致的情况，同时也用来保证图 3 中的某些性质。每一条日志条目同时也都有一个整数索引值来表明它在日志中的位置。领导人来决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为已提交。Raft 算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行。在领导人将创建的日志条目复制到大多数的服务器上的时候，日志条目就会被提交（例如在图 6 中的条目 7）。同时，领导人的日志中之前的所有日志条目也都会被提交，包括由其他领导人创建的条目。5.4 节会讨论某些当在领导人改变之后应用这条规则的隐晦内容，同时他也展示了这种提交的定义是安全的。领导人跟踪了最大的将会被提交的日志项的索引，并且索引值会被包含在未来的所有附加日志 RPCs （包括心跳包），这样其他的服务器才能最终知道领导人的提交位置。一旦跟随者知道一条日志条目已经被提交，那么他也会将这个日志条目应用到本地的状态机中（按照日志的顺序）。我们设计了 Raft 的日志机制来维护一个不同服务器的日志之间的高层次的一致性。这么做不仅简化了系统的行为也使得更加可预计，同时他也是安全性保证的一个重要组件。Raft 维护着以下的特性，这些同时也组成了图 3 中的日志匹配特性：如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也全部相同。第一个特性来自这样的一个事实，领导人最多在一个任期里在指定的一个日志索引位置创建一条日志条目，同时日志条目在日志中的位置也从来不会改变。第二个特性由附加日志 RPC 的一个简单的一致性检查所保证。在发送附加日志 RPC 的时候，领导人会把新的日志条目紧接着之前的条目的索引位置和任期号包含在里面。如果跟随者在它的日志中找不到包含相同索引位置和任期号的条目，那么他就会拒绝接收新的日志条目。一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性的，然后一致性检查保护了日志匹配特性当日志扩展的时候。因此，每当附加日志 RPC 返回成功时，领导人就知道跟随者的日志一定是和自己相同的了。在正常的操作中，领导人和跟随者的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。然而，领导人崩溃的情况会使得日志处于不一致的状态（老的领导人可能还没有完全复制所有的日志条目）。这种不一致问题会在领导人和跟随者的一系列崩溃下加剧。图 7 展示了跟随者的日志可能和新的领导人不同的方式。跟随者可能会丢失一些在新的领导人中有的日志条目，他也可能拥有一些领导人没有的日志条目，或者两者都发生。丢失或者多出日志条目可能会持续多个任期。图 7：当一个领导人成功当选时，跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。例如，场景 f 可能会这样发生，某服务器在任期 2 的时候是领导人，已附加了一些日志条目到自己的日志中，但在提交之前就崩溃了；很快这个机器就被重启了，在任期 3 重新被选为领导人，并且又增加了一些日志条目到自己的日志中；在任期 2 和任期 3 的日志被提交之前，这个服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态。在 Raft 算法中，领导人处理不一致是通过强制跟随者直接复制自己的日志来解决了。这意味着在跟随者中的冲突的日志条目会被领导人的日志覆盖。5.4 节会阐述如何通过增加一些限制来使得这样的操作是安全的。要使得跟随者的日志进入和自己一致的状态，领导人必须找到最后两者达成一致的地方，然后删除从那个点之后的所有日志条目，发送自己的日志给跟随者。所有的这些操作都在进行附加日志 RPCs 的一致性检查时完成。领导人针对每一个跟随者维护了一个 nextIndex，这表示下一个需要发送给跟随者的日志条目的索引地址。当一个领导人刚获得权力的时候，他初始化所有的 nextIndex 值为自己的最后一条日志的index加1（图 7 中的 11）。如果一个跟随者的日志和领导人不一致，那么在下一次的附加日志 RPC 时的一致性检查就会失败。在被跟随者拒绝之后，领导人就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导人和跟随者的日志达成一致。当这种情况发生，附加日志 RPC 就会成功，这时就会把跟随者冲突的日志条目全部删除并且加上领导人的日志。一旦附加日志 RPC 成功，那么跟随者的日志就会和领导人保持一致，并且在接下来的任期里一直继续保持。如果需要的话，算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化。例如，当附加日志 RPC 的请求被拒绝的时候，跟随者可以包含冲突的条目的任期号和自己存储的那个任期的最早的索引地址。借助这些信息，领导人可以减小 nextIndex 越过所有那个任期冲突的所有日志条目；这样就变成每个任期需要一次附加条目 RPC 而不是每个条目一次。在实践中，我们十分怀疑这种优化是否是必要的，因为失败是很少发生的并且也不大可能会有这么多不一致的日志。通过这种机制，领导人在获得权力的时候就不需要任何特殊的操作来恢复一致性。他只需要进行正常的操作，然后日志就能自动的在回复附加日志 RPC 的一致性检查失败的时候自动趋于一致。领导人从来不会覆盖或者删除自己的日志（图 3 的领导人只附加特性）。日志复制机制展示出了第 2 节中形容的一致性特性：Raft 能够接受，复制并应用新的日志条目只要大部分的机器是工作的；在通常的情况下，新的日志条目可以在一次 RPC 中被复制给集群中的大多数机器；并且单个的缓慢的跟随者不会影响整体的性能。5.4 安全性前面的章节里描述了 Raft 算法是如何选举和复制日志的。然而，到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令。例如，一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此，不同的状态机可能会执行不同的指令序列。这一节通过在领导选举的时候增加一些限制来完善 Raft 算法。这一限制保证了任何的领导人对于给定的任期号，都拥有了之前任期的所有被提交的日志条目（图 3 中的领导人完整特性）。增加这一选举时的限制，我们对于提交时的规则也更加清晰。最终，我们将展示对于领导人完整特性的简要证明，并且说明领导人是如何领导复制状态机的做出正确行为的。5.4.1 选举限制在任何基于领导人的一致性算法中，领导人都必须存储所有已经提交的日志条目。在某些一致性算法中，例如 Viewstamped Replication，某个节点即使是一开始并没有包含所有已经提交的日志条目，它也能被选为领导者。这些算法都包含一些额外的机制来识别丢失的日志条目并把他们传送给新的领导人，要么是在选举阶段要么在之后很快进行。不幸的是，这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法，它可以保证所有之前的任期号中已经提交的日志条目在选举的时候都会出现在新的领导人中，不需要传送这些日志条目给领导人。这意味着日志条目的传送是单向的，只从领导人传给跟随者，并且领导人从不会覆盖自身本地日志中已经存在的条目。Raft 使用投票的方式来阻止一个候选人赢得选举除非这个候选人包含了所有已经提交的日志条目。候选人为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。如果候选人的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。请求投票 RPC 实现了这样的限制： RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。Raft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。5.4.2 提交之前任期内的日志条目如同 5.3 节介绍的那样，领导人知道一条当前任期内的日志记录是可以被提交的，只要它被存储到了大多数的服务器上。如果一个领导人在提交日志条目之前崩溃了，未来后续的领导人会继续尝试复制这条日志记录。然而，一个领导人不能断定一个之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。图 8 展示了一种情况，一条已经被存储到大多数节点上的老日志条目，也依然有可能会被未来的领导人覆盖掉。图 8：如图的时间序列展示了为什么领导人无法决定对老任期号的日志条目进行提交。在 (a) 中，S1 是领导者，部分的复制了索引位置 2 的日志条目。在 (b) 中，S1 崩溃了，然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。然后到 (c)，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，但是还没有被提交。如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。反之，如果在崩溃之前，S1 把自己主导的新任期里产生的日志条目复制到了大多数机器上，就如 (e) 中那样，那么在后面任期里面这些新的日志条目就会被提交（因为S5 就不可能选举成功）。 这样在同一时刻就同时保证了，之前的所有老的日志条目就会被提交。为了消除图 8 里描述的情况，Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用一种更加保守的方法。当领导人复制之前任期里的日志时，Raft 会为所有日志保留原始的任期号, 这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。5.4.3 安全性论证在给定了完整的 Raft 算法之后，我们现在可以更加精确的讨论领导人完整性特性（这一讨论基于 9.2 节的安全性证明）。我们假设领导人完全性特性是不存在的，然后我们推出矛盾来。假设任期 T 的领导人（领导人 T）在任期内提交了一条日志条目，但是这条日志条目没有被存储到未来某个任期的领导人的日志中。设大于 T 的最小任期 U 的领导人 U 没有这条日志条目。图 9：如果 S1 （任期 T 的领导者）提交了一条新的日志在它的任期里，然后 S5 在之后的任期 U 里被选举为领导人，然后至少会有一个机器，如 S3，既拥有来自 S1 的日志，也给 S5 投票了。在领导人 U 选举的时候一定没有那条被提交的日志条目（领导人从不会删除或者覆盖任何条目）。领导人 T 复制这条日志条目给集群中的大多数节点，同时，领导人U 从集群中的大多数节点赢得了选票。因此，至少有一个节点（投票者、选民）同时接受了来自领导人T 的日志条目，并且给领导人U 投票了，如图 9。这个投票者是产生这个矛盾的关键。这个投票者必须在给领导人 U 投票之前先接受了从领导人 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导人 T 的附加日志请求（因为此时他的任期号会比 T 大）。投票者在给领导人 U 投票时依然保存有这条日志条目，因为任何中间的领导人都包含该日志条目（根据上述的假设），领导人从不会删除条目，并且跟随者只有在和领导人冲突的时候才会删除条目。投票者把自己选票投给领导人 U 时，领导人 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。首先，如果投票者和领导人 U 的最后一条日志的任期号相同，那么领导人 U 的日志至少和投票者一样长，所以领导人 U 的日志一定包含所有投票者的日志。这是另一处矛盾，因为投票者包含了那条已经被提交的日志条目，但是在上述的假设里，领导人 U 是不包含的。除此之外，领导人 U 的最后一条日志的任期号就必须比投票人大了。此外，他也比 T 大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导人 U 最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人 U 是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，领导人 U 一定也包含那条被提交的日志，这里产生矛盾。这里完成了矛盾。因此，所有比 T 大的领导人一定包含了所有来自 T 的已经被提交的日志。日志匹配原则保证了未来的领导人也同时会包含被间接提交的条目，例如图 8 (d) 中的索引 2。通过领导人完全特性，我们就能证明图 3 中的状态机安全特性，即如果服务器已经在某个给定的索引值应用了日志条目到自己的状态机里，那么其他的服务器不会应用一个不一样的日志到同一个索引值上。在一个服务器应用一条日志条目到他自己的状态机中时，他的日志必须和领导人的日志，在该条目和之前的条目上相同，并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性保证拥有更高任期号的领导人会存储相同的日志条目，所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此，状态机安全特性是成立的。最后，Raft 要求服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。5.5 跟随者和候选人崩溃到目前为止，我们都只关注了领导人崩溃的情况。跟随者和候选人崩溃后的处理方式比领导人要简单的多，并且他们的处理方式是相同的。如果跟随者或者候选人崩溃了，那么后续发送给他们的 RPCs 都会失败。Raft 中处理这种失败就是简单的通过无限的重试；如果崩溃的机器重启了，那么这些 RPC 就会完整的成功。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了，那么在他重新启动之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。5.6 时间和可用性Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换比服务器故障间隔时间长，候选人将没有足够长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举并维持一个稳定的领导人,只要系统满足下面的时间要求：广播时间（broadcastTime） &lt;&lt; 选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF）在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间就是在 5.2 节中介绍的选举的超时时间限制；然后平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统的运行中很少出现。广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。6 集群成员变化到目前为止，我们都假设集群的配置（加入到一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔是会改变集群的配置的，例如替换那些宕机的机器或者改变复制级别。尽管可以通过暂停整个集群，更新所有配置，然后重启整个集群的方式来实现，但是在更改的时候集群会不可用。另外，如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，我们决定自动化配置改变并且将其纳入到 Raft 一致性算法中来。为了让配置修改机制能够安全，那么在转换的过程中不能够存在任何时间点使得两个领导人同时被选举成功在同一个任期里。不幸的是，任何服务器直接从旧的配置直接转换到新的配置的方案都是不安全的。一次性自动的转换所有服务器是不可能的，所以在转换期间整个集群存在划分成两个独立的大多数群体的可能性（见图 10）。图 10：直接从一种配置转到新的配置是十分不安全的，因为各个机器可能在任何的时候进行转换。在这个例子中，集群配额从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。为了保证安全性，配置更改必须使用两阶段方法。目前有很多种两阶段的实现。例如，有些系统在第一阶段停掉旧的配置所以集群就不能处理客户端请求；然后在第二阶段在启用新的配置。在 Raft 中，集群先切换到一个过渡的配置，我们称之为共同一致；一旦共同一致已经被提交了，那么系统就切换到新的配置上。共同一致是老配置和新配置的结合：日志条目被复制给集群中新、老配置的所有服务器。新、旧配置的服务器都可以成为领导人。达成一致（针对选举和提交）需要分别在两种配置上获得大多数的支持。共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程人依然响应客户端的请求。集群配置在复制日志中以特殊的日志条目来存储和通信；图 11 展示了配置转换的过程。当一个领导人接收到一个改变配置从 C-old 到 C-new 的请求，他会为了共同一致存储配置（图中的 C-old,new），以前面描述的日志条目和副本的形式。一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定（服务器总是使用最新的配置，无论他是否已经被提交）。这意味着领导人要使用 C-old,new 的规则来决定日志条目 C-old,new 什么时候需要被提交。如果领导人崩溃了，被选出来的新领导人可能是使用 C-old 配置也可能是 C-old,new 配置，这取决于赢得选举的候选人是否已经接收到了 C-old,new 配置。在任何情况下， C-new 配置在这一时期都不会单方面的做出决定。一旦 C-old,new 被提交，那么无论是 C-old 还是 C-new，在没有经过他人批准的情况下都不可能做出决定，并且领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。这个时候，领导人创建一条关于 C-new 配置的日志条目并复制给集群就是安全的了。再者，每个服务器在见到新的配置的时候就会立即生效。当新的配置在 C-new 的规则下被提交，旧的配置就变得无关紧要，同时不使用新的配置的服务器就可以被关闭了。如图 11，C-old 和 C-new 没有任何机会同时做出单方面的决定；这保证了安全性。图 11：一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的条目，实线表示最后被提交的日志条目。领导人首先创建了 C-old,new 的配置条目在自己的日志中，并提交到 C-old,new 中（C-old 的大多数和 C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。这样就不存在 C-new 和 C-old 可以同时做出决定的时间点。在关于重新配置还有三个问题需要提出。第一个问题是，新的服务器可能初始化没有存储任何的日志条目。当这些服务器以这种状态加入到集群中，那么他们需要一段时间来更新追赶，这时还不能提交新的日志条目。为了避免这种可用性的间隔时间，Raft 在配置更新的时候使用了一种额外的阶段，在这个阶段，新的服务器以没有投票权身份加入到集群中来（领导人复制日志给他们，但是不考虑他们是大多数）。一旦新的服务器追赶上了集群中的其他机器，重新配置可以像上面描述的一样处理。第二个问题是，集群的领导人可能不是新配置的一员。在这种情况下，领导人就会在提交了 C-new 日志之后退位（回到跟随者状态）。这意味着有这样的一段时间，领导人管理着集群，但是不包括他自己；他复制日志但是不把他自己算作是大多数之一。当 C-new 被提交时，会发生领导人过渡，因为这时是最早新的配置可以独立工作的时间点（将总是能够在 C-new 配置下选出新的领导人）。在此之前，可能只能从 C-old 中选出领导人。第三个问题是，移除不在 C-new 中的服务器可能会扰乱集群。这些服务器将不会再接收到心跳，所以当选举超时，他们就会进行新的选举过程。他们会发送拥有新的任期号的请求投票 RPCs，这样会导致当前的领导人回退成跟随者状态。新的领导人最终会被选出来，但是被移除的服务器将会再次超时，然后这个过程会再次重复，导致整体可用性大幅降低。为了避免这个问题，当服务器确认当前领导人存在时，服务器会忽略请求投票 RPCs。特别的，当服务器在当前最小选举超时时间内收到一个请求投票 RPC，他不会更新当前的任期号或者投出选票。这不会影响正常的选举，每个服务器在开始一次选举之前，至少等待一个最小选举超时时间。然而，这有利于避免被移除的服务器扰乱：如果领导人能够发送心跳给集群，那么他就不会被更大的任期号废黜。7 日志压缩Raft 的日志在正常操作中不断的增长，但是在实际的系统中，日志不能无限制的增长。随着日志不断增长，他会占用越来越多的空间，花费越来越多的时间来重置。如果没有一定的机制去清除日志里积累的陈旧的信息，那么会带来可用性问题。快照是最简单的压缩方法。在快照系统中，整个系统的状态都以快照的形式写入到稳定的持久化存储中，然后到那个时间点之前的日志全部丢弃。快照技术被使用在 Chubby 和 ZooKeeper 中，接下来的章节会介绍 Raft 中的快照技术。增量压缩的方法，例如日志清理或者日志结构合并树，都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，他们先选择一个已经积累的大量已经被删除或者被覆盖对象的区域，然后重写那个区域还活跃的对象，之后释放那个区域。和简单操作整个数据集合的快照相比，需要增加复杂的机制来实现。状态机可以实现 LSM tree 使用和快照相同的接口，但是日志清除方法就需要修改 Raft 了。图 12：一个服务器用新的快照替换了从 1 到 5 的条目，快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。图 12 展示了 Raft 中快照的基础思想。每个服务器独立的创建快照，只包括已经被提交的日志。主要的工作包括将状态机的状态写入到快照中。Raft 也包含一些少量的元数据到快照中：最后被包含索引指的是被快照取代的最后的条目在日志中的索引值（状态机最后应用的日志），最后被包含的任期指的是该条目的任期号。保留这些数据是为了支持快照后紧接着的第一个条目的附加日志请求时的一致性检查，因为这个条目需要前一日志条目的索引值和任期号。为了支持集群成员更新（第 6 节），快照中也将最后的一次配置作为最后一个条目存下来。一旦服务器完成一次快照，他就可以删除最后索引位置之前的所有日志和快照了。尽管通常服务器都是独立的创建快照，但是领导人必须偶尔的发送快照给一些落后的跟随者。这通常发生在当领导人已经丢弃了下一条需要发送给跟随者的日志条目的时候。幸运的是这种情况不是常规操作：一个与领导人保持同步的跟随者通常都会有这个条目。然而一个运行非常缓慢的跟随者或者新加入集群的服务器（第 6 节）将不会有这个条目。这时让这个跟随者更新到最新的状态的方式就是通过网络把快照发送给他们。安装快照 RPC：由领导人调用以将快照的分块发送给跟随者。领导者总是按顺序发送分块。参数解释term领导人的任期号leaderId领导人的 Id，以便于跟随者重定向请求lastIncludedIndex快照中包含的最后日志条目的索引值lastIncludedTerm快照中包含的最后日志条目的任期号offset分块在快照中的字节偏移量data[]原始数据done如果这是最后一个分块则为 true结果解释term当前任期号（currentTerm），便于领导人更新自己接收者实现：如果term &lt; currentTerm就立即回复如果是第一个分块（offset 为 0）就创建一个新的快照在指定偏移量写入数据如果 done 是 false，则继续等待更多的数据保存快照文件，丢弃具有较小索引的任何现有或部分快照如果现存的日志条目与快照中最后包含的日志条目具有相同的索引值和任期号，则保留其后的日志条目并进行回复丢弃整个日志使用快照重置状态机（并加载快照的集群配置）图 13：一个关于安装快照的简要概述。为了便于传输，快照都是被分成分块的；每个分块都给了跟随者生命的迹象，所以跟随者可以重置选举超时计时器。在这种情况下领导人使用一种叫做安装快照的新的 RPC 来发送快照给太落后的跟随者；见图 13。当跟随者通过这种 RPC 接收到快照时，他必须自己决定对于已经存在的日志该如何处理。通常快照会包含没有在接收者日志中存在的信息。在这种情况下，跟随者丢弃其整个日志；它全部被快照取代，并且可能包含与快照冲突的未提交条目。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误），那么被快照包含的条目将会被全部删除，但是快照后面的条目仍然有效，必须保留。这种快照的方式背离了 Raft 的强领导人原则，因为跟随者可以在不知道领导人情况下创建快照。但是我们认为这种背离是值得的。领导人的存在，是为了解决在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成，这时不存在冲突了，所以没有领导人也是可以的。数据依然是从领导人传给跟随者，只是跟随者可以重新组织他们的数据了。我们考虑过一种替代的基于领导人的快照方案，即只有领导人创建快照，然后发送给所有的跟随者。但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照处理的时间。每个跟随者都已经拥有了所有产生快照需要的信息，而且很显然，自己从本地的状态中创建快照比通过网络接收别人发来的要经济。第二，领导人的实现会更加复杂。例如，领导人需要发送快照的同时并行的将新的日志条目发送给跟随者，这样才不会阻塞新的客户端请求。还有两个问题影响了快照的性能。首先，服务器必须决定什么时候应该创建快照。如果快照创建的过于频繁，那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低，他就要承受耗尽存储容量的风险，同时也增加了从日志重建的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置的显著大于期望的快照的大小，那么快照对磁盘压力的影响就会很小了。第二个影响性能的问题就是写入快照需要花费显著的一段时间，并且我们还不希望影响到正常操作。解决方案是通过写时复制的技术，这样新的更新就可以被接收而不影响到快照。例如，具有函数式数据结构的状态机天然支持这样的功能。另外，操作系统的写时复制技术的支持（如 Linux 上的 fork）可以被用来创建完整的状态机的内存快照（我们的实现就是这样的）。8 客户端交互这一节将介绍客户端是如何和 Raft 进行交互的，包括客户端如何发现领导人和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在，并且 Raft 的解决方案和其他的也差不多。Raft 中的客户端发送所有请求给领导人。当客户端启动的时候，他会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是领导人，那么那个服务器会拒绝客户端的请求并且提供他最近接收到的领导人的信息（附加条目请求包含了领导人的网络地址）。如果领导人已经崩溃了，那么客户端的请求就会超时；客户端之后会再次重试随机挑选服务器的过程。我们 Raft 的目标是要实现线性化语义（每一次操作立即执行，只执行一次，在他调用和收到回复之间）。但是，如上述，Raft 是可以执行同一条命令多次的：例如，如果领导人在提交了这条日志之后，但是在响应客户端之前崩溃了，那么客户端会和新的领导人重试这条指令，导致这条命令就被再次执行了。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令，它的序列号已经被执行了，那么就立即返回结果，而不重新执行指令。只读的操作可以直接处理而不需要记录日志。但是，在不增加任何限制的情况下，这么做可能会冒着返回脏数据的风险，因为领导人响应客户端请求时可能已经被新的领导人作废了，但是他还不知道。线性化的读操作必须不能返回脏数据，Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。首先，领导人必须有关于被提交日志的最新信息。领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目，但是在他任期开始的时候，他可能不知道那些是已经被提交的。为了知道这些信息，他需要在他的任期里提交一条日志条目。Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。第二，领导人在处理只读的请求之前必须检查自己是否已经被废黜了（他自己的信息已经变脏了如果一个更新的领导人被选举出来）。Raft 中通过让领导人在响应只读请求之前，先和集群中的大多数节点交换一次心跳信息来处理这个问题。可选的，领导人可以依赖心跳机制来实现一种租约的机制，但是这种方法依赖时间来保证安全性（假设时间误差是有界的）。9 算法实现和评估我们已经为 RAMCloud 实现了 Raft 算法作为存储配置信息的复制状态机的一部分，并且帮助 RAMCloud 协调故障转移。这个 Raft 实现包含大约 2000 行 C++ 代码，其中不包括测试、注释和空行。这些代码是开源的。同时也有大约 25 个其他独立的第三方的基于这篇论文草稿的开源实现，针对不同的开发场景。同时，很多公司已经部署了基于 Raft 的系统。这一节会从三个方面来评估 Raft 算法：可理解性、正确性和性能。9.1 可理解性为了和 Paxos 比较 Raft 算法的可理解能力，我们针对高层次的本科生和研究生，在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程上，进行了一次学习的实验。我们分别拍了针对 Raft 和 Paxos 的视频课程，并准备了相应的小测验。Raft 的视频讲课覆盖了这篇论文的所有内容除了日志压缩；Paxos 讲课包含了足够的资料来创建一个等价的复制状态机，包括单决策 Paxos，多决策 Paxos，重新配置和一些实际系统需要的性能优化（例如领导人选举）。小测验测试一些对算法的基本理解和解释一些边角的示例。每个学生都是看完第一个视频，回答相应的测试，再看第二个视频，回答相应的测试。大约有一半的学生先进行 Paxos 部分，然后另一半先进行 Raft 部分，这是为了说明两者从第一部分的算法学习中获得的表现和经验的差异。我们计算参加人员的每一个小测验的得分来看参与者是否在 Raft 算法上更加容易理解。我们尽可能的使得 Paxos 和 Raft 的比较更加公平。这个实验偏爱 Paxos 表现在两个方面：43 个参加者中有 15 个人在之前有一些 Paxos 的经验，并且 Paxos 的视频要长 14%。如表格 1 总结的那样，我们采取了一些措施来减轻这种潜在的偏见。我们所有的材料都可供审查。关心缓和偏见采取的手段可供查看的材料相同的讲课质量两者使用同一个讲师。Paxos 使用的是现在很多大学里经常使用的。Paxos 会长 14%。视频相同的测验难度问题以难度分组，在两个测验里成对出现。小测验公平评分使用评价量规。随机顺序打分，两个测验交替进行。评价量规（rubric）表 1：考虑到可能会存在的偏见，对于每种情况的解决方法，和相应的材料。参加者平均在 Raft 的测验中比 Paxos 高 4.9 分（总分 60，那么 Raft 的平均得分是 25.7，而 Paxos 是 20.8）；图 14 展示了每个参与者的得分。配置t-检验（又称student‘s t-test）表明，在 95% 的可信度下，真实的 Raft 分数分布至少比 Paxos 高 2.5 分。图 14：一个散点图表示了 43 个学生在 Paxos 和 Raft 的小测验中的成绩。在对角线之上的点表示在 Raft 获得了更高分数的学生。我们也建立了一个线性回归模型来预测一个新的学生的测验成绩，基于以下三个因素：他们使用的是哪个小测验，之前对 Paxos 的经验，和学习算法的顺序。模型预测，对小测验的选择会产生 12.5 分的差别。这显著的高于之前的 4.9 分，因为很多学生在之前都已经有了对于 Paxos 的经验，这相当明显的帮助 Paxos，对 Raft 就没什么太大影响了。但是奇怪的是，模型预测对于先进行 Paxos 小测验的人而言，Raft的得分低了6.3分; 虽然我们不知道为什么，这似乎在统计上是有意义的。我们同时也在测验之后调查了参与者，他们认为哪个算法更加容易实现和解释；这个的结果在图 15 上。压倒性的结果表明 Raft 算法更加容易实现和解释（41 人中的 33个）。但是，这种自己报告的结果不如参与者的成绩更加可信，并且参与者可能因为我们的 Raft 更加易于理解的假说而产生偏见。图 15：通过一个 5 分制的问题，参与者（左边）被问哪个算法他们觉得在一个高效正确的系统里更容易实现，右边被问哪个更容易向学生解释。关于 Raft 用户学习有一个更加详细的讨论。9.2 正确性在第 5 节，我们已经制定了正式的规范，和对一致性机制的安全性证明。这个正式规范使用 TLA+ 规范语言使图 2 中总结的信息非常清晰。它长约400行，并作为证明的主题。同时对于任何想实现 Raft 的人也是十分有用的。我们通过 TLA 证明系统非常机械的证明了日志完全特性。然而，这个证明依赖的约束前提还没有被机械证明（例如，我们还没有证明规范的类型安全）。而且，我们已经写了一个非正式的证明关于状态机安全性是完备的，并且是相当清晰的（大约 3500 个词）。9.3 性能Raft 和其他一致性算法例如 Paxos 有着差不多的性能。在性能方面，最重要的关注点是，当领导人被选举成功时，什么时候复制新的日志条目。Raft 通过很少数量的消息包（一轮从领导人到集群大多数机器的消息）就达成了这个目的。同时，进一步提升 Raft 的性能也是可行的。例如，很容易通过支持批量操作和管道操作来提高吞吐量和降低延迟。对于其他一致性算法已经提出过很多性能优化方案；其中有很多也可以应用到 Raft 中来，但是我们暂时把这个问题放到未来的工作中去。我们使用我们自己的 Raft 实现来衡量 Raft 领导人选举的性能并且回答两个问题。首先，领导人选举的过程收敛是否快速？第二，在领导人宕机之后，最小的系统宕机时间是多久？图 16：发现并替换一个已经崩溃的领导人的时间。上面的图考察了在选举超时时间上的随机化程度，下面的图考察了最小选举超时时间。每条线代表了 1000 次实验（除了 150-150 毫秒只试了 100 次），和相应的确定的选举超时时间。例如，150-155 毫秒意思是，选举超时时间从这个区间范围内随机选择并确定下来。这个实验在一个拥有 5 个节点的集群上进行，其广播时延大约是 15 毫秒。对于 9 个节点的集群，结果也差不多。为了衡量领导人选举，我们反复的使一个拥有五个节点的服务器集群的领导人宕机，并计算需要多久才能发现领导人已经宕机并选出一个新的领导人（见图 16）。为了构建一个最坏的场景，在每一的尝试里，服务器都有不同长度的日志，意味着有些候选人是没有成为领导人的资格的。另外，为了促成选票瓜分的情况，我们的测试脚本在终止领导人之前同步的发送了一次心跳广播（这大约和领导人在崩溃前复制一个新的日志给其他机器很像）。领导人均匀的随机的在心跳间隔里宕机，也就是最小选举超时时间的一半。因此，最小宕机时间大约就是最小选举超时时间的一半。图 16 中上面的图表明，只需要在选举超时时间上使用很少的随机化就可以大大避免选票被瓜分的情况。在没有随机化的情况下，在我们的测试里，选举过程往往都需要花费超过 10 秒钟由于太多的选票瓜分的情况。仅仅增加 5 毫秒的随机化时间，就大大的改善了选举过程，现在平均的宕机时间只有 287 毫秒。增加更多的随机化时间可以大大改善最坏情况：通过增加 50 毫秒的随机化时间，最坏的完成情况（1000 次尝试）只要 513 毫秒。图 16 中下面的图显示，通过减少选举超时时间可以减少系统的宕机时间。在选举超时时间为 12-24 毫秒的情况下，只需要平均 35 毫秒就可以选举出新的领导人（最长的一次花费了 152 毫秒）。然而，进一步降低选举超时时间的话就会违反 Raft 的时间不等式需求：在选举新领导人之前，领导人就很难发送完心跳包。这会导致没有意义的领导人改变并降低了系统整体的可用性。我们建议使用更为保守的选举超时时间，比如 150-300 毫秒；这样的时间不大可能导致没有意义的领导人改变，而且依然提供不错的可用性。10 相关工作已经有很多关于一致性算法的工作被发表出来，其中很多都可以归到下面的类别中：Lamport 关于 Paxos 的原始描述，和尝试描述的更清晰。关于 Paxos 的更详尽的描述，补充遗漏的细节并修改算法，使得可以提供更加容易的实现基础。实现一致性算法的系统，例如 Chubby，ZooKeeper 和 Spanner。对于 Chubby 和 Spanner 的算法并没有公开发表其技术细节，尽管他们都声称是基于 Paxos 的。ZooKeeper 的算法细节已经发表，但是和 Paxos 着实有着很大的差别。Paxos 可以应用的性能优化。Oki 和 Liskov 的 Viewstamped Replication（VR），一种和 Paxos 差不多的替代算法。原始的算法描述和分布式传输协议耦合在了一起，但是核心的一致性算法在最近的更新里被分离了出来。VR 使用了一种基于领导人的方法，和 Raft 有很多相似之处。Raft 和 Paxos 最大的不同之处就在于 Raft 的强领导特性：Raft 使用领导人选举作为一致性协议里必不可少的部分，并且将尽可能多的功能集中到了领导人身上。这样就可以使得算法更加容易理解。例如，在 Paxos 中，领导人选举和基本的一致性协议是正交的：领导人选举仅仅是性能优化的手段，而且不是一致性所必须要求的。但是，这样就增加了多余的机制：Paxos 同时包含了针对基本一致性要求的两阶段提交协议和针对领导人选举的独立的机制。相比较而言，Raft 就直接将领导人选举纳入到一致性算法中，并作为两阶段一致性的第一步。这样就减少了很多机制。像 Raft 一样，VR 和 ZooKeeper 也是基于领导人的，因此他们也拥有一些 Raft 的优点。但是，Raft 比 VR 和 ZooKeeper 拥有更少的机制因为 Raft 尽可能的减少了非领导人的功能。例如，Raft 中日志条目都遵循着从领导人发送给其他人这一个方向：附加条目 RPC 是向外发送的。在 VR 中，日志条目的流动是双向的（领导人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。根据 ZooKeeper 公开的资料看，它的日志条目也是双向传输的，但是它的实现更像 Raft。和上述我们提及的其他基于一致性的日志复制算法中，Raft 的消息类型更少。例如，我们数了一下 VR 和 ZooKeeper 使用的用来基本一致性需要和成员改变的消息数（排除了日志压缩和客户端交互，因为这些都比较独立且和算法关系不大）。VR 和 ZooKeeper 都分别定义了 10 中不同的消息类型，相对的，Raft 只有 4 中消息类型（两种 RPC 请求和对应的响应）。Raft 的消息都稍微比其他算法的要信息量大，但是都很简单。另外，VR 和 ZooKeeper 都在领导人改变时传输了整个日志；所以为了能够实践中使用，额外的消息类型就很必要了。Raft 的强领导人模型简化了整个算法，但是同时也排斥了一些性能优化的方法。例如，平等主义 Paxos （EPaxos）在某些没有领导人的情况下可以达到很高的性能。平等主义 Paxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令，除非其他指令同时被提出了。然而，如果指令都是并发的被提出，并且互相之间不通信沟通，那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可以提交指令，所以 EPaxos 在服务器之间的负载均衡做的很好，并且很容易在 WAN 网络环境下获得很低的延迟。但是，他在 Paxos 上增加了非常明显的复杂性。一些集群成员变换的方法已经被提出或者在其他的工作中被实现，包括 Lamport 的原始的讨论，VR 和 SMART。我们选择使用共同一致的方法因为他对一致性协议的其他部分影响很小，这样我们只需要很少的一些机制就可以实现成员变换。Lamport 的基于 α 的方法之所以没有被 Raft 选择是因为它假设在没有领导人的情况下也可以达到一致性。和 VR 和 SMART 相比较，Raft 的重新配置算法可以在不限制正常请求处理的情况下进行；相比较的，VR 需要停止所有的处理过程，SMART 引入了一个和 α 类似的方法，限制了请求处理的数量。Raft 的方法同时也需要更少的额外机制来实现，和 VR、SMART 比较而言。11 结论算法的设计通常会把正确性，效率或者简洁作为主要的目标。尽管这些都是很有意义的目标，但是我们相信，可理解性也是一样的重要。在开发者把算法应用到实际的系统中之前，这些目标没有一个会被实现，这些都会必然的偏离发表时的形式。除非开发人员对这个算法有着很深的理解并且有着直观的感觉，否则将会对他们而言很难在实现的时候保持原有期望的特性。在这篇论文中，我们尝试解决分布式一致性问题，但是一个广为接受但是十分令人费解的算法 Paxos 已经困扰了无数学生和开发者很多年了。我们创造了一种新的算法 Raft，显而易见的比 Paxos 要容易理解。我们同时也相信，Raft 也可以为实际的实现提供坚实的基础。把可理解性作为设计的目标改变了我们设计 Raft 的方式；随着设计的进展，我们发现自己重复使用了一些技术，比如分解问题和简化状态空间。这些技术不仅提升了 Raft 的可理解性，同时也使我们坚信其正确性。12 感谢这项研究必须感谢以下人员的支持：Ali Ghodsi，David Mazie`res，和伯克利 CS 294-91 课程、斯坦福 CS 240 课程的学生。Scott Klemmer 帮我们设计了用户调查，Nelson Ray 建议我们进行统计学的分析。在用户调查时使用的关于 Paxos 的幻灯片很大一部分是从 Lorenzo Alvisi 的幻灯片上借鉴过来的。特别的，非常感谢 DavidMazieres 和 Ezra Hoch，他们找到了 Raft 中一些难以发现的漏洞。许多人提供了关于这篇论文十分有用的反馈和用户调查材料，包括 Ed Bugnion，Michael Chan，Hugues Evrard，Daniel Giffin，Arjun Gopalan，Jon Howell，Vimalkumar Jeyakumar，Ankita Kejriwal，Aleksandar Kracun，Amit Levy，Joel Martin，Satoshi Matsushita，Oleg Pesok，David Ramos，Robbert van Renesse，Mendel Rosenblum，Nicolas Schiper，Deian Stefan，Andrew Stone，Ryan Stutsman，David Terei，Stephen Yang，Matei Zaharia 以及 24 位匿名的会议审查人员（可能有重复），并且特别感谢我们的领导人 Eddie Kohler。Werner Vogels 发了一条早期草稿链接的推特，给 Raft 带来了极大的关注。我们的工作由 Gigascale 系统研究中心和 Multiscale 系统研究中心给予支持，这两个研究中心由关注中心研究程序资金支持，一个是半导体研究公司的程序，由 STARnet 支持，一个半导体研究公司的程序由 MARCO 和 DARPA 支持，在国家科学基金会的 0963859 号批准，并且获得了来自 Facebook，Google，Mellanox，NEC，NetApp，SAP 和 Samsung 的支持。Diego Ongaro 由 Junglee 公司，斯坦福的毕业团体支持。参考raft paperraft.github.ioetcd raft]]></content>
      <categories>
        <category>algorithm</category>
        <category>distributed</category>
      </categories>
      <tags>
        <tag>raft</tag>
        <tag>consensus</tag>
        <tag>algorithm</tag>
        <tag>translate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[星客云盘]]></title>
    <url>%2F2019%2F03%2F11%2Fx-sync%2F</url>
    <content type="text"><![CDATA[SyncCloud 星客云盘打造一个开源、简单、分布式的云盘。]]></content>
      <categories>
        <category>cloud</category>
      </categories>
      <tags>
        <tag>sync</tag>
        <tag>pan</tag>
        <tag>edge</tag>
        <tag>devices</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维笔记：一次kubernetes内偶发超时的问题]]></title>
    <url>%2F2019%2F03%2F09%2Fkubernetes-go-timeout%2F</url>
    <content type="text"><![CDATA[一次kubernetes内的pod（go程序）连接外网域名偶发超时问题。问题最近线上有个机房突然出现超时预警，原因是零星的报微信、支付宝连接超时。刚开始以为是机房的网络故障，就没有深究。过去一天，现象还是继续。没办法，大概率不是机房问题，需要深入解决。修复先看了下日志，是go报net/http: request canceled (Client.Timeout exceeded while awaiting headers)&quot;错误，证明是连接阶段超时，而不是等待响应阶段超时，错误应当是在建立连接阶段时出现的。于是，可以缩小问题范围：可能是解析dns超时可能是连接某个ip超时直接修改go代码来看定位是哪个问题比较麻烦，于是直接使用curl来确认问题。首先创建一个带curl功能的busybox pod:1kubectl run --rm -it busybox --image sequenceiq/busybox --restart=Never然后执行curl调试:12345678910111213tee curl-format.txt &lt;&lt;- 'EOF'time_namelookup: %&#123;time_namelookup&#125;\ntime_connect: %&#123;time_connect&#125;\ntime_appconnect: %&#123;time_appconnect&#125;\ntime_redirect: %&#123;time_redirect&#125;\ntime_pretransfer: %&#123;time_pretransfer&#125;\ntime_starttransfer: %&#123;time_starttransfer&#125;\n----------\ntime_total: %&#123;time_total&#125;\n\nEOFDOMAIN="api2.mch.weixin.qq.com"curl -w '@curl-format.txt' $DOMAIN发现curl也会偶尔连接超时于是可以确认是dns解析的问题，给应用pod配上host之后问题也得到改善。我们的k8s集群是使用的kube-dns作为dns解析，于是看下CoreDNS的日志：1kubectl -n kube-system logs -l k8s-app=kube-dns存在有比较多的异常，都是连接相同一个IP：xx.xx.xx.6连接超时咨询过运维之后发现，该IP：xx.xx.xx.6是一个错误配置，该IP实际是不存在的。修复待运维修改CoreDNS的configmap之后，问题得到解决。总结go是没有dns缓存的，比较依赖主机/环境的dns解析缓存。如果要做到可靠的话建议自己加缓存。kubernetes基础组件的配置变更要细致，且做好监控。参考go-http-issuesproposal-go-dns-cachego-dns-cachego-dnscacheCoreDNSkube-dnsuse-curl-to-analyze-request]]></content>
      <categories>
        <category>kubernetes</category>
        <category>运维笔记</category>
      </categories>
      <tags>
        <tag>curl</tag>
        <tag>timeout</tag>
        <tag>go</tag>
        <tag>kubernetes</tag>
        <tag>dns</tag>
        <tag>kube-dns</tag>
        <tag>coredns</tag>
        <tag>httpclient</tag>
        <tag>awaiting headers</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[curl网络耗时调试]]></title>
    <url>%2F2019%2F03%2F05%2Fcurl-debug%2F</url>
    <content type="text"><![CDATA[线上环境各种蛋疼问题，通过日志无法定位出是我们服务器的问题（服务器问题又包括：dns服务器问题、内部网络问题等）还是第三方服务器的问题，通过一个简单的脚本即可直观调试出来。12345678910111213tee curl-format.txt &lt;&lt;- 'EOF'time_namelookup: %&#123;time_namelookup&#125;\ntime_connect: %&#123;time_connect&#125;\ntime_appconnect: %&#123;time_appconnect&#125;\ntime_redirect: %&#123;time_redirect&#125;\ntime_pretransfer: %&#123;time_pretransfer&#125;\ntime_starttransfer: %&#123;time_starttransfer&#125;\n----------\ntime_total: %&#123;time_total&#125;\n\nEOFDOMAIN="api2.mch.weixin.qq.com"curl -w '@curl-format.txt' $DOMAIN释义：time_namelookup：DNS 域名解析的时候，就是把 https://zhihu.com 转换成 ip 地址的过程time_connect：TCP 连接建立的时间，就是三次握手的时间time_appconnect：SSL/SSH 等上层协议建立连接的时间，比如 connect/handshake 的时间time_redirect：从开始到最后一个请求事务的时间time_pretransfer：从请求开始到响应开始传输的时间time_starttransfer：从请求开始到第一个字节将要传输的时间time_total：这次请求花费的全部时间]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>curl</tag>
        <tag>debug</tag>
        <tag>timeout</tag>
        <tag>pay</tag>
        <tag>time</tag>
        <tag>-w</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Einstein's Mass-Energy Equation]]></title>
    <url>%2F2019%2F02%2F23%2Feinstein-mass-energy-equation%2F</url>
    <content type="text"><![CDATA[$$e=mc^2$$TheoremThe energy imparted to a body to cause that body to move causes the body to increase in mass by a value 𝑀 as given by the equation:$$E = M c^2$$where 𝑐 is the speed of light.ProofFrom Einstein’s Law of Motion, we have:$$\mathbf F = \dfrac {m_0 \mathbf a} {\left({1 - \dfrac {v^2} {c^2}}\right)^{\tfrac 3 2}}$$where:𝐅 is the force on the body𝐚 is the acceleration induced on the body𝑣 is the magnitude of the velocity of the body𝑐 is the speed of light𝑚0 is the rest mass of the body.Without loss of generality, assume that the body is starting from rest at the origin of a cartesian coordinate plane.Assume the force 𝐅 on the body is in the positive direction along the x-axis.To simplify the work, we consider the acceleration as a scalar quantity and write it 𝑎.Thus, from the Chain Rule:$$a = \dfrac{\mathrm d v}{\mathrm d t} = \dfrac{\mathrm d v}{\mathrm d x} \dfrac {\mathrm d x}{\mathrm d t} = v \dfrac {\mathrm d v} {\mathrm d x}$$Then from the definition of energy:$$\displaystyle E = \int_0^x F \mathrm d x$$which leads us to:$$E = m_0 \int_0^x \frac a {\left({1 - v^2 / c^2}\right)^{\tfrac 3 2} } \ \mathrm d x $$$$ = m_0 \int_0^v \frac v {\left({1 - v^2 / c^2}\right)^{\tfrac 3 2} } \ \mathrm d v $$$$ = m_0 \left({- \frac {c^2} 2}\right) \int_0^v \left({1 - \frac {v^2} {c^2} }\right)^{-\tfrac 3 2} \left({- \frac {2 v \ \mathrm d v} {c^2} }\right) $$$$ = \left[{m_0 c^2 \left({1 - \frac {v^2} {c^2} }\right)^{- \tfrac 1 2} }\right]_0^v $$$$ = m_0 c^2 \left({\frac 1 {\sqrt {1 - \frac {v^2} {c^2} } } - 1}\right) $$$$ = c^2 \left({\frac {m_0} {\sqrt {1 - \frac {v^2} {c^2} } } - m_0}\right) $$$$ = c^2 \left({m - m_0}\right) $$$$ = M c^2$$Einstein’s Mass-Velocity EquationSources1972: George F. Simmons: Differential Equations … (previous) … (next): Miscellaneous Problems for Chapter 2: Problem 321992: George F. Simmons: Calculus Gems … (previous) … (next): Chapter B.7: A Simple Approach to $E = M c^2$]]></content>
      <categories>
        <category>physical</category>
      </categories>
      <tags>
        <tag>physical</tag>
        <tag>einstein</tag>
        <tag>energy equation</tag>
        <tag>energy</tag>
        <tag>equation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Einstein's Law of Motion]]></title>
    <url>%2F2019%2F02%2F23%2Feinstein-law-of-motion%2F</url>
    <content type="text"><![CDATA[$$\mathbf F = \dfrac {m_0 \mathbf a} {\left({1 - \dfrac{v^2}{c^2}}\right)^{\tfrac 3 2}}$$Physical LawThe force and acceleration on a body of constant rest mass are related by the equation:$$\mathbf F = \dfrac {m_0 \mathbf a} {\left({1 - \dfrac{v^2}{c^2}}\right)^{\tfrac 3 2}}$$where:𝐅 is the force on the body𝐚 is the acceleration induced on the body𝑣 is the magnitude of the velocity of the body𝑐 is the speed of light𝑚0 is the rest mass of the body.ProofInto Newton’s Second Law of Motion:$$\mathbf F = \dfrac {\mathrm d}{\mathrm d t} \left({m \mathbf v}\right)$$we substitute Einstein’s Mass-Velocity Equation:$$m = \dfrac {m_0} {\sqrt {1 - \dfrac {v^2} {c^2}}}$$where:𝑣 is the magnitude of the velocity of the body𝑐 is the speed of light in vacuum𝑚0 is the rest mass of the body.The value 𝑚 is known as the relativistic mass of the body.The factor $\dfrac 1 {\sqrt{1 - \dfrac {v^2} {c^2} } }$ is known as the Lorentz Factor.to obtain:$$\mathbf F = \dfrac {\mathrm d} {\mathrm d t} \left({\dfrac {m_0 \mathbf v}{\sqrt{1 - \dfrac {v^2}{c^2}}}}\right)$$Then we perform the differentiation with respect to time:$$\frac{\mathrm d}{\mathrm d t} \left({\frac {\mathbf v}{\sqrt{1 - \dfrac {v^2}{c^2} } } }\right)$$ $$ = \frac{\mathrm d}{\mathrm d v} \left({\frac {\mathbf v}{\sqrt{1 - \dfrac {v^2}{c^2} } } }\right) \frac{\mathrm d v}{\mathrm d t} $$$$ = \mathbf a \left({\frac {\sqrt{1 - \dfrac {v^2}{c^2} } - \dfrac v 2 \dfrac 1 {\sqrt{1 - \dfrac {v^2}{c^2} } } \dfrac{-2 v}{c^2} } {1 - \dfrac {v^2}{c^2} } }\right) $$$$ = \mathbf a \left({\frac {c^2 \left({1 - \dfrac {v^2}{c^2} }\right) + v^2} {c^2 \left({1 - \dfrac {v^2}{c^2} }\right)^{3/2} } }\right) $$$$ = \mathbf a \left({\frac 1 {\left({1 - \dfrac {v^2}{c^2} }\right)^{3/2} } }\right)$$Thus we arrive at the form:$$\mathbf F = \dfrac {m_0 \mathbf a} {\left({1 - \dfrac{v^2}{c^2}}\right)^{\tfrac 3 2}}$$Sources1992: George F. Simmons: Calculus Gems … (previous) … (next): Chapter B.7: A Simple Approach to $E = M c^2$]]></content>
      <categories>
        <category>physical</category>
      </categories>
      <tags>
        <tag>physical</tag>
        <tag>law of motion</tag>
        <tag>law</tag>
        <tag>montion</tag>
        <tag>einstein</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Einstein's Mass-Velocity Equation]]></title>
    <url>%2F2019%2F02%2F23%2Feinstein-mass-velocity-equation%2F</url>
    <content type="text"><![CDATA[$$m = \dfrac {m_0} {\sqrt{1 - \dfrac {v^2} {c^2} } }$$Physical LawThe mass 𝑚 of a body is not constant.It varies with the body’s velocity, according to the equation:$$m = \dfrac {m_0} {\sqrt{1 - \dfrac {v^2} {c^2} } }$$where:𝑣 is the magnitude of the velocity of the body𝑐 is the speed of light in vacuum𝑚0 is the rest mass of the body.The value 𝑚 is known as the relativistic mass of the body.The factor $\dfrac 1 {\sqrt{1 - \dfrac {v^2} {c^2} } }$ is known as the Lorentz Factor.ProofImagine a comet that flies towards a planet on which you are resting.The comet’s velocity 𝑢 towards the planet is much smaller than the speed of light.Now imagine the impact caused by the comet striking the planet as a deformation of the planet.That impact can be seen as proportional to the momentum of the comet which is:$$𝑝=𝑚𝑢$$where:𝑝 is the magnitude of the comet’s momentum𝑚 is the comet’s rest mass𝑢 is the magnitude of the comet’s velocity.f someone else watches the crash from a space ship passing by with a relativistic velocity (for example 𝑣=0.7𝑐) he will find that the comet appears to move more slowly than it does from your stationary perspective on the planet.This is due to the time dilation, which is given by:$$\Delta t’ = \dfrac {\Delta t} {\sqrt{1 - \dfrac {v^2} {c^2}}}$$where:Δ𝑡′ is the time interval measured from the space shipΔ𝑡 is the time interval measured in the inertial system containing planet and comet𝑣 is the magnitude of the space ship’s velocity𝑐 is the speed of light in vacuum.Because the time measured in the space ship is less, the comet will appear to need more time to cover a certain distance.Thus, its velocity seems smaller from the perspective of the space ship (Note: The space ship’s trajectory be perpendicular to the comet’s trajectory towards the planet, so there is no length contraction parallel to the trajectory of the comet).The comet’s velocity measured from the planet is:$$u = \dfrac {\mathrm d s} {\mathrm d t}$$where the comet’s velocity measured from the space ship is:$$u’ = \dfrac {\mathrm d s} {\mathrm d t’}$$and as we know from the time dilation, the term for 𝑢′ is thus:$$u’ = u \sqrt{1 - \frac {v^2}{c^2}}$$The observer in the space ship will nevertheless find out that the impact is equal to the one observed by the resting person.That means that the comet’s momentum doesn’t change, no matter from what inertial system you measure it.That can only be possible, if – seen from the space ship – the comet’s mass increases, as its velocity decreases.The comet’s momentum from the perspective of the space ship is:$$p’ = m’ u’$$where:𝑝′ is the magnitude of the comet’s momentum measured from the inertial system of the space ship𝑚′ is the comet’s relativistic mass measured from the inertial system of the space ship𝑢′ is the magnitude of the comet’s velocity measured from the inertial system of the space ship.And because the measured momentums from both observers are the same, you can write:$$p = p’$$$$m u = m’ u’$$$$m’ = m \dfrac u {u’}$$$$m’ = m \dfrac u {u \sqrt{1 - \frac {v^2} {c^2}}}$$$$m’ = \dfrac m {\sqrt{1 - \frac {v^2} {c^2}}}$$Sources1972: George F. Simmons: Differential Equations … (previous) … (next): Miscellaneous Problems for Chapter 2: Problem 321992: George F. Simmons: Calculus Gems … (previous) … (next): Chapter B.7: A Simple Approach to $E = M c^2$]]></content>
      <categories>
        <category>physical</category>
      </categories>
      <tags>
        <tag>physical</tag>
        <tag>einstein</tag>
        <tag>equation</tag>
        <tag>mass-velocity equation</tag>
        <tag>mass</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[next主题的一些配置]]></title>
    <url>%2F2019%2F02%2F14%2Fnext-tips%2F</url>
    <content type="text"><![CDATA[在使用next主题过程中遇到一些问题，供大家参考。中文问题原因站点内将language设置为zh-Hans，但是博客的语言并没有被改变为中文，原因是next主题使用zh-CN.yml配置跟site的配置不一致。解决办法创建一个软链即可12cd $THEME_FOLDER/languagesln -s zh-CN.yml zh-Hans.yml版权申明现在是需要配置creative_commons节点：1234567# Creative Commons 4.0 International License.# https://creativecommons.org/share-your-work/licensing-types-examples# Available values: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zerocreative_commons: license: by-nc-sa sidebar: true # 显示在sidebar里面，可选 post: true # 显示在post底部]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
        <tag>theme</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[支付系统-架构设计]]></title>
    <url>%2F2019%2F02%2F06%2Fpay-design-architecture%2F</url>
    <content type="text"><![CDATA[本文介绍核心支付系统的主要功能和组件。span.green{color:#54cc76}span.purple{color:#7949b3}span.yellow{color:#ffca80}设计目标简化逻辑：边界清晰、无冗余逻辑、方便测试分布式：容器化部署、无状态、可扩展、低耦合高用性：机房多主、自动扩容、数据库最终一致拆分业务：代金券、活动支付中心：商品管理、价格管理、发货路由支付网关：下单、支付、代扣、通知、后督（订单二次确认）、对账、渠道服务实现网关体系支付网关：接受下单请求、校验签名、生成订单、操作DB、调用渠道服务代扣网关：处理签约请求、代扣请求、互斥逻辑通知网关：处理渠道通知渠道服务集合原则无db操作无订单操作只接受请求并响应对应数据不关心上层逻辑微服务化service:wechatalipayunionpayrpc:grpc://wechat:8080grpc://alipay:8080http://unionpay:8080渠道微服务化，可以在国际化业务中带来更便捷的差异化部署面向协议编程pay(用户触发扣款或签约)method：alipay/wechat/unionpayfrom: WEB/MWEB/APP/SDK/BANK/SERVERtype: pay/sign_payconfirm_pay(确认支付，用户二次验证)fromtypemethodrefund(退款)transfer(转账)扩展&amp;配置etcd配置管理高可用实时变更配置跨地域同步简化配置使用field tag生成json管理后台根据field json生成配置表单支付网关系统支付调用时序图签约数据库高可用跨DC同步：基于otter进行同步，双向同步（多机房使用星型结构）同DC高可用：基于mycat和mgr，实现大容量、高可用db集群mgr的心跳检测：二次开发mycat，对mgr节点状态实时检测并增删故障db应用层：去除自增主键，按机房、机器生成无冲突、有序的流水号，防止多机房数据冲突部署架构交互配置核心交易系统是将配置信息存储在etcd容器内渠道基础目录: /foo/bar/pay/config每个渠道占用一个文件夹，每个渠道账户占用一个文件，例如微信存放在/foo/bar/pay/config/wechat目录下，appId: 2088123456 所在的配置信息存储在/foo/bar/pay/config/wechat/2088123456]]></content>
      <categories>
        <category>pay</category>
      </categories>
      <tags>
        <tag>pay</tag>
        <tag>design</tag>
        <tag>payment</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[支付系统-概述]]></title>
    <url>%2F2019%2F02%2F06%2Fpay-summary%2F</url>
    <content type="text"><![CDATA[网上对于支付系统的讲解，都是比较偏概念性的讲解，很少有对于开发细节的说明文章。博主有多年从事支付系统的设计与开发，希望能结合以往经验、做出总结，分享给即将从事或者正在从事开发的童鞋参考，也希望自己能多锻炼写作技能、总结能力。如有不足或者错误的地方，请留言指出或交流讨论~感谢阅读！支付系统支付系统主要是用于规范化支付流程、加强安全、财务对账等。一个支付系统要想做得好，一定要做好接口规范、做好安全措施、把调单对账做好。同时，服务必须是高可用、高一致性的。聚合支付与三方支付规范支付流程规范支付流程的方法有：抽象支付场景，分别定义支付流程H5支付（有些支付商会定义为WAP支付）：主要适用于手机浏览器APP支付SDK支付网银支付规范接口参数，尽量简化接入方的开发提供良好的测试工具，方便调试安全网络层使用https协议下单、回调，保证网络数据不被窃听接口协议使用签名机制防止参数传输过程中被篡改]]></content>
      <categories>
        <category>pay</category>
      </categories>
      <tags>
        <tag>pay</tag>
        <tag>design</tag>
        <tag>payment</tag>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo使用git子模块来管理theme]]></title>
    <url>%2F2019%2F02%2F01%2Fuse-git-submodules%2F</url>
    <content type="text"><![CDATA[我们的博客可能面临评论系统不可用、分享插件不可用、主题升级的问题。如果你是直接把代码copy到你的博客目录里面，那么你想修复这些问题，就会代码灾难性的后果。使用git submodule能很好解决这个问题。我们需要对主题进行单独的管理，使其成为博客的一个独立部件，而这就是使用 git submodule 的最佳场景。步骤如下：1. Fork 一份主题到自己的 Github 上。 &gt; Fork 的目的在于，我们可以对主题进行各种个性化的定制以及修改，并对这些定制进行版本控制。同时，我们还能随时与原主题的更新进行合并。 2. 创建一个 submodule。 12$ cd blog-hexo // 切换到hexo目录$ git submodule add https://github.com/pinggod/hexo-theme-apollo themes/apollo 3. 更新 _config.yml 使用修改过的主题。 1theme: apollo 4. 这时，我们就拥有了两个独立的仓库，一个是 hexo 博客，另外一个是主题。 123$ cd blog-hexo$ git submodule# 6c40f5ec27e1889c5a0a0a999e847634a33aef1c themes/apollo (heads/master) 并且，在 github 上也可以看到它指向了正确的地址。 使用 submodule 配置好之后，在不同电脑间进行同步就非常简单了：123$ cd blog-hexo$ git pull$ git submodule update就算是一台全新的电脑，也可以很轻松地进行配置：1234$ git clone https://github.com/buginux/swiftyper-blog.git$ cd swiftyper-blog$ npm install$ git submodule update --init使用几行代码就能配置一个博客，是不是感觉相当酷炫。而这其中的便利都是拜 Git 及 Github 所赐，这也是我为何如此喜欢它们的原因。当然，使用这种方法也有缺点，那就是当原主题更新的时候，我们需要进行手动拉取对方的最新代码，并合并到自己的代码中，而且由于我们修改过主题，所以合并的过程中可能会出现冲突，这就需要我们进行手动解决了。不过总体来说，如果我们选择的是一个比较稳定的主题，出现这种情况的机率还是比较小的，相对于 submodule 的便利，这点付出还是值得的。参考www.swiftyper.comGit-Tools-Submodules]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>hexo</tag>
        <tag>blog</tag>
        <tag>submodule</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell-strings]]></title>
    <url>%2F2019%2F01%2F30%2Fshell-strings%2F</url>
    <content type="text"><![CDATA[在做shell批处理程序时候，经常会涉及到字符串相关操作。有很多命令语句，如：awk,sed都可以做字符串各种操作。 其实shell内置一系列操作符号，可以达到类似效果，大家知道，使用内部操作符会省略启动外部程序等时间，因此速度会非常的快。判断读取字符串值${var} 变量var的值, 与$var相同${var-DEFAULT} 如果var没有被声明, 那么就以$DEFAULT作为其值 *${var:-DEFAULT} 如果var没有被声明, 或者其值为空, 那么就以$DEFAULT作为其值 *${var=DEFAULT} 如果var没有被声明, 那么就以$DEFAULT作为其值 *${var:=DEFAULT} 如果var没有被声明, 或者其值为空, 那么就以$DEFAULT作为其值 *${var+OTHER} 如果var声明了, 那么其值就是$OTHER, 否则就为null字符串${var:+OTHER} 如果var被设置了, 那么其值就是$OTHER, 否则就为null字符串${var?ERR_MSG} 如果var没被声明, 那么就打印$ERR_MSG *${var:?ERR_MSG} 如果var没被设置, 那么就打印$ERR_MSG *${!varprefix*} 匹配之前所有以varprefix开头进行声明的变量${!varprefix@} 匹配之前所有以varprefix开头进行声明的变量加入了“*” 不是意思是： 当然, 如果变量var已经被设置的话, 那么其值就是$var.字符串操作${string:position} 在string中, 从位置$position开始提取子串${string:position:length} 在string中, 从位置$position开始提取长度为length的子串${string#substring} 从变量string的开头, 删除最短匹配substring的子串${string##substring} 从变量string的开头, 删除最长匹配substring的子串${string%substring} 从变量string的结尾, 删除最短匹配substring的子串${string%%substring} 从变量string的结尾, 删除最长匹配substring的子串${string/substring/replacement} 使用replacement, 来代替第一个匹配的substring${string//substring/replacement} 使用replacement, 代替所有匹配的substring${string/#substring/replacement} 如果string的前缀匹配$substring, 那么就用replacement来代替匹配到的substring${string/%substring/replacement} 如果string的后缀匹配$substring, 那么就用replacement来代替匹配到的substring说明：”* $substring”可以是一个正则表达式.实例读取12345678910111213141516$ echo $&#123;abc-'ok'&#125; ok $ echo $abc $ echo $&#123;abc='ok'&#125; ok $ echo $abc ok #如果abc 没有声明“=" 还会给abc赋值。 $ var1=11;var2=12;var3= $ echo $&#123;!v@&#125; var1 var2 var3 $ echo $&#123;!v*&#125; var1 var2 var3 #$&#123;!varprefix*&#125;与$&#123;!varprefix@&#125;相似，可以通过变量名前缀字符，搜索已经定义的变量,无论是否为空值。取得字符串长度1234string=abc12342341 //等号二边不要有空格 echo $&#123;#string&#125; //结果11 expr length $string //结果11 expr "$string" : ".*" //结果11 分号二边要有空格,这里的:根match的用法差不多字符串所在位置123456expr index $string '123' //结果4 字符串对应的下标是从1开始的str="abc" expr index $str "a" # 1 expr index $str "b" # 2 expr index $str "x" # 0 expr index $str "" # 0字符串截取12345678910111213141516echo $&#123;string:4&#125; //2342341 从第4位开始截取后面所有字符串 echo $&#123;string:3:3&#125; //123 从第3位开始截取后面3位 echo $&#123;string:3:6&#125; //123423 从第3位开始截取后面6位 echo $&#123;string: -4&#125; //2341 ：右边有空格 截取后4位 echo $&#123;string:(-4)&#125; //2341 同上 expr substr $string 3 3 //123 从第3位开始截取后面3位 str="abcdef" expr substr "$str" 1 3 # 从第一个位置开始取3个字符， abc expr substr "$str" 2 5 # 从第二个位置开始取5个字符， bcdef expr substr "$str" 4 5 # 从第四个位置开始取5个字符， def echo $&#123;str:2&#125; # 从第二个位置开始提取字符串， bcdef echo $&#123;str:2:3&#125; # 从第二个位置开始提取3个字符, bcd echo $&#123;str:(-6):5&#125; # 从倒数第二个位置向左提取字符串, abcde echo $&#123;str:(-4):3&#125; # 从倒数第二个位置向左提取6个字符, cde匹配显示内容1234//例3中也有match和这里的match不同，上面显示的是匹配字符的长度，而下面的是匹配的内容 expr match $string '[a−c]∗[0−9]∗[a−c]∗[0−9]∗' //abc12342341 expr $string : '[a−c]∗[0−9][a−c]∗[0−9]' //abc1 expr $string : '.*[0−9][0−9][0−9][0−9][0−9][0−9]' //341 显示括号中匹配的内容这里括号的用法，是不是根其他的括号用法有相似之处呢，截取不匹配的内容123456echo $&#123;string#a*3&#125; //42341 从$string左边开始，去掉最短匹配子串 echo $&#123;string#c*3&#125; //abc12342341 这样什么也没有匹配到 echo $&#123;string#*c1*3&#125; //42341 从$string左边开始，去掉最短匹配子串 echo $&#123;string##a*3&#125; //41 从$string左边开始，去掉最长匹配子串 echo $&#123;string%3*1&#125; //abc12342 从$string右边开始，去掉最短匹配子串 echo $&#123;string%%3*1&#125; //abc12 从$string右边开始，去掉最长匹配子串获取文件名123url="https://dl.google.com/go/go1.12.darwin-amd64.tar.gz"echo $&#123;url##*/&#125; // go1.12.darwin-amd64.tar.gzecho $&#123;url%/*&#125; // https://dl.google.com/go12345678910111213str="abbc,def,ghi,abcjkl" echo $&#123;str#a*c&#125; # 输出,def,ghi,abcjkl 一个井号(#) 表示从左边截取掉最短的匹配 (这里把abbc字串去掉） echo $&#123;str##a*c&#125; # 输出jkl， 两个井号(##) 表示从左边截取掉最长的匹配 (这里把abbc,def,ghi,abc字串去掉) echo $&#123;str#"a*c"&#125; # 输出abbc,def,ghi,abcjkl 因为str中没有"a*c"子串 echo $&#123;str##"a*c"&#125; # 输出abbc,def,ghi,abcjkl 同理 echo $&#123;str#*a*c*&#125; # 空 echo $&#123;str##*a*c*&#125; # 空 echo $&#123;str#d*f) # 输出abbc,def,ghi,abcjkl, echo $&#123;str#*d*f&#125; # 输出,ghi,abcjkl echo $&#123;str%a*l&#125; # abbc,def,ghi 一个百分号(%)表示从右边截取最短的匹配 echo $&#123;str%%b*l&#125; # a 两个百分号表示(%%)表示从右边截取最长的匹配 echo $&#123;str%a*c&#125; # abbc,def,ghi,abcjkl这里要注意，必须从字符串的第一个字符开始，或者从最后一个开始，可以这样记忆, 井号（#）通常用于表示一个数字，它是放在前面的；百分号（%）卸载数字的后面; 或者这样记忆，在键盘布局中，井号(#)总是位于百分号（%）的左边(即前面) 。匹配并且替换1234echo $&#123;string/23/bb&#125; //abc1bb42341 替换一次 echo $&#123;string//23/bb&#125; //abc1bb4bb41 双斜杠替换所有匹配 echo $&#123;string/#abc/bb&#125; //bb12342341 #以什么开头来匹配，根php中的^有点像 echo $&#123;string/%41/bb&#125; //abc123423bb %以什么结尾来匹配，根php中的$有点像123456789101112131415str="apple, tree, apple tree" echo $&#123;str/apple/APPLE&#125; # 替换第一次出现的apple echo $&#123;str//apple/APPLE&#125; # 替换所有apple echo $&#123;str/#apple/APPLE&#125; # 如果字符串str以apple开头，则用APPLE替换它 echo $&#123;str/%apple/APPLE&#125; # 如果字符串str以apple结尾，则用APPLE替换它 ```shell $ test='c:/windows/boot.ini' $ echo $&#123;test/\//\\&#125; c:\windows/boot.ini $ echo $&#123;test//\//\\&#125; c:\windows\boot.ini #$&#123;变量/查找/替换值&#125; 一个“/”表示替换第一个，”//”表示替换所有,当查找中出现了：”/”请加转义符”\/”表示。比较1234[[ "a.txt" == a* ]] # 逻辑真 (pattern matching) [[ "a.txt" =~ .*\.txt ]] # 逻辑真 (regex matching) [[ "abc" == "abc" ]] # 逻辑真 (string comparision) [[ "11" &lt; "2" ]] # 逻辑真 (string comparision), 按ascii值比较连接123s1="hello" s2="world" echo $&#123;s1&#125;$&#123;s2&#125; # 当然这样写 $s1$s2 也行，但最好加上大括号字符串删除123456789101112131415$ test='c:/windows/boot.ini' $ echo $&#123;test#/&#125; c:/windows/boot.ini $ echo $&#123;test#*/&#125; windows/boot.ini $ echo $&#123;test##*/&#125; boot.ini $ echo $&#123;test%/*&#125; c:/windows $ echo $&#123;test%%/*&#125; #$&#123;变量名#substring正则表达式&#125;从字符串开头开始配备substring,删除匹配上的表达式。 #$&#123;变量名%substring正则表达式&#125;从字符串结尾开始配备substring,删除匹配上的表达式。 #注意：$&#123;test##*/&#125;,$&#123;test%/*&#125; 分别是得到文件名，或者目录地址最简单方法。]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>shell</tag>
        <tag>linux</tag>
        <tag>strings</tag>
        <tag>substring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac滚动截屏]]></title>
    <url>%2F2019%2F01%2F29%2Fmac-screenshots%2F</url>
    <content type="text"><![CDATA[作为开发者，截图是一个必备技能之一最常规的或许就是登陆QQ，使用Ctrl + Command（Alt）+ A，简单粗暴。没错，使用QQ快捷键截图可能是那些年我们最常用的方式。当然，这种方式并没有过时，大家依然常用，方便，快捷，实用。另外，Mac有自带截图功能。（1）Shift + Command + 3，会将生成图片自动保存到桌面上。（2）Shift + Command + 4，会出现十字光标，按需选中要截图的内容后，会将生成图片自动保存到桌面上。（3）Shift + Command + 4，会出现十字光标，按空格键，出现相机图标，然后点击界面，就会把当前界面生成图片自动保存到桌面上。以上截图方式就已经很方便，那么，如果要截长图，有什么好的办法呢？Chorme浏览器有自带截长图功能，方便好用。打开需要截长图的网页，右键–检查–Shift + Command + P，输入screen，选择Capture full size screenshot，chrome会生成一张以当前页面url命名的长截图，并会将生成图片自动保存到下载里面，通过Finder可以找到。当然，我们也可以用同样的方法，局部截图：通过审查元素，选中我们需要截图的div盒子，选择：Capture node screenshot就可以实现局部截图了。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>screenshot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker notes]]></title>
    <url>%2F2019%2F01%2F28%2Fdocker-notes%2F</url>
    <content type="text"><![CDATA[重写docker镜像内的EntryPoint1docker run --entrypoint "/bin/ls -al /root" debian]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gcr.io镜像：解决kubernetes镜像无法访问的问题]]></title>
    <url>%2F2019%2F01%2F28%2Fgoogle-containers%2F</url>
    <content type="text"><![CDATA[kubernetes镜像（gcr.io）无法访问的问题经常会遇到gcr.io/google_containers被墙的问题，可以使用：https://hub.docker.com/u/googlecontainer使用方法将gcr.io/google_containers/$repo替换为googlecontainer/$repo，例如需要使用gcr.io/google_containers/kubernetes-dashboard-amd64镜像，则使用googlecontainer/kubernetes-dashboard-amd64即可。docker pull googlecontainer/kubernetes-dashboard-amd64 # for dockerkubeadm init –image-repository googlecontainer # for kubernetes原理travis-ci安装gcloud并授权，然后利用travis-ci的网络来拉取google_containers镜像，并将镜像push到docker仓库。每天定时出发travis来拉取google_containers的更新。使用gcloud命令列列举gcr.io/google_containers下的所有镜像repo遍历第1步的repo，获取该repo的所有tag，然后对比gcr-complete-tasks，如果该tag已经被同步，则跳过拉取gcr.io/google_containers/$repo:$tag的镜像：image。如果$image已经在gcr-complete-images内存在，则跳过。修改$image的repo和tag，打docker tag为googlecontainer/$repo:$tag，并push到googlecontainer$repo:$tag重复2-4步，直到所有$repo都已经同步优点不需要自己vps不需要搭梯子理论镜像的延迟时间是24H，比较实时全自动检测新镜像，不需要人为参与缺点比较依赖git来存储进度，造成git的commit log非常大（已经解决，通过使用travis-ci的cache解决）有被travis封禁的风险（每次限制存储量和任务量）新增owner（目前owner=google_containers）时无法检测（已经解决，使用owners文件来新增owner。如需增加，请留言或者提交Pull request。）代码https://github.com/blademainer/google_containers_mirror]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>docker</tag>
        <tag>image</tag>
        <tag>google</tag>
        <tag>containers</tag>
        <tag>kubernetes</tag>
        <tag>k8s</tag>
        <tag>forbid</tag>
        <tag>gcr</tag>
        <tag>io</tag>
        <tag>mirror</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes-notes]]></title>
    <url>%2F2019%2F01%2F25%2Fkubernetes-notes-md%2F</url>
    <content type="text"><![CDATA[Kubernetes笔记导出现有的资源12345for n in $(kubectl get -o=name pvc,configmap,serviceaccount,secret,ingress,service,deployment,statefulset,hpa,job,cronjob)do mkdir -p $(dirname $n) kubectl get -o=yaml --export $n &gt; $n.yamldone热更新deploy有时候我们修改了ConfigMap，但是代码不支持，肯定不能让程序停止，因此必须支持热更新。命令如下：1kubectl patch deployment [deploy] --patch '&#123;"spec": &#123;"template": &#123;"metadata": &#123;"annotations": &#123;"version/config": "'`date +%Y%m%d%H%M%S`'" &#125;&#125;&#125;&#125;&#125;'拷贝secrets到其他namespace12kubectl get secret gitlab-registry --namespace=revsys-com --export -o yaml |\ kubectl apply --namespace=devspectrum-dev -f -临时运行一个pod--restart=Never 代表起一个pod--rm 在终端退出时删除pod-l 给pod打label12kubectl run --rm -it busybox --image sequenceiq/busybox --restart=Neverkubectl run --rm -it mysql-client --image=mysql -l "net=grant-db" --restart=Never bash获取pod信息123456789101112131415161718192021env: - name: MY_NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: MY_POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: MY_POD_IP valueFrom: fieldRef: fieldPath: status.podIP - name: MY_POD_SERVICE_ACCOUNT valueFrom: fieldRef: fieldPath: spec.serviceAccountNameScratch DebuggerThis is a tool to make debugging containers based on scratch easier. The scriptworks by bringing up a pod with a statically-linked busybox image on the samenode as the debug target, mounting the node’s root filesystem, and callingdocker directly to copy busybox into the target container. Once the “install” iscomplete, the target can be debugged through a standard kubectl exec.Usage1curl https://raw.githubusercontent.com/kubernetes/contrib/master/scratch-debugger/debug.sh | sh -s -- POD_NAME [-n POD_NAMESPACE -c CONTAINER_NAME]POD_NAME - The name of the pod to debug.POD_NAMESPACE - The namespace of the target pod (defaults to default).CONTAINER_NAME - The name of the container in the pod to debug (defaults to the first container).Additionally, the following environment variables can be set:TMP_SUBDIR - The subdirectory under /tmp to install busybox into (defaults to debug-tools).KUBECONTEXT - The kubectl context to use (defaults to current context).DEBUGGER_NAME - The name to use for the debug pod (defaults to debugger).ARCH - The architecture Kubernetes is running on (defaults to amd64).DOCKER_DOWNLOAD_URL - URL for downloading the docker release .tgz file(see debug.sh for the default value).ExampleCreate a simple pause pod, which is based off a scratch image and does nothing.123456789101112$ kubectl create -f - &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: pausespec: containers: - name: pause image: k8s.gcr.io/pauseEOFpod "pause" createdNote that we cannot simply exec into the pod, since there isn’t a shell or anyother interactive tools available:12$ kubectl exec -i -t pause -- shrpc error: code = 2 desc = "oci runtime error: exec failed: exec: \"sh\": executable file not found in $PATH"So we use the debug.sh script to copy busybox (which includes many commontools) into the container:1234567891011121314151617181920212223$ scratch-debugger/debug.sh pauseDebug Target Container: Pod: pause Namespace: default Node: e2e-test-stclair-minion-group-phj6 Container: pause Container ID: 80b134ab6550d34684cdb31e4300ff128f9f43f67fdb3d271372f9417e546737 Runtime: dockerInstalling busybox to /tmp/debug-tools ...pod "debugger" createdwaiting for debugger pod to become ready...Installation complete.To debug pause, run: kubectl exec -i -t pause -- /tmp/debug-tools/sh -c 'PATH=$PATH:/tmp/debug-tools sh'Dumping you into the pod container now./ # lsdev etc pause proc sys tmp var/ # echo Hello world!Hello world!/ # exitpod "debugger" deletedThe script automatically execs into the pod and starts a shell (ash) with thePATH variable set to include the debug tools. After exiting, the tools arestill present in the pod, and we can simply exec back in using the command thescript gave us:1234$ kubectl exec -i -t pause -- /tmp/debug-tools/sh -c 'PATH=$PATH:/tmp/debug-tools sh'/ # which sh/tmp/debug-tools/sh/ # exitAlternatively, we can just call the debug.sh script again:123$ scratch-debugger/debug.sh pauseDebug tools already installed. Dumping you into the pod container now./ # exitOnce we’ve finished debugging, it’s a good practice to delete the “tainted”pod. If that is undesirable for some reason, you can simply delete the toolsfrom the container:1$ kubectl exec pause -- /tmp/debug-tools/rm -r /tmp/debug-toolsmysql-operator简化在kubernetes内创建mysql集群(支持MySQL Group Replication)github]]></content>
      <categories>
        <category>kuberbetes</category>
      </categories>
      <tags>
        <tag>notes</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[plantuml示例]]></title>
    <url>%2F2019%2F01%2F24%2Fplant-uml-demo%2F</url>
    <content type="text"><![CDATA[plantuml使用示例online editor activity ArchimateClassDeploy Gantt UseCase Timing]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>plantuml</tag>
        <tag>demo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL笔记]]></title>
    <url>%2F2019%2F01%2F19%2F2019-01-20-mysql-notes%2F</url>
    <content type="text"><![CDATA[这里收藏工作中用到的脚本，也为了防止做重复的搜索工作，同时分享给大家。查看当前表的自增序列1SELECT `AUTO_INCREMENT` FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = &apos;DatabaseName&apos; AND TABLE_NAME = &apos;TableName&apos;;修改自增序列1alter table tablename auto_increment=NUMBER;查看binlog1show binary logs;查看binlog位置1show binlog events in &apos;$&#123;BINLOG&#125;&apos; limit 10;批量更新指定schema的increment1234567#!/bin/bashINCREMENT="34614952180"echo "select CONCAT(TABLE_SCHEMA, '.', TABLE_NAME) FROM INFORMATION_SCHEMA.TABLES where TABLE_SCHEMA in ('schema1','schema2','schema3') or TABLE_SCHEMA like 'schema_prefix_%';" | mysql -h $&#123;HOST&#125; -u$&#123;USER&#125; -p$&#123;PASS&#125; -s &gt; tables.tmpcat tables.tmp | while read table; do echo "alter table $table AUTO_INCREMENT=$INCREMENT" | mysql -h $&#123;HOST&#125; -u$&#123;USER&#125; -p$&#123;PASS&#125;;done批量导出数据库（除了系统库）123echo "show databases" | mysql | grep -Ev "^(Database|mysql|performance_schema|information_schema)$" &gt; databasescat databases | while read db; do mysqldump --column-statistics=0 --complete-insert --single-transaction --skip-opt --extended-insert --disable-keys --create-options --default-character-set=utf8 --quick --set-gtid-purged=OFF --databases $db &gt;&gt; payproxy.sql; donerm databases]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在docker内运行java的问题]]></title>
    <url>%2F2017%2F04%2F05%2F2017-04-06-run-java-in-docker%2F</url>
    <content type="text"><![CDATA[众所周知，当我们执行没有任何调优参数（如java -jar myapplication.jar）的 Java 应用程序时，JVM 会自动调整几个参数，以便在执行环境中具有最佳性能。但是许多开发者发现，如果让 JVM ergonomics (即JVM人体工程学，用于自动选择和行为调整)对垃圾收集器、堆大小和运行编译器使用默认设置值，运行在Linux容器（docker,rkt,runC,lxcfs 等）中的 Java 进程会与我们的预期表现严重不符。本篇文章采用简单的方法来向开发人员展示在 Linux 容器中打包 Java 应用程序时应该知道什么。存在的问题我们往往把容器当虚拟机，让它定义一些虚拟 CPU 和虚拟内存。其实容器更像是一种隔离机制：它可以让一个进程中的资源（CPU，内存，文件系统，网络等）与另一个进程中的资源完全隔离。Linux 内核中的 cgroups 功能用于实现这种隔离。然而，一些从执行环境收集信息的应用程序已经在 cgroups 存在之前就被执行了。“top”，“free”，“ps”，甚至 JVM 等工具都没有针对在容器内执行高度受限的 Linux 进程进行优化。场景还原实验采用的是本人编写的测试代码。代码很简单，就是不断的创建byte数组并保存到list里面。代码所在项目：blademainer/java-memory-demo运行步骤：首先使用docker运行java的测试镜像，并限制其最大可用的内存为64M1docker run --name java-memory-demo --memory-swap=0 --memory-swappiness=0 -m 64m -e JAVA_OPTIONS="-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/jvmdump/" -v `pwd`/jvmdump:/jvmdump -d blademainer/java-memory-demoJAVA_OPTIONS=”-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/jvmdump/“ 的作用是：在JVM报oom时dump出堆信息。另起一个终端，监听镜像的事件:1docker events -f image=blademainer/java-memory-demo运行一段时间后，java容器会被杀死，运行日志如下：123456789101112131415161718192021222324252627282930313233343536373839404142------------------------------------------MaxMemory: 3.46GFreeMemory: 197.48MTotalMemory: 240.0MUsable: 3.42G------------------------------------------Name: Code CachePeakUsage: init = 2555904(2.44M) used = 1242176(1.18M) committed = 2555904(2.44M) max = 251658240(240.0M)------------------------------------------Name: MetaspacePeakUsage: init = 0(0) used = 3276728(3.12M) committed = 4980736(4.75M) max = -1(-1)------------------------------------------Name: Compressed Class SpacePeakUsage: init = 0(0) used = 345832(337.73K) committed = 524288(512.0K) max = 1073741824(1.0G)------------------------------------------Name: PS Eden SpaceCollectionUsage: init = 66060288(63.0M) used = 0(0) committed = 0(0) max = 1371537408(1.28G)CollectionUsageThreshold: 0CollectionUsageThresholdCount: 0PeakUsage: init = 66060288(63.0M) used = 44585544(42.52M) committed = 66060288(63.0M) max = 1371537408(1.28G)------------------------------------------Name: PS Survivor SpaceCollectionUsage: init = 10485760(10.0M) used = 0(0) committed = 0(0) max = 10485760(10.0M)CollectionUsageThreshold: 0CollectionUsageThresholdCount: 0PeakUsage: init = 10485760(10.0M) used = 0(0) committed = 10485760(10.0M) max = 10485760(10.0M)------------------------------------------Name: PS Old GenCollectionUsage: init = 175112192(167.0M) used = 0(0) committed = 0(0) max = 2785017856(2.59G)CollectionUsageThreshold: 0CollectionUsageThresholdCount: 0PeakUsage: init = 175112192(167.0M) used = 0(0) committed = 175112192(167.0M) max = 2785017856(2.59G)------------------------------------------PS ScavengeCollectionCount: 0CollectionTime: 0ms------------------------------------------PS MarkSweepCollectionCount: 0CollectionTime: 0msAllocating memory: 10485760Killed原因分析事件分析第二步docker events -f image=blademainer/java-memory-demo事件监听输出如下：12342017-04-29T23:01:24.753731857+08:00 container create 92f98a1773549572cf8c3435350a6d1a885196884e957b35b5e1fa572e617a3b (image=blademainer/java-memory-demo, name=java-memory-demo)2017-04-29T23:01:24.948240973+08:00 container start 92f98a1773549572cf8c3435350a6d1a885196884e957b35b5e1fa572e617a3b (image=blademainer/java-memory-demo, name=java-memory-demo)2017-04-29T23:01:25.015361538+08:00 container oom 92f98a1773549572cf8c3435350a6d1a885196884e957b35b5e1fa572e617a3b (image=blademainer/java-memory-demo, name=java-memory-demo)2017-04-29T23:01:25.092596145+08:00 container die 92f98a1773549572cf8c3435350a6d1a885196884e957b35b5e1fa572e617a3b (exitCode=137, image=blademainer/java-memory-demo, name=java-memory-demo)输出内容的第四行有个致命的报错container oom导致java程序直接退出。或者使用docker inspect java-memory-demo也能看到错误信息以及状态:12345678910111213"State": &#123; "Status": "exited", "Running": false, "Paused": false, "Restarting": false, "OOMKilled": true, "Dead": false, "Pid": 0, "ExitCode": 137, "Error": "", "StartedAt": "2017-04-29T15:01:24.940805854Z", "FinishedAt": "2017-04-29T15:01:25.092588915Z" &#125;docker直接杀掉了java容器，此时的退出前的java程序不会报任何错误信息也不会打印错误堆栈、调用shutdownHook等。jvmdump也不会有dump的文件输出：原因分析按道理JVM会自动根据当前系统的可用内存来自动分配JVM的内存大小，那么JVM分配的内存应该不大于64M，然而我们的java程序输出日志如下：1234MaxMemory: 3.46GFreeMemory: 207.48MTotalMemory: 240.0MUsable: 3.43GMaxMemory: 3.46G代表最大可用内存为3.46G，明显不是我们期望的结果。JVM之所以不知道他所在的环境是被限制了内存大小的，是因为docker采用cgroup技术来限制资源的，而JVM无法感知该限制，导致JVM根据宿主机器的最大内存来分配可用内存。解决方案使用启动参数来限制容器内JVM的内存1docker run --name java-memory-demo --memory-swap=0 --memory-swappiness=0 -m 256m -e JAVA_OPTIONS="-Xmx128m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/jvmdump/" -v `pwd`/jvmdump:/jvmdump -d blademainer/java-memory-demoJAVA_OPTIONS增加了-Xmx128mJVM正确的打印了异常日志日志、调用了ShutdownHook以及正确的输出了HeapDumpPath使用可以识别cgroup限制的JVMjdk9fabric8/java-jboss-openjdk8-jdkTomcat容器的运行运行时使用JAVA_OPTS环境变量：1docker run --memory-swap=0 --memory-swappiness=0 -m 256m -e JAVA_OPTS="-Xmx128m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/jvmdump/" -v `pwd`/jvmdump:/jvmdump tomcat参考java-inside-dockergc-ergonomics]]></content>
      <tags>
        <tag>java</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在docker内运行docker命令]]></title>
    <url>%2F2017%2F03%2F23%2Frun-docker-in-docker%2F</url>
    <content type="text"><![CDATA[我们的项目里面经常需要使用jenkins来编译docker，然后jenkins本身就是docker运行起来的，因此编译docker镜像就无法进行。通过调查发现：可以通过映射宿主机器的docker来达到运行的目的。命令如下：12345678docker run -it --rm \ --privileged=true \ -v /var/run/docker.sock:/var/run/docker.sock \ -v /var/run/docker:/var/run/docker \ -v /usr/bin/docker:/usr/bin/docker \ --group-add=$(stat -c %g /var/run/docker.sock) \ -v /etc/localtime:/etc/localtime:ro \ jenkins docker psCentOS7123456789101112docker run --rm \ -it \ -u root \ -v /var/run/docker.sock:/var/run/docker.sock \ -v $(which docker):/usr/bin/docker:ro \ -v /usr/lib64/libsystemd-journal.so.0:/usr/lib/x86_64-linux-gnu/libsystemd-journal.so.0 \ -v /usr/lib64/libsystemd-id128.so.0:/usr/lib/x86_64-linux-gnu/libsystemd-id128.so.0 \ -v /usr/lib64/libdevmapper.so.1.02:/usr/lib/x86_64-linux-gnu/libdevmapper.so.1.02 \ -v /usr/lib64/libgcrypt.so.11:/usr/lib/x86_64-linux-gnu/libgcrypt.so.11 \ -v /usr/lib64/libdw.so.1:/usr/lib/x86_64-linux-gnu/libdw.so.1 \ -v /usr/lib64/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7 \ jenkins docker ps]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker in docker</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash快捷键]]></title>
    <url>%2F2017%2F03%2F13%2Fbash-shortcuts%2F</url>
    <content type="text"><![CDATA[Linux 终端常用快捷键移动光标ctrl+b: 前移一个字符(backward)ctrl+f: 后移一个字符(forward)alt+b: 前移一个单词alt+f: 后移一个单词ctrl+a: 移到行首（a是首字母）ctrl+e: 移到行尾（end）ctrl+x: 行首到当前光标替换编辑命令alt+.: 粘帖最后一次命令最后的参数（通常用于mkdir long-long-dir后, cd配合着alt+.）alt+d: 删除当前光标到临近右边单词开始(delete)ctrl+w: 删除当前光标到临近左边单词结束(word)ctrl+h: 删除光标前一个字符（相当于backspace）ctrl+d: 删除光标后一个字符（相当于delete）ctrl+u: 删除光标左边所有ctrl+k: 删除光标右边所有ctrl+l: 清屏ctrl+shift+c: 复制（相当于鼠标左键拖拽）ctrl+shift+v: 粘贴（相当于鼠标中键）其它ctrl+n: 下一条命令ctrl+p: 上一条命令alt+n: 下一条命令（例如输入ls, 然后按’alt+n’, 就会找到历史记录下的ls命令）alt+p: 上一条命令（跟alt+n相似）shift+PageUp: 向上翻页shift+PageDown: 向下翻页ctrl+r: 进入历史查找命令记录， 输入关键字。 多次按返回下一个匹配项zshd: 列出以前的打开的命令j: jump到以前某个目录，模糊匹配Vim移动光标b: 向前移动一个单词w: 向后移动一个单词删除dw: 从当前光标开始删除到下一个单词头de: 从当前光标开始删除到单词尾带注释粘贴1:set paste然后再粘贴参考CSDN]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>bash</tag>
        <tag>shortcuts</tag>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openjdk阅读笔记]]></title>
    <url>%2F2017%2F02%2F16%2F2017-02-17-openjdk-read-note%2F</url>
    <content type="text"><![CDATA[openjdk目录结构123456789101112131415161718192021222324252627282930313233343536373839├─agent Serviceability Agent的客户端实现├─make 用来build出HotSpot的各种配置文件├─src HotSpot VM的源代码│ ├─cpu CPU相关代码（汇编器、模板解释器、ad文件、部分runtime函数在这里实现）│ ├─os 操作系相关代码│ ├─os_cpu 操作系统+CPU的组合相关的代码│ └─share 平台无关的共通代码│ ├─tools 工具│ │ ├─hsdis 反汇编插件│ │ ├─IdealGraphVisualizer 将server编译器的中间代码可视化的工具│ │ ├─launcher 启动程序“java”│ │ ├─LogCompilation 将-XX:+LogCompilation输出的日志（hotspot.log）整理成更容易阅读的格式的工具│ │ └─ProjectCreator 生成Visual Studio的project文件的工具│ └─vm HotSpot VM的核心代码│ ├─adlc 平台描述文件（上面的cpu或os_cpu里的*.ad文件）的编译器│ ├─asm 汇编器接口│ ├─c1 client编译器（又称“C1”）│ ├─ci 动态编译器的公共服务/从动态编译器到VM的接口│ ├─classfile 类文件的处理（包括类加载和系统符号表等）│ ├─code 动态生成的代码的管理│ ├─compiler 从VM调用动态编译器的接口│ ├─gc_implementation GC的实现│ │ ├─concurrentMarkSweep Concurrent Mark Sweep GC的实现│ │ ├─g1 Garbage-First GC的实现（不使用老的分代式GC框架）│ │ ├─parallelScavenge ParallelScavenge GC的实现（server VM默认，不使用老的分代式GC框架）│ │ ├─parNew ParNew GC的实现│ │ └─shared GC的共通实现│ ├─gc_interface GC的接口│ ├─interpreter 解释器，包括“模板解释器”（官方版在用）和“C++解释器”（官方版不在用）│ ├─libadt 一些抽象数据结构│ ├─memory 内存管理相关（老的分代式GC框架也在这里）│ ├─oops HotSpot VM的对象系统的实现│ ├─opto server编译器（又称“C2”或“Opto”）│ ├─prims HotSpot VM的对外接口，包括部分标准库的native部分和JVMTI实现│ ├─runtime 运行时支持库（包括线程管理、编译器调度、锁、反射等）│ ├─services 主要是用来支持JMX之类的管理功能的接口│ ├─shark 基于LLVM的JIT编译器（官方版里没有使用）│ └─utilities 一些基本的工具类└─test 单元测试]]></content>
      <tags>
        <tag>java</tag>
        <tag>openjdk</tag>
        <tag>hotspot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里巴巴Java开发手册]]></title>
    <url>%2F2017%2F02%2F13%2Fali-java-specification%2F</url>
    <content type="text"><![CDATA[一 编程规约(一) 命名规约(二) 常量定义(三) 格式规约(四) OOP规约(五) 集合处理(六) 并发处理(七) 控制语句(八) 注释规约(九) 其它二 异常日志(一) 异常处理(二) 日志规约三 MySQL规约(一) 建表规约(二) 索引规约(三) SQL规约(四) ORM规约四 工程规约(一) 应用分层(二) 二方库规约(三) 服务器规约五 安全规约一 编程规约(一)命名规约【强制】 代码中的命名均不能以下划线或美元符号开始，也不能以下划线或美元符号结束。反例： name / __name / $Object / name / name$ / Object$【强制】 代码中的命名严禁使用拼音与英文混合的方式，更不允许直接使用中文的方式。说明：正确的英文拼写和语法可以让阅读者易于理解，避免歧义。注意，即使纯拼音命名方式也要避免采用。反例： DaZhePromotion [打折] / getPingfenByName() [评分] / int 某变量 = 3正例： alibaba / taobao / youku / hangzhou 等国际通用的名称，可视同英文。【强制】类名使用 UpperCamelCase 风格，必须遵从驼峰形式，但以下情形例外：（领域模型的相关命名）DO / BO / DTO / VO 等。正例：MarcoPolo / UserDO / XmlService / TcpUdpDeal / TaPromotion反例：macroPolo / UserDo / XMLService / TCPUDPDeal / TAPromotion【强制】方法名、参数名、成员变量、局部变量都统一使用 lowerCamelCase 风格，必须遵从驼峰形式。正例： localValue / getHttpMessage() / inputUserId【强制】常量命名全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。正例： MAX_STOCK_COUNT反例： MAX_COUNT【强制】抽象类命名使用 Abstract 或 Base 开头；异常类命名使用 Exception 结尾；测试类命名以它要测试的类的名称开始，以 Test 结尾。【强制】中括号是数组类型的一部分，数组定义如下：String[] args;反例：使用 String args[]的方式来定义。【强制】POJO 类中布尔类型的变量，都不要加 is，否则部分框架解析会引起序列化错误。反例：定义为基本数据类型 boolean isSuccess；的属性，它的方法也是 isSuccess()，RPC框架在反向解析的时候，“以为”对应的属性名称是 success，导致属性获取不到，进而抛出异常。【强制】包名统一使用小写，点分隔符之间有且仅有一个自然语义的英语单词。包名统一使用单数形式，但是类名如果有复数含义，类名可以使用复数形式。正例： 应用工具类包名为 com.alibaba.open.util、类名为 MessageUtils（此规则参考spring 的框架结构）【强制】杜绝完全不规范的缩写，避免望文不知义。反例： AbstractClass“缩写”命名成 AbsClass；condition“缩写”命名成 condi，此类随意缩写严重降低了代码的可阅读性。【推荐】如果使用到了设计模式，建议在类名中体现出具体模式。说明：将设计模式体现在名字中，有利于阅读者快速理解架构设计思想。正例：public class OrderFactory;public class LoginProxy;public class ResourceObserver;【推荐】接口类中的方法和属性不要加任何修饰符号（public 也不要加），保持代码的简洁性，并加上有效的 Javadoc 注释。尽量不要在接口里定义变量，如果一定要定义变量，肯定是与接口方法相关，并且是整个应用的基础常量。正例：接口方法签名：void f();接口基础常量表示：String COMPANY = “alibaba”;反例：接口方法定义：public abstract void f();说明：JDK8 中接口允许有默认实现，那么这个 default 方法，是对所有实现类都有价值的默认实现。接口和实现类的命名有两套规则：1）【强制】对于 Service 和 DAO 类，基于 SOA 的理念，暴露出来的服务一定是接口，内部的实现类用 Impl 的后缀与接口区别。正例：CacheServiceImpl 实现 CacheService 接口。2） 【推荐】 如果是形容能力的接口名称，取对应的形容词做接口名（通常是–able 的形式）。正例：AbstractTranslator 实现 Translatable。【参考】枚举类名建议带上 Enum 后缀，枚举成员名称需要全大写，单词间用下划线隔开。说明：枚举其实就是特殊的常量类，且构造方法被默认强制是私有。正例：枚举名字：DealStatusEnum，成员名称：SUCCESS / UNKOWN_REASON。【参考】各层命名规约：A) Service/DAO 层方法命名规约1） 获取单个对象的方法用 get 做前缀。2） 获取多个对象的方法用 list 做前缀。3） 获取统计值的方法用 count 做前缀。4） 插入的方法用 save（推荐）或 insert 做前缀。5） 删除的方法用 remove（推荐）或 delete 做前缀。6） 修改的方法用 update 做前缀。B) 领域模型命名规约1） 数据对象：xxxDO，xxx 即为数据表名。2） 数据传输对象：xxxDTO，xxx 为业务领域相关的名称。3） 展示对象：xxxVO，xxx 一般为网页名称。4） POJO 是 DO/DTO/BO/VO 的统称，禁止命名成 xxxPOJO。(二)常量定义【强制】不允许出现任何魔法值（即未经定义的常量）直接出现在代码中。反例： String key=”Id#taobao_”+tradeId；cache.put(key, value); 【强制】long 或者 Long 初始赋值时，必须使用大写的 L，不能是小写的 l，小写容易跟数字1 混淆，造成误解。说明：Long a = 2l; 写的是数字的 21，还是 Long 型的 2?【推荐】不要使用一个常量类维护所有常量，应该按常量功能进行归类，分开维护。如：缓存相关的常量放在类：CacheConsts 下；系统配置相关的常量放在类：ConfigConsts 下。说明：大而全的常量类，非得使用查找功能才能定位到修改的常量，不利于理解和维护。【推荐】常量的复用层次有五层：跨应用共享常量、应用内共享常量、子工程内共享常量、包内共享常量、类内共享常量。1） 跨应用共享常量：放置在二方库中，通常是 client.jar 中的 constant 目录下。2） 应用内共享常量：放置在一方库的 modules 中的 constant 目录下。反例：易懂变量也要统一定义成应用内共享常量，两位攻城师在两个类中分别定义了表示“是”的变量： 类 A 中：public static final String YES = “yes”;类 B 中：public static final String YES = “y”;A.YES.equals(B.YES)，预期是 true，但实际返回为 false，导致产生线上问题。3） 子工程内部共享常量：即在当前子工程的 constant 目录下。4） 包内共享常量：即在当前包下单独的 constant 目录下。5） 类内共享常量：直接在类内部 private static final 定义。【推荐】如果变量值仅在一个范围内变化用 Enum 类。如果还带有名称之外的延伸属性，必须使用 Enum 类，下面正例中的数字就是延伸信息，表示星期几。正例：public Enum{ MONDAY(1), TUESDAY(2), WEDNESDAY(3), THURSDAY(4), FRIDAY(5), SATURDAY(6), SUNDAY(7);}(三)格式规约【强制】大括号的使用约定。如果是大括号内为空，则简洁地写成{}即可，不需要换行；如果是非空代码块则：1） 左大括号前不换行。2） 左大括号后换行。3） 右大括号前换行。4） 右大括号后还有 else 等代码则不换行；表示终止右大括号后必须换行。【强制】 左括号和后一个字符之间不出现空格；同样，右括号和前一个字符之间也不出现空格。详见第 5 条下方正例提示。【强制】if/for/while/switch/do 等保留字与左右括号之间都必须加空格。【强制】任何运算符左右必须加一个空格。说明：运算符包括赋值运算符=、逻辑运算符&amp;&amp;、加减乘除符号、三目运行符等。【强制】缩进采用 4 个空格，禁止使用 tab 字符。说明：如果使用 tab 缩进，必须设置 1 个 tab 为 4 个空格。IDEA 设置 tab 为 4 个空格时，请勿勾选 Use tab character；而在 eclipse 中，必须勾选 insert spaces for tabs。正例： （涉及 1-5 点）12345678910111213141516171819public static void main(String[] args) &#123; // 缩进 4 个空格 String say = "hello"; // 运算符的左右必须有一个空格 int flag = 0; // 关键词 if 与括号之间必须有一个空格，括号内的 f 与左括号，0 与右括号不需要空格 if (flag == 0) &#123; System.out.println(say); &#125; // 左大括号前加空格且不换行；左大括号后换行 if (flag == 1) &#123; System.out.println("world"); // 右大括号前换行，右大括号后有 else，不用换行 &#125; else &#123; System.out.println("ok"); // 在右大括号后直接结束，则必须换行 &#125; &#125;【强制】单行字符数限制不超过 120 个，超出需要换行，换行时遵循如下原则：1）第二行相对第一行缩进 4 个空格，从第三行开始，不再继续缩进，参考示例。2）运算符与下文一起换行。3）方法调用的点符号与下文一起换行。4）在多个参数超长，逗号后进行换行。5）在括号前不要换行，见反例。正例：123456StringBuffer sb = new StringBuffer(); //超过 120 个字符的情况下，换行缩进 4 个空格，并且方法前的点符号一起换行 sb.append("zi").append("xin")... .append("huang")... .append("huang")... .append("huang");反例：12345StringBuffer sb = new StringBuffer(); //超过 120 个字符的情况下，不要在括号前换行 sb.append("zi").append("xin")...append("huang"); //参数很多的方法调用可能超过 120 个字符，不要在逗号前换行 method(args1, args2, args3, ... , argsX);【强制】方法参数在定义和传入时，多个参数逗号后边必须加空格。正例：下例中实参的”a”,后边必须要有一个空格。method(“a”, “b”, “c”);【强制】IDE 的 text file encoding 设置为 UTF-8; IDE 中文件的换行符使用 Unix 格式，不要使用 windows 格式。【推荐】没有必要增加若干空格来使某一行的字符与上一行的相应字符对齐。正例：1234int a = 3; long b = 4L; float c = 5F; StringBuffer sb = new StringBuffer();说明：增加 sb 这个变量，如果需要对齐，则给 a、b、c 都要增加几个空格，在变量比较多的情况下，是一种累赘的事情。【推荐】方法体内的执行语句组、变量的定义语句组、不同的业务逻辑之间或者不同的语义之间插入一个空行。相同业务逻辑和语义之间不需要插入空行。说明：没有必要插入多行空格进行隔开。(四)OOP 规约【强制】避免通过一个类的对象引用访问此类的静态变量或静态方法，无谓增加编译器解析成本，直接用类名来访问即可。【强制】所有的覆写方法，必须加@Override 注解。反例：getObject()与 get0bject()的问题。一个是字母的 O，一个是数字的 0，加@Override可以准确判断是否覆盖成功。另外，如果在抽象类中对方法签名进行修改，其实现类会马上编译报错。【强制】相同参数类型，相同业务含义，才可以使用 Java 的可变参数，避免使用 Object。说明：可变参数必须放置在参数列表的最后。（提倡同学们尽量不用可变参数编程）正例：public User getUsers(String type, Integer… ids)【强制】对外暴露的接口签名，原则上不允许修改方法签名，避免对接口调用方产生影响。接口过时必须加@Deprecated 注解，并清晰地说明采用的新接口或者新服务是什么。【强制】不能使用过时的类或方法。说明：java.net.URLDecoder 中的方法 decode(String encodeStr) 这个方法已经过时，应该使用双参数 decode(String source, String encode)。接口提供方既然明确是过时接口，那么有义务同时提供新的接口；作为调用方来说，有义务去考证过时方法的新实现是什么。【强制】Object 的 equals 方法容易抛空指针异常，应使用常量或确定有值的对象来调用equals。正例： “test”.equals(object);反例： object.equals(“test”);说明：推荐使用 java.util.Objects#equals （JDK7 引入的工具类）【强制】所有的相同类型的包装类对象之间值的比较，全部使用 equals 方法比较。说明：对于 Integer var=?在-128 至 127 之间的赋值，Integer 对象是在IntegerCache.cache 产生，会复用已有对象，这个区间内的 Integer 值可以直接使用==进行判断，但是这个区间之外的所有数据，都会在堆上产生，并不会复用已有对象，这是一个大坑，推荐使用 equals 方法进行判断。【强制】关于基本数据类型与包装数据类型的使用标准如下：1） 所有的 POJO 类属性必须使用包装数据类型。2） RPC 方法的返回值和参数必须使用包装数据类型。3） 所有的局部变量【推荐】使用基本数据类型。说明：POJO 类属性没有初值是提醒使用者在需要使用时，必须自己显式地进行赋值，任何NPE 问题，或者入库检查，都由使用者来保证。正例：数据库的查询结果可能是 null，因为自动拆箱，用基本数据类型接收有 NPE 风险。反例：比如显示成交总额涨跌情况，即正负 x%，x 为基本数据类型，调用的 RPC 服务，调用不成功时，返回的是默认值，页面显示：0%，这是不合理的，应该显示成中划线-。所以包装数据类型的 null 值，能够表示额外的信息，如：远程调用失败，异常退出。【强制】定义 DO/DTO/VO 等 POJO 类时，不要设定任何属性默认值。反例：POJO 类的 gmtCreate 默认值为 new Date();但是这个属性在数据提取时并没有置入具体值，在更新其它字段时又附带更新了此字段，导致创建时间被修改成当前时间。【强制】序列化类新增属性时，请不要修改 serialVersionUID 字段，避免反序列失败；如果完全不兼容升级，避免反序列化混乱，那么请修改 serialVersionUID 值。说明：注意 serialVersionUID 不一致会抛出序列化运行时异常。【强制】构造方法里面禁止加入任何业务逻辑，如果有初始化逻辑，请放在 init 方法中。【强制】POJO 类必须写 toString 方法。使用 IDE 的中工具：source&gt; generate toString时，如果继承了另一个 POJO 类，注意在前面加一下 super.toString。说明：在方法执行抛出异常时，可以直接调用 POJO 的 toString()方法打印其属性值，便于排查问题。【推荐】使用索引访问用 String 的 split 方法得到的数组时，需做最后一个分隔符后有无内容的检查，否则会有抛 IndexOutOfBoundsException 的风险。说明：1234String str = "a,b,c,,"; String[] ary = str.split(","); //预期大于 3，结果是 3 System.out.println(ary.length);【推荐】当一个类有多个构造方法，或者多个同名方法，这些方法应该按顺序放置在一起，便于阅读。【推荐】 类内方法定义顺序依次是：公有方法或保护方法 &gt; 私有方法 &gt; getter/setter方法。说明：公有方法是类的调用者和维护者最关心的方法，首屏展示最好；保护方法虽然只是子类关心，也可能是“模板设计模式”下的核心方法；而私有方法外部一般不需要特别关心，是一个黑盒实现；因为方法信息价值较低，所有 Service 和 DAO 的 getter/setter 方法放在类体最后。【推荐】setter 方法中，参数名称与类成员变量名称一致，this.成员名=参数名。在getter/setter 方法中，尽量不要增加业务逻辑，增加排查问题的难度。反例：1234567public Integer getData()&#123; if(true) &#123; return data + 100; &#125; else &#123; return data - 100; &#125; &#125;【推荐】循环体内，字符串的联接方式，使用 StringBuilder 的 append 方法进行扩展。反例：1234String str = "start"; for(int i=0; i&lt;100; i++)&#123; str = str + "hello"; &#125;说明：反编译出的字节码文件显示每次循环都会 new 出一个 StringBuilder 对象，然后进行append 操作，最后通过 toString 方法返回 String 对象，造成内存资源浪费。【推荐】final 可提高程序响应效率，声明成 final 的情况：1） 不需要重新赋值的变量，包括类属性、局部变量。2） 对象参数前加 final，表示不允许修改引用的指向。3） 类方法确定不允许被重写。【推荐】慎用 Object 的 clone 方法来拷贝对象。说明：对象的 clone 方法默认是浅拷贝，若想实现深拷贝需要重写 clone 方法实现属性对象的拷贝。【推荐】类成员与方法访问控制从严：1） 如果不允许外部直接通过 new 来创建对象，那么构造方法必须是 private。2） 工具类不允许有 public 或 default 构造方法。3） 类非 static 成员变量并且与子类共享，必须是 protected。4） 类非 static 成员变量并且仅在本类使用，必须是 private。5） 类 static 成员变量如果仅在本类使用，必须是 private。6） 若是 static 成员变量，必须考虑是否为 final。7） 类成员方法只供类内部调用，必须是 private。8） 类成员方法只对继承类公开，那么限制为 protected。说明：任何类、方法、参数、变量，严控访问范围。过宽泛的访问范围，不利于模块解耦。思考：如果是一个 private 的方法，想删除就删除，可是一个 public 的 Service 方法，或者一个 public 的成员变量，删除一下，不得手心冒点汗吗？变量像自己的小孩，尽量在自己的视线内，变量作用域太大，如果无限制的到处跑，那么你会担心的。(五)集合处理【强制】关于 hashCode 和 equals 的处理，遵循如下规则：1） 只要重写 equals，就必须重写 hashCode。2） 因为 Set 存储的是不重复的对象，依据 hashCode 和 equals 进行判断，所以 Set 存储的对象必须重写这两个方法。3） 如果自定义对象做为 Map 的键，那么必须重写 hashCode 和 equals。正例：String 重写了 hashCode 和 equals 方法，所以我们可以非常愉快地使用 String 对象作为 key 来使用。【强制】 ArrayList的subList结果不可强转成ArrayList，否则会抛出ClassCastException异常：java.util.RandomAccessSubList cannot be cast to java.util.ArrayList ;说明：subList 返回的是 ArrayList 的内部类 SubList，并不是 ArrayList ，而是 ArrayList 的一个视图，对于 SubList 子列表的所有操作最终会反映到原列表上。【强制】 在 subList 场景中，高度注意对原集合元素个数的修改，会导致子列表的遍历、增加、删除均产生 ConcurrentModificationException 异常。【强制】使用集合转数组的方法，必须使用集合的 toArray(T[] array)，传入的是类型完全一样的数组，大小就是 list.size()。反例：直接使用 toArray 无参方法存在问题，此方法返回值只能是 Object[]类，若强转其它类型数组将出现 ClassCastException 错误。正例：12345List&lt;String&gt; list = new ArrayList&lt;String&gt;(2); list.add("guan"); list.add("bao"); String[] array = new String[list.size()]; array = list.toArray(array);说明：使用 toArray 带参方法，入参分配的数组空间不够大时，toArray 方法内部将重新分配内存空间，并返回新数组地址；如果数组元素大于实际所需，下标为[ list.size() ]的数组元素将被置为 null，其它数组元素保持原值，因此最好将方法入参数组大小定义与集合元素个数一致。【强制】使用工具类 Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。说明：asList 的返回对象是一个 Arrays 内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配器模式，只是转换接口，后台的数据仍是数组。String[] str = new String[] { “a”, “b” };List list = Arrays.asList(str);第一种情况：list.add(“c”); 运行时异常。第二种情况：str[0]= “gujin”; 那么 list.get(0)也会随之修改。【强制】泛型通配符&lt;? extends T&gt;来接收返回的数据，此写法的泛型集合不能使用 add 方法。说明：苹果装箱后返回一个&lt;? extends Fruits&gt;对象，此对象就不能往里加任何水果，包括苹果。【强制】不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator方式，如果并发操作，需要对 Iterator 对象加锁。反例：12345678List&lt;String&gt; a = new ArrayList&lt;String&gt;(); a.add("1"); a.add("2"); for (String temp : a) &#123; if("1".equals(temp))&#123; a.remove(temp); &#125; &#125;说明：以上代码的执行结果肯定会出乎大家的意料，那么试一下把“1”换成“2”，会是同样的结果吗？正例：1234567Iterator&lt;String&gt; it = a.iterator(); while(it.hasNext())&#123; String temp = it.next(); if(删除元素的条件)&#123; it.remove(); &#125; &#125;【强制】 在 JDK7 版本以上，Comparator 要满足自反性，传递性，对称性，不然 Arrays.sort，Collections.sort 会报 IllegalArgumentException 异常。说明：1） 自反性：x，y 的比较结果和 y，x 的比较结果相反。2） 传递性：x&gt;y,y&gt;z,则 x&gt;z。3） 对称性：x=y,则 x,z 比较结果和 y，z 比较结果相同。反例：下例中没有处理相等的情况，实际使用中可能会出现异常：123456new Comparator&lt;Student&gt;() &#123; @Override public int compare(Student o1, Student o2) &#123; return o1.getId() &gt; o2.getId() ? 1 : -1; &#125; &#125;【推荐】集合初始化时，尽量指定集合初始值大小。说明：ArrayList 尽量使用 ArrayList(int initialCapacity) 初始化。【推荐】使用 entrySet 遍历 Map 类集合 KV，而不是 keySet 方式进行遍历。说明：keySet 其实是遍历了 2 次，一次是转为 Iterator 对象，另一次是从 hashMap 中取出key 所对应的 value。而 entrySet 只是遍历了一次就把 key 和 value 都放到了 entry 中，效率更高。如果是 JDK8，使用 Map.foreach 方法。正例：values()返回的是 V 值集合，是一个 list 集合对象；keySet()返回的是 K 值集合，是一个 Set 集合对象；entrySet()返回的是 K-V 值组合集合。【推荐】高度注意 Map 类集合 K/V 能不能存储 null 值的情况，如下表格：集合类KeyValueSuper说明Hashtable不允许为 null不允许为 nullDictionary线程安全ConcurrentHashMap不允许为 null不允许为 nullAbstractMap分段锁技术TreeMap不允许为 null允许为 nullAbstractMap线程不安全HashMap允许为 null允许为 nullAbstractMap线程不安全反例： 由于 HashMap 的干扰，很多人认为 ConcurrentHashMap 是可以置入 null 值，注意存储null 值时会抛出 NPE 异常。【参考】合理利用好集合的有序性(sort)和稳定性(order)，避免集合的无序性(unsort)和不稳定性(unorder)带来的负面影响。说明：有序性是指遍历的结果是按某种比较规则依次排列的。稳定性指集合每次遍历的元素次序是一定的。如：ArrayList 是 order/unsort；HashMap 是 unorder/unsort；TreeSet 是order/sort。【参考】利用 Set 元素唯一的特性，可以快速对一个集合进行去重操作，避免使用 List 的contains 方法进行遍历、对比、去重操作。(六)并发处理【强制】获取单例对象需要保证线程安全，其中的方法也要保证线程安全。说明：资源驱动类、工具类、单例工厂类都需要注意。【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。正例：123456public class TimerTaskThread extends Thread &#123; public TimerTaskThread()&#123; super.setName("TimerTaskThread"); ... &#125;&#125;【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。说明：使用线程池的好处是减少在创建和销毁线程上所花的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明：Executors 返回的线程池对象的弊端如下：1）FixedThreadPool 和 SingleThreadPool:允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。2）CachedThreadPool 和 ScheduledThreadPool:允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。【强制】SimpleDateFormat 是线程不安全的类，一般不要定义为 static 变量，如果定义为static，必须加锁，或者使用 DateUtils 工具类。正例：注意线程安全，使用 DateUtils。亦推荐如下处理：123456private static final ThreadLocal&lt;DateFormat&gt; df = new ThreadLocal&lt;DateFormat&gt;() &#123; @Override protected DateFormat initialValue() &#123; return new SimpleDateFormat("yyyy-MM-dd"); &#125;&#125;;说明：如果是 JDK8 的应用，可以使用 Instant 代替 Date，LocalDateTime 代替 Calendar，DateTimeFormatter代替 Simpledateformatter，官方给出的解释：simple beautiful strong immutable thread-safe。【强制】高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。【强制】对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造成死锁。说明：线程一需要对表 A、B、C 依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序也必须是 A、B、C，否则可能出现死锁。【强制】并发修改同一记录时，避免更新丢失，要么在应用层加锁，要么在缓存加锁，要么在数据库层使用乐观锁，使用 version 作为更新依据。说明：如果每次访问冲突概率小于 20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于 3 次。【强制】多线程并行处理定时任务时，Timer 运行多个 TimeTask 时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用 ScheduledExecutorService 则没有这个问题。【推荐】使用 CountDownLatch 进行异步转同步操作，每个线程退出前必须调用 countDown方法，线程执行代码注意 catch 异常，确保 countDown 方法可以执行，避免主线程无法执行至 await 方法，直到超时才返回结果。说明：注意，子线程抛出异常堆栈，不能在主线程 try-catch 到。【推荐】避免 Random 实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一seed 导致的性能下降。说明：Random 实例包括 java.util.Random 的实例或者 Math.random()实例。正例：在 JDK7 之后，可以直接使用 API ThreadLocalRandom，在 JDK7 之前，可以做到每个线程一个实例。【推荐】通过双重检查锁（double-checked locking）（在并发场景）实现延迟初始化的优化问题隐患(可参考 The “Double-Checked Locking is Broken” Declaration),推荐问题解决方案中较为简单一种（适用于 JDK5 及以上版本），将目标属性声明为 volatile 型。反例：123456789101112class Foo &#123; private Helper helper = null; public Helper getHelper() &#123; if (helper == null) synchronized(this) &#123; if (helper == null) helper = new Helper(); &#125; return helper; &#125; // other functions and members... &#125;【参考】volatile 解决多线程内存不可见问题。对于一写多读，是可以解决变量同步问题，但是如果多写，同样无法解决线程安全问题。如果是 count++操作，使用如下类实现：12AtomicInteger count = new AtomicInteger(); count.addAndGet(1);如果是 JDK8，推荐使用 LongAdder 对象，比 AtomicLong 性能更好（减少乐观锁的重试次数）。【参考】 HashMap 在容量不够进行 resize 时由于高并发可能出现死链，导致 CPU 飙升，在开发过程中注意规避此风险。【参考】ThreadLocal 无法解决共享对象的更新问题，ThreadLocal 对象建议使用 static修饰。这个变量是针对一个线程内所有操作共有的，所以设置为静态变量，所有此类实例共享此静态变量 ，也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只要是这个线程内定义的)都可以操控这个变量。(七)控制语句【强制】在一个 switch 块内，每个 case 要么通过 break/return 等来终止，要么注释说明程序将继续执行到哪一个 case 为止；在一个 switch 块内，都必须包含一个 default 语句并且放在最后，即使它什么代码也没有。【强制】在 if/else/for/while/do 语句中必须使用大括号，即使只有一行代码，避免使用下面的形式：if (condition) statements;【推荐】推荐尽量少用 else， if-else 的方式可以改写成：12345if(condition)&#123; ... return obj; &#125; // 接着写 else 的业务逻辑代码;说明：如果非得使用 if()…else if()…else…方式表达逻辑，【强制】请勿超过 3 层，超过请使用状态设计模式。正例：逻辑上超过 3 层的 if-else 代码可以使用卫语句，或者状态模式来实现。【推荐】除常用方法（如 getXxx/isXxx）等外，不要在条件判断中执行其它复杂的语句，将复杂逻辑判断的结果赋值给一个有意义的布尔变量名，以提高可读性。说明：很多 if 语句内的逻辑相当复杂，阅读者需要分析条件表达式的最终结果，才能明确什么样的条件执行什么样的语句，那么，如果阅读者分析逻辑表达式错误呢？正例：123456789//伪代码如下 boolean existed = (file.open(fileName, "w") != null) &amp;&amp; (...) || (...); if (existed) &#123; ... &#125; 反例：if ((file.open(fileName, "w") != null) &amp;&amp; (...) || (...)) &#123; ...&#125;【推荐】循环体中的语句要考量性能，以下操作尽量移至循环体外处理，如定义对象、变量、获取数据库连接，进行不必要的 try-catch 操作（这个 try-catch 是否可以移至循环体外）。【推荐】接口入参保护，这种场景常见的是用于做批量操作的接口。【参考】方法中需要进行参数校验的场景：1） 调用频次低的方法。2） 执行时间开销很大的方法，参数校验时间几乎可以忽略不计，但如果因为参数错误导致中间执行回退，或者错误，那得不偿失。3） 需要极高稳定性和可用性的方法。4） 对外提供的开放接口，不管是 RPC/API/HTTP 接口。5） 敏感权限入口。【参考】方法中不需要参数校验的场景：1） 极有可能被循环调用的方法，不建议对参数进行校验。但在方法说明里必须注明外部参数检查。2） 底层的方法调用频度都比较高，一般不校验。毕竟是像纯净水过滤的最后一道，参数错误不太可能到底层才会暴露问题。一般 DAO 层与 Service 层都在同一个应用中，部署在同一台服务器中，所以 DAO 的参数校验，可以省略。3） 被声明成 private 只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参数已经做过检查或者肯定不会有问题，此时可以不校验参数。(八)注释规约【强制】类、类属性、类方法的注释必须使用 Javadoc 规范，使用/*内容/格式，不得使用//xxx 方式。说明：在 IDE 编辑窗口中，Javadoc 方式会提示相关注释，生成 Javadoc 可以正确输出相应注释；在 IDE 中，工程调用方法时，不进入方法即可悬浮提示方法、参数、返回值的意义，提高阅读效率。【强制】所有的抽象方法（包括接口中的方法）必须要用 Javadoc 注释、除了返回值、参数、异常说明外，还必须指出该方法做什么事情，实现什么功能。说明：对子类的实现要求，或者调用注意事项，请一并说明。【强制】所有的类都必须添加创建者信息。【强制】方法内部单行注释，在被注释语句上方另起一行，使用//注释。方法内部多行注释使用/ /注释，注意与代码对齐。【强制】所有的枚举类型字段必须要有注释，说明每个数据项的用途。【推荐】与其“半吊子”英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持英文原文即可。反例：“TCP 连接超时”解释成“传输控制协议连接超时”，理解反而费脑筋。【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑等的修改。说明：代码与注释更新不同步，就像路网与导航软件更新不同步一样，如果导航软件严重滞后，就失去了导航的意义。【参考】注释掉的代码尽量要配合说明，而不是简单的注释掉。说明：代码被注释掉有两种可能性：1）后续会恢复此段代码逻辑。2）永久不用。前者如果没有备注信息，难以知晓注释动机。后者建议直接删掉（代码仓库保存了历史代码）。【参考】对于注释的要求：第一、能够准确反应设计思想和代码逻辑；第二、能够描述业务含义，使别的程序员能够迅速了解到代码背后的信息。完全没有注释的大段代码对于阅读者形同天书，注释是给自己看的，即使隔很长时间，也能清晰理解当时的思路；注释也是给继任者看的，使其能够快速接替自己的工作。【参考】好的命名、代码结构是自解释的，注释力求精简准确、表达到位。避免出现注释的一个极端：过多过滥的注释，代码的逻辑一旦修改，修改注释是相当大的负担。反例：12// put elephant into fridge put(elephant, fridge);方法名put，加上两个有意义的变量名 elephant 和 fridge，已经说明了这是在干什么，语义清晰的代码不需要额外的注释。【参考】特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描，经常清理此类标记。线上故障有时候就是来源于这些标记处的代码。1） 待办事宜（TODO）:（ 标记人，标记时间，[预计处理时间]）表示需要实现，但目前还未实现的功能。这实际上是一个 Javadoc 的标签，目前的 Javadoc还没有实现，但已经被广泛使用。只能应用于类，接口和方法（因为它是一个 Javadoc 标签）。2） 错误，不能工作（FIXME）:（标记人，标记时间，[预计处理时间]）在注释中用 FIXME 标记某代码是错误的，而且不能工作，需要及时纠正的情况。(九)其它【强制】在使用正则表达式时，利用好其预编译功能，可以有效加快正则匹配速度。说明：不要在方法体内定义：Pattern pattern = Pattern.compile(规则);【强制】velocity 调用 POJO 类的属性时，建议直接使用属性名取值即可，模板引擎会自动按规范调用 POJO 的 getXxx()，如果是 boolean 基本数据类型变量（boolean 命名不需要加 is前缀），会自动调用 isXxx()方法。说明：注意如果是 Boolean 包装类对象，优先调用 getXxx()的方法。【强制】后台输送给页面的变量必须加$!{var}——中间的感叹号。说明：如果 var=null 或者不存在，那么${var}会直接显示在页面上。【强制】注意 Math.random() 这个方法返回是 double 类型，注意取值的范围 0≤x&lt;1（能够取到零值，注意除零异常），如果想获取整数类型的随机数，不要将 x 放大 10 的若干倍然后取整，直接使用 Random 对象的 nextInt 或者 nextLong 方法。【强制】获取当前毫秒数 System.currentTimeMillis(); 而不是 new Date().getTime();说明：如果想获取更加精确的纳秒级时间值，用 System.nanoTime()。在 JDK8 中，针对统计时间等场景，推荐使用 Instant 类。【推荐】尽量不要在 velocity 模板中加入变量声明、逻辑运算符，更不要在模板中加入任何复杂的逻辑。【推荐】任何数据结构的构造或初始化，都应指定大小，避免数据结构无限增长吃光内存。【推荐】对于“明确停止使用的代码和配置”，如方法、变量、类、配置文件、动态配置属性等要坚决从程序中清理出去，避免造成过多垃圾。二 异常日志(一)异常处理【强制】不要捕获 Java 类库中定义的继承自 RuntimeException 的运行时异常类，如：IndexOutOfBoundsException / NullPointerException，这类异常由程序员预检查来规避，保证程序健壮性。正例：if(obj != null) {…}反例：try { obj.method() } catch(NullPointerException e){…}【强制】异常不要用来做流程控制，条件控制，因为异常的处理效率比条件分支低。【强制】对大段代码进行 try-catch，这是不负责任的表现。catch 时请分清稳定代码和非稳定代码，稳定代码指的是无论如何不会出错的代码。对于非稳定代码的 catch 尽可能进行区分异常类型，再做对应的异常处理。【强制】捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的内容。【强制】有 try 块放到了事务代码中，catch 异常后，如果需要回滚事务，一定要注意手动回滚事务。【强制】finally 块必须对资源对象、流对象进行关闭，有异常也要做 try-catch。说明：如果 JDK7，可以使用 try-with-resources 方式。 7. 【强制】不能在 finally 块中使用 return，finally 块中的 return 返回后方法结束执行，不会再执行 try 块中的 return 语句。【强制】捕获异常与抛异常，必须是完全匹配，或者捕获异常是抛异常的父类。说明：如果预期对方抛的是绣球，实际接到的是铅球，就会产生意外情况。【推荐】方法的返回值可以为 null，不强制返回空集合，或者空对象等，必须添加注释充分说明什么情况下会返回 null 值。调用方需要进行 null 判断防止 NPE 问题。说明：本规约明确防止 NPE 是调用者的责任。即使被调用方法返回空集合或者空对象，对调用者来说，也并非高枕无忧，必须考虑到远程调用失败，运行时异常等场景返回 null 的情况。【推荐】防止 NPE，是程序员的基本修养，注意 NPE 产生的场景：1） 返回类型为包装数据类型，有可能是 null，返回 int 值时注意判空。反例：public int f(){ return Integer 对象}; 如果为 null，自动解箱抛 NPE。2） 数据库的查询结果可能为 null。3） 集合里的元素即使 isNotEmpty，取出的数据元素也可能为 null。4） 远程调用返回对象，一律要求进行 NPE 判断。5） 对于 Session 中获取的数据，建议 NPE 检查，避免空指针。6） 级联调用 obj.getA().getB().getC()；一连串调用，易产生 NPE。【推荐】在代码中使用“抛异常”还是“返回错误码”，对于公司外的 http/api 开放接口必须使用“错误码”；而应用内部推荐异常抛出；跨应用间 RPC 调用优先考虑使用 Result 方式，封装 isSuccess、“错误码”、“错误简短信息”。说明：关于 RPC 方法返回方式使用 Result 方式的理由：1）使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。2）如果不加栈信息，只是 new 自定义异常，加入自己的理解的 error message，对于调用端解决问题的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。【推荐】定义时区分 unchecked / checked 异常，避免直接使用 RuntimeException 抛出，更不允许抛出 Exception 或者 Throwable，应使用有业务含义的自定义异常。推荐业界已定义过的自定义异常，如：DAOException / ServiceException 等。【参考】避免出现重复的代码（Don’t Repeat Yourself），即 DRY 原则。说明：随意复制和粘贴代码，必然会导致代码的重复，在以后需要修改时，需要修改所有的副本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是共用模块。正例：一个类中有多个 public 方法，都需要进行数行相同的参数校验操作，这个时候请抽取：private boolean checkParam(DTO dto){…}(二)日志规约【强制】应用中不可直接使用日志系统（Log4j、Logback）中的 API，而应依赖使用日志框架SLF4J 中的 API，使用门面模式的日志框架，有利于维护和各个类的日志处理方式统一。123import org.slf4j.Logger; import org.slf4j.LoggerFactory; private static final Logger logger = LoggerFactory.getLogger(Abc.class);【强制】日志文件推荐至少保存 15 天，因为有些异常具备以“周”为频次发生的特点。【强制】应用中的扩展日志（如打点、临时监控、访问日志等）命名方式： appName_logType_logName.log。logType:日志类型，推荐分类有stats/desc/monitor/visit 等；logName:日志描述。这种命名的好处：通过文件名就可知道日志文件属于什么应用，什么类型，什么目的，也有利于归类查找。正例：mppserver 应用中单独监控时区转换异常，如：mppserver_monitor_timeZoneConvert.log说明：推荐对日志进行分类，错误日志和业务日志尽量分开存放，便于开发人员查看，也便于通过日志对系统进行及时监控。【强制】对 trace/debug/info 级别的日志输出，必须使用条件输出形式或者使用占位符的方式。说明：logger.debug(“Processing trade with id: “ + id + “ symbol: “ + symbol);如果日志级别是 warn，上述日志不会打印，但是会执行字符串拼接操作，如果 symbol 是对象，会执行 toString()方法，浪费了系统资源，执行了上述操作，最终日志却没有打印。正例：（条件）123if (logger.isDebugEnabled()) &#123; logger.debug("Processing trade with id: " + id + " symbol: " + symbol); &#125;正例：（占位符）1logger.debug("Processing trade with id: &#123;&#125; symbol : &#123;&#125; ", id, symbol);【强制】避免重复打印日志，浪费磁盘空间，务必在 log4j.xml 中设置 additivity=false。正例：【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么往上抛。正例：logger.error(各类参数或者对象 toString + “_” + e.getMessage(), e);【推荐】可以使用 warn 日志级别来记录用户输入参数错误的情况，避免用户投诉时，无所适从。注意日志输出的级别，error 级别只记录系统逻辑出错、异常等重要的错误信息。如非必要，请不要在此场景打出 error 级别。【推荐】谨慎地记录日志。生产环境禁止输出 debug 日志；有选择地输出 info 日志；如果使用 warn 来记录刚上线时的业务行为信息，一定要注意日志输出量的问题，避免把服务器磁盘撑爆，并记得及时删除这些观察日志。说明：大量地输出无效日志，不利于系统性能提升，也不利于快速定位错误点。记录日志时请思考：这些日志真的有人看吗？看到这条日志你能做什么？能不能给问题排查带来好处？三 MySQL规约(一)建表规约【强制】表达是与否概念的字段，必须使用 is_xxx 的方式命名，数据类型是 unsigned tinyint（ 1 表示是，0 表示否），此规则同样适用于 odps 建表。说明：任何字段如果为非负数，必须是 unsigned。【强制】表名、字段名必须使用小写字母或数字；禁止出现数字开头，禁止两个下划线中间只出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。正例：getter_admin，task_config，level3_name反例：GetterAdmin，taskConfig，level_3_name【强制】表名不使用复数名词。说明：表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于 DO 类名也是单数形式，符合表达习惯。【强制】禁用保留字，如 desc、range、match、delayed 等，请参考 MySQL 官方保留字。【强制】唯一索引名为 uk_字段名；普通索引名则为 idx_字段名。说明：uk_ 即 unique key；idx_ 即 index 的简称。【强制】小数类型为 decimal，禁止使用 float 和 double。说明：float 和 double 在存储的时候，存在精度损失的问题，很可能在值的比较时，得到不正确的结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数分开存储。【强制】如果存储的字符串长度几乎相等，使用 char 定长字符串类型。【强制】varchar 是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长度大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效率。【强制】表必备三字段：id, gmt_create, gmt_modified。说明：其中 id 必为主键，类型为 unsigned bigint、单表时自增、步长为 1。gmt_create, gmt_modified 的类型均为 date_time 类型。【推荐】表的命名最好是加上“业务名称_表的作用”。正例：tiger_task / tiger_reader / mpp_config【推荐】库名与应用名称尽量一致。【推荐】如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。【推荐】字段允许适当冗余，以提高性能，但是必须考虑数据同步的情况。冗余字段应遵循：1）不是频繁修改的字段。2）不是 varchar 超长字段，更不能是 text 字段。正例：商品类目名称使用频率高，字段长度短，名称基本一成不变，可在相关联的表中冗余存储类目名称，避免关联查询。【推荐】单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度。正例：人的年龄用 unsigned tinyint（表示范围 0-255，人的寿命不会超过 255 岁）；海龟就必须是 smallint，但如果是太阳的年龄，就必须是 int；如果是所有恒星的年龄都加起来，那么就必须使用 bigint。(二)索引规约【强制】业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。说明：不要以为唯一索引影响了 insert 速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，即使在应用层做了非常完善的校验和控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。【强制】 超过三个表禁止 join。需要 join 的字段，数据类型保持绝对一致；多表关联查询时，保证被关联的字段需要有索引。说明：即使双表 join 也要注意表索引、SQL 性能。【强制】在 varchar 字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度。说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达 90%以上，可以使用 count(distinct left(列名, 索引长度))/count(*)的区分度来确定。【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。说明：索引文件具有 B-Tree 的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。【推荐】如果有 order by 的场景，请注意利用索引的有序性。order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，避免出现 file_sort 的情况，影响查询性能。正例：where a=? and b=? order by c; 索引：a_b_c反例：索引中有范围查找，那么索引有序性无法利用，如：WHERE a&gt;10 ORDER BY b; 索引a_b 无法排序。【推荐】利用覆盖索引来进行查询操作，来避免回表操作。说明：如果一本书需要知道第 11 章是什么标题，会翻开第 11 章对应的那一页吗？目录浏览一下就好，这个目录就是起到覆盖索引的作用。正例：能够建立索引的种类：主键索引、唯一索引、普通索引，而覆盖索引是一种查询的一种效果，用 explain 的结果，extra 列会出现：using index。【推荐】利用延迟关联或者子查询优化超多分页场景。说明：MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前 offset 行，返回N 行，那当 offset 特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行 SQL 改写。正例：先快速定位需要获取的 id 段，然后再关联：1SELECT a.* FROM 表 1 a, (select id from 表 1 where 条件 LIMIT 100000,20 ) b where a.id=b.id【推荐】 SQL 性能优化的目标：至少要达到 range 级别，要求是 ref 级别，如果可以是 consts最好。说明：1）consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。2）ref 指的是使用普通的索引（normal index）。3）range 对索引进行范围检索。反例：explain 表的结果，type=index，索引物理文件全扫描，速度非常慢，这个 index 级别比较 range 还低，与全表扫描是小巫见大巫。【推荐】建组合索引的时候，区分度最高的在最左边。正例：如果 where a=? and b=? ，a 列的几乎接近于唯一值，那么只需要单建 idx_a 索引即可。说明：存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。如：where a&gt;? and b=? 那么即使 a 的区分度更高，也必须把 b 放在索引的最前列。【参考】创建索引时避免有如下极端误解：1）误认为一个查询就需要建一个索引。2）误认为索引会消耗空间、严重拖慢更新和新增速度。3）误认为唯一索引一律需要在应用层通过“先查后插”方式解决。(三)SQL 规约【强制】不要使用 count(列名)或 count(常量)来替代 count()，count()就是 SQL92 定义的标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。说明：count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。【强制】count(distinct col) 计算该列除 NULL 之外的不重复数量。注意 count(distinct col1, col2) 如果其中一列全为 NULL，那么即使另一列有不同的值，也返回为 0。【强制】当某一列的值全是 NULL 时，count(col)的返回结果为 0，但 sum(col)的返回结果为NULL，因此使用 sum()时需注意 NPE 问题。正例：可以使用如下方式来避免 sum 的 NPE 问题：SELECT IF(ISNULL(SUM(g)),0,SUM(g)) FROM table;【强制】使用 ISNULL()来判断是否为 NULL 值。注意：NULL 与任何值的直接比较都为 NULL。说明：1） NULL&lt;&gt;NULL 的返回结果是 NULL，而不是 false。2） NULL=NULL 的返回结果是 NULL，而不是 true。3） NULL&lt;&gt;1 的返回结果是 NULL，而不是 true。【强制】 在代码中写分页查询逻辑时，若 count 为 0 应直接返回，避免执行后面的分页语句。【强制】不得使用外键与级联，一切外键概念必须在应用层解决。说明：（概念解释）学生表中的 student_id 是主键，那么成绩表中的 student_id 则为外键。 如果更新学生表中的 student_id，同时触发成绩表中的 student_id 更新，则为级联更新。外键与级联更新适用于单机低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库的插入速度。【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。【强制】数据订正时，删除和修改记录时，要先 select，避免出现误删除，确认无误才能执行更新语句。【推荐】in 操作能避免则避免，若实在避免不了，需要仔细评估 in 后边的集合元素数量，控制在 1000 个之内。【参考】如果有全球化需要，所有的字符存储与表示，均以 utf-8 编码，那么字符计数方法注意：说明：SELECT LENGTH(“轻松工作”)； 返回为 12SELECT CHARACTER_LENGTH(“轻松工作”)； 返回为 4如果要使用表情，那么使用 utfmb4 来进行存储，注意它与 utf-8 编码的区别。【参考】 TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但 TRUNCATE无事务且不触发 trigger，有可能造成事故，故不建议在开发代码中使用此语句。说明：TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同。(四)ORM 规约【强制】在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明。说明：1）增加查询分析器解析成本。2）增减字段容易与 resultMap 配置不一致。【强制】POJO 类的 boolean 属性不能加 is，而数据库字段必须加 is_，要求在 resultMap 中进行字段与属性之间的映射。说明：参见定义 POJO 类以及数据库字段定义规定，在 sql.xml 增加映射，是必须的。【强制】不要用 resultClass 当返回参数，即使所有类属性名与数据库字段一一对应，也需要定义；反过来，每一个表也必然有一个与之对应。说明：配置映射关系，使字段与 DO 类解耦，方便维护。【强制】xml 配置中参数注意使用：#{}，#param# 不要使用${} 此种方式容易出现 SQL 注入。【强制】iBATIS 自带的 queryForList(String statementName,int start,int size)不推荐使用。说明： 其实现方式是在数据库取到 statementName对应的SQL语句的所有记录，再通过 subList取 start,size 的子集合，线上因为这个原因曾经出现过 OOM。? 正例：在 sqlmap.xml 中引入 #start#, #size#123Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); map.put("start", start); map.put("size", size);【强制】不允许直接拿 HashMap 与 Hashtable 作为查询结果集的输出。【强制】更新数据表记录时，必须同时更新记录对应的 gmt_modified 字段值为当前时间。【推荐】不要写一个大而全的数据更新接口，传入为 POJO 类，不管是不是自己的目标更新字段，都进行 update table set c1=value1,c2=value2,c3=value3; 这是不对的。执行 SQL时，尽量不要更新无改动的字段，一是易出错；二是效率低；三是 binlog 增加存储。【参考】@Transactional 事务不要滥用。事务会影响数据库的 QPS，另外使用事务的地方需要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。【参考】中的 compareValue 是与属性值对比的常量，一般是数字，表示相等时带上此条件；表示不为空且不为 null 时执行；表示不为 null 值时执行。四 工程规约(一)应用分层【推荐】图中默认上层依赖于下层，箭头关系表示可直接依赖，如：开放接口层可以依赖于Web 层，也可以直接依赖于 Service 层，依此类推：开放接口层：可直接封装 Service 接口暴露成 RPC 接口；通过 Web 封装成 http 接口；网关控制层等。终端显示层：各个端的模板渲染并执行显示层。当前主要是 velocity 渲染，JS 渲染，JSP 渲染，移动端展示层等。Web 层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。Service 层：相对具体的业务逻辑服务层。Manager 层：通用业务处理层，它有如下特征：1） 对第三方平台封装的层，预处理返回结果及转化异常信息；2） 对 Service 层通用能力的下沉，如缓存方案、中间件通用处理；3） 与 DAO 层交互，对 DAO 的业务通用能力的封装。DAO 层：数据访问层，与底层 MySQL、Oracle、Hbase 进行数据交互。外部接口或第三方平台：包括其它部门 RPC 开放接口，基础平台，其它公司的 HTTP 接口。【参考】 （分层异常处理规约）在 DAO 层，产生的异常类型有很多，无法用细粒度异常进行catch，使用 catch(Exception e)方式，并 throw new DAOException(e)，不需要打印日志，因为日志在 Manager/Service 层一定需要捕获并打到日志文件中去，如果同台服务器再打日志，浪费性能和存储。在 Service 层出现异常时，必须记录日志信息到磁盘，尽可能带上参数信息，相当于保护案发现场。如果 Manager 层与 Service 同机部署，日志方式与 DAO 层处理一致，如果是单独部署，则采用与 Service 一致的处理方式。Web 层绝不应该继续往上抛异常， 因为已经处于顶层，无继续处理异常的方式，如果意识到这个异常将导致页面无法正常渲染，那么就应该直接跳转到友好错误页面，尽量加上友好的错误提示信息。开放接口层要将异常处理成错误码和错误信息方式返回。【参考】分层领域模型规约：DO（Data Object）：与数据库表结构一一对应，通过 DAO 层向上传输数据源对象。DTO（Data Transfer Object）：数据传输对象，Service 和 Manager 向外传输的对象。BO（Business Object）：业务对象。可以由 Service 层输出的封装业务逻辑的对象。QUERY：数据查询对象，各层接收上层的查询请求。注：超过 2 个参数的查询封装，禁止使用 Map 类来传输。VO（View Object）：显示层对象，通常是 Web 向模板渲染引擎层传输的对象。(二)二方库规约【强制】定义 GAV 遵从以下规则：1） GroupID 格式：com.{公司/BU }.业务线.[子业务线]，最多 4 级。说明：{公司/BU} 例如：alibaba/taobao/tmall/aliexpress 等 BU 一级；子业务线可选。正例：com.taobao.jstorm 或 com.alibaba.dubbo.register2） ArtifactID 格式：产品线名-模块名。语义不重复不遗漏，先到仓库中心去查证一下。正例：dubbo-client / fastjson-api / jstorm-tool3） Version：详细规定参考下方。【强制】二方库版本号命名方式：主版本号.次版本号.修订号1） 主版本号：当做了不兼容的 API 修改，或者增加了能改变产品方向的新功能。2） 次版本号：当做了向下兼容的功能性新增（新增类、接口等）。3） 修订号：修复 bug，没有修改方法签名的功能加强，保持 API 兼容性。说明：起始版本号必须为：1.0.0，而不是 0.0.1【强制】线上应用不要依赖 SNAPSHOT 版本（安全包除外）；正式发布的类库必须使用 RELEASE版本号升级+1 的方式，且版本号不允许覆盖升级，必须去中央仓库进行查证。说明：不依赖 SNAPSHOT 版本是保证应用发布的幂等性。另外，也可以加快编译时的打包构建。【强制】二方库的新增或升级，保持除功能点之外的其它 jar 包仲裁结果不变。如果有改变，必须明确评估和验证，建议进行 dependency:resolve 前后信息比对，如果仲裁结果完全不一致，那么通过 dependency:tree 命令，找出差异点，进行排除 jar 包。【强制】二方库里可以定义枚举类型，参数可以使用枚举类型，但是接口返回值不允许使用枚举类型或者包含枚举类型的 POJO 对象。【强制】依赖于一个二方库群时，必须定义一个统一版本变量，避免版本号不一致。说明：依赖 springframework-core,-context,-beans，它们都是同一个版本，可以定义一个变量来保存版本：${spring.version}，定义依赖的时候，引用该版本。【强制】禁止在子项目的 pom 依赖中出现相同的 GroupId，相同的 ArtifactId，但是不同的Version。说明：在本地调试时会使用各子项目指定的版本号，但是合并成一个 war，只能有一个版本号出现在最后的 lib 目录中。曾经出现过线下调试是正确的，发布到线上出故障的先例。【推荐】所有 pom 文件中的依赖声明放在语句块中，所有版本仲裁放在语句块中。说明：里只是声明版本，并不实现引入，因此子项目需要显式的声明依赖，version 和 scope 都读取自父 pom。而所有声明在主 pom 的里的依赖都会自动引入，并默认被所有的子项目继承。【推荐】二方库尽量不要有配置项，最低限度不要再增加配置项。【参考】为避免应用二方库的依赖冲突问题，二方库发布者应当遵循以下原则：1）精简可控原则。移除一切不必要的 API 和依赖，只包含 Service API、必要的领域模型对象、Utils 类、常量、枚举等。如果依赖其它二方库，尽量是 provided 引入，让二方库使用者去依赖具体版本号；无 log 具体实现，只依赖日志框架。2）稳定可追溯原则。每个版本的变化应该被记录，二方库由谁维护，源码在哪里，都需要能方便查到。除非用户主动升级版本，否则公共二方库的行为不应该发生变化。(三)服务器规约【推荐】高并发服务器建议调小 TCP 协议的 time_wait 超时时间。说明：操作系统默认 240 秒后，才会关闭处于 time_wait 状态的连接，在高并发访问下，服务器端会因为处于 time_wait 的连接数太多，可能无法建立新的连接，所以需要在服务器上调小此等待值。正例：在 linux 服务器上请通过变更/etc/sysctl.conf 文件去修改该缺省值（秒）：net.ipv4.tcp_fin_timeout = 30【推荐】调大服务器所支持的最大文件句柄数（File Descriptor，简写为 fd）。说明：主流操作系统的设计是将 TCP/UDP 连接采用与文件一样的方式去管理，即一个连接对应于一个 fd。主流的 linux 服务器默认所支持最大 fd 数量为 1024，当并发连接数很大时很容易因为 fd 不足而出现“open too many files”错误，导致新的连接无法建立。 建议将 linux服务器所支持的最大句柄数调高数倍（与服务器的内存数量相关）。【推荐】给 JVM 设置-XX:+HeapDumpOnOutOfMemoryError 参数，让 JVM 碰到 OOM 场景时输出dump 信息。说明：OOM 的发生是有概率的，甚至有规律地相隔数月才出现一例，出现时的现场信息对查错非常有价值。【参考】服务器内部重定向使用 forward；外部重定向地址使用 URL 拼装工具类来生成，否则会带来 URL 维护不一致的问题和潜在的安全风险。五、安全规约【强制】隶属于用户个人的页面或者功能必须进行权限控制校验。说明：防止没有做水平权限校验就可随意访问、操作别人的数据，比如查看、修改别人的订单。【强制】用户敏感数据禁止直接展示，必须对展示数据脱敏。说明：查看个人手机号码会显示成:158**9119，隐藏中间 4 位，防止隐私泄露。【强制】用户输入的 SQL 参数严格使用参数绑定或者 METADATA 字段值限定，防止 SQL 注入， 禁止字符串拼接 SQL 访问数据库。【强制】用户请求传入的任何参数必须做有效性验证。说明：忽略参数校验可能导致：page size 过大导致内存溢出恶意 order by 导致数据库慢查询任意重定向SQL 注入反序列化注入正则输入源串拒绝服务 ReDoS说明：Java 代码用正则来验证客户端的输入，有些正则写法验证普通用户输入没有问题，但是如果攻击人员使用的是特殊构造的字符串来验证，有可能导致死循环的效果。【强制】禁止向 HTML 页面输出未经安全过滤或未正确转义的用户数据。【强制】表单、AJAX 提交必须执行 CSRF 安全过滤。说明：CSRF(Cross-site request forgery)跨站请求伪造是一类常见编程漏洞。对于存在CSRF 漏洞的应用/网站，攻击者可以事先构造好 URL，只要受害者用户一访问，后台便在用户不知情情况下对数据库中用户参数进行相应修改。【强制】在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放限制，如数量限制、疲劳度控制、验证码校验，避免被滥刷、资损。说明：如注册时发送验证码到手机，如果没有限制次数和频率，那么可以利用此功能骚扰到其它用户，并造成短信平台资源浪费。【推荐】发贴、评论、发送即时消息等用户生成内容的场景必须实现防刷、文本内容违禁词过滤等风控策略。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>specification</tag>
        <tag>ali</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven记事本]]></title>
    <url>%2F2016%2F12%2F17%2F2016-12-19-maven-notes%2F</url>
    <content type="text"><![CDATA[记录工作中经常要去爬的maven相关技术。拷贝maven依赖到target/lib下12345678910111213141516171819&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/lib&lt;/outputDirectory&gt; &lt;overWriteReleases&gt;false&lt;/overWriteReleases&gt; &lt;overWriteSnapshots&gt;false&lt;/overWriteSnapshots&gt; &lt;overWriteIfNewer&gt;true&lt;/overWriteIfNewer&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt;]]></content>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java开发者常用软件下载地址收集]]></title>
    <url>%2F2016%2F11%2F14%2F2016-11-14-tools-download-url%2F</url>
    <content type="text"><![CDATA[这里收藏工作中用到的下载地址，也为了防止做重复的搜索工作，同时分享给大家。java相关apihttps://docs.oracle.com/javase/8/docs/api/index.htmljavasehttp://www.oracle.com/technetwork/java/javase/downloads/index.htmlserver-jre8http://www.oracle.com/technetwork/java/javase/downloads/server-jre8-downloads-2133154.htmllinux wget下载java8 wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u112-b15/jdk-8u112-linux-x64.tar.gzserverjre8 wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gzjava7 wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/7u80-b15/server-jre-7u80-linux-x64.tar.gzlinux curl下载java8 curl -v -j -k -L -H &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u112-b15/jdk-8u112-linux-x64.tar.gz -o jdk-8u112-linux-x64.tar.gzserverjre8 curl -v -j -k -L -H &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz -o server-jre-8u131-linux-x64.tar.gzjava7 curl -v -j -k -L -H &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/7u80-b15/server-jre-7u80-linux-x64.tar.gz -o server-jre-7u80-linux-x64.tar.gzkafkahttps://kafka.apache.org/downloadszookeeperhttp://www.apache.org/dyn/closer.cgi/zookeeper/mavenhttp://maven.apache.org/download.cgi?Preferred=http%3A%2F%2Fmirror.bit.edu.cn%2Fapache%2Fdockerofficialhttps://docs.docker.com/engine/installation/linux/aliyunhttp://mirrors.aliyun.com/help/docker-engine?spm=0.0.0.0.2Uz4uTcomposehttps://docs.docker.com/compose/install/databaseMySQLhttp://dev.mysql.com/downloads/MySQL Community Serverhttp://dev.mysql.com/downloads/mysql/]]></content>
      <tags>
        <tag>java</tag>
        <tag>tool</tag>
        <tag>download</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本命令备忘]]></title>
    <url>%2F2016%2F09%2F12%2Fshell-notes%2F</url>
    <content type="text"><![CDATA[这里收藏工作中用到的脚本，也为了防止做重复的搜索工作，同时分享给大家。数组初始化数组123name = (value1 value2 ... valuen)$ A=(a b c d)$ echo $&#123;A[@]&#125; # 输出所有元素数组去重1$ array=($(awk -vRS=' ' '!a[$1]++' &lt;&lt;&lt; $&#123;array[@]&#125;))取得数组元素的个数1$ echo $&#123;#A[@]&#125;取下标1$ echo $&#123;A[1]&#125; # 从1开始清除元素12$ unset A$ echo $&#123;A[@]&#125;循环取元素123$ for a in $&#123;A[@]&#125;; do $ echo "$a"$ done替换1$ $&#123;A[@]/3/100&#125;date获取当前日期并格式化成指定格式1$ NOW=$(date +'%Y-%m-%d_%H%M%S') # 2016-09-07_184914获取一个小时前的日期1date --date="1 hours ago" +"%Y-%m-%d"字符串转日期12date -d '2019-05-20'date -d '2019-05-20' +%s #转成时间戳计算当前时间的时间戳1$ STAMP=$(($(date +%s -d "$(date +'%Y-%m-%d %H:%M:%S')"))) # 1473245414计算N天之前的时间12# 十天之前的日期$ TEN_DAYS_AGO=$(($(date -d '-10 day' "+%Y%m%d%H%M%S"))) #20160828185138计算指定日期的前一天1date -d &quot;2019-05-20 -1 day&quot; +&quot;%Y%m%d&quot;获取指定日期的季度1234SEASON=`echo "$&#123;today&#125;" | awk -F "-" '&#123;print $2&#125;'| awk '&#123;season_least=$1%3&#125; &#123;season=$1/3&#125; &#123;if(season_least&gt;0) season+=1&#125; &#123;printf("%d\n",season)&#125;'`YEAR=`echo "$&#123;today&#125;" | awk -F "-" '&#123;print $1&#125;'`YEAR_SEASON="$&#123;YEAR&#125;Q$&#123;SEASON&#125;"echo "YEAR_SEASON=$&#123;YEAR_SEASON&#125;"获取xxxx年xx月的天数12# 获取 2016-10 的天数$ cal 10 2016 | awk 'NF&#123;out=$NF;&#125;END&#123;print out&#125;'输出131vimvi/vim修改只读(readonly)文件，使用sudo修改1:w !sudo tee % &gt; /dev/nullawk过滤数字1$ echo "123" |awk '&#123;if($0 ~ /^[0-9]+$/) print $0;&#125;'数字求和1$ cat $&#123;FILE&#125; | awk '&#123;sum += $1&#125;;END &#123;printf ("%d\n", sum)&#125;'截取字符串1$ echo "123456" | awk '&#123;print substr($1,1,4)&#125;' #1234获取月份所在季度1$ for q in `seq 1 12`; echo $q | awk '&#123;season_least=$1%3&#125; &#123;season=$1/3&#125; &#123;if(season_least&gt;0) season+=1&#125; &#123;printf("%d\n",season)&#125;'输出123456789101112111222333444删除所有空格1$ echo "1 2 3 4" | sed -e 's/[[:space:]]//g '输出11234替换所有的.为/1$ echo "com.xiongyingqi.Test" | awk '&#123;gsub(/\./,"/"); print $0&#125;'输出1com/xiongyingqi/Testsed去除首尾空格1$ FOO_NO_EXTERNAL_SPACE="$(echo -e "$&#123;FOO&#125;" | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')"删除空行1$ sed '/^$/d' sources.listuniq统计重复数1$ cat file | uniq -c文件寻找有指定内容的文件12$ FOUND="test" # 需要查找的内容$ find . | while read file; do if [ -f $file ]; then content=`cat $&#123;file&#125; | grep "$&#123;FOUND&#125;"`; if [ -n "$content" ]; then echo $&#123;file&#125; ; fi; fi; done列举文件并用管道打包1$ find . -name "*.class" | xargs tar cvf classes.tar变量我们先写一个简单的脚本，执行以后再解释各个变量的意义12$ touch variable$ vi variable脚本内容如下：123456789#!/bin/shecho "number:$#"echo "scname:$0"echo "first :$1"echo "second:$2"echo "argume:$@"echo "show parm list:$*"echo "show process id:$$"echo "show precomm stat: $?"保存退出赋予脚本执行权限1$ chmod +x variable执行脚本1$ ./variable aa bb输出12345678number:2scname:./variablefirst:aasecond:bbargume:aa bbshow parm list:aa bbshow process id:24544show precomm stat:0通过显示结果可以看到：$# 是传给脚本的参数个数$0 是脚本本身的名字$1 是传递给该shell脚本的第一个参数$2 是传递给该shell脚本的第二个参数$@ 是传给脚本的所有参数的列表$* 是以一个单字符串显示所有向脚本传递的参数，与位置变量不同，参数可超过9个$$ 是脚本运行的当前进程ID号$? 是显示最后命令的退出状态，0表示没有错误，其他表示有错误例子*amount.txt 下所有文件的第8列数字之和iconv -fgbk 为转换文件为 gbk1ls *amount.txt | while read file; do cat $&#123;file&#125;; done | iconv -fgbk | awk -F "\t" '&#123;print $8&#125;' | awk '&#123;if($0 ~ /^[0-9]+$/) print $0;&#125;' | awk '&#123;sum += $1&#125;;END &#123;printf ("%d\n", sum)&#125;'将目录下的jar文件转换为maven格式的依赖12345678910111213141516171819202122232425262728#!/bin/bashfind . -name "*.jar" | while read jar; do artifact=`echo $&#123;jar&#125; | awk '&#123;print substr($jar,1,length($jar)-4);&#125;'` version=`echo "$artifact" | awk -F '-' ' &#123; print $NF &#125; '` if [ $version == $artifact ]; then version="1.0" else artifact=`echo "$artifact" | awk -v version="$version" '&#123;print substr($1,1,index($1,version)-2)&#125;'` fi # find group groupDirectory=`jar -tf $jar | grep ".class" | head -n 1` last=`echo "$groupDirectory" | awk -F '/' ' &#123; print $NF &#125; '` group=`echo "$groupDirectory" | awk -v last="$last" '&#123;print substr($1,1,index($1,last)-2)&#125;'` # replace / to . group=`echo $group | awk '&#123;gsub(/\//,"."); print $0&#125;'` echo " &lt;dependency&gt; &lt;groupId&gt;$&#123;group&#125;&lt;/groupId&gt; &lt;artifactId&gt;$&#123;artifact&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;version&#125;&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;\$&#123;project.basedir&#125;/lib/$&#123;jar&#125;&lt;/systemPath&gt; &lt;/dependency&gt;" #&gt;&gt; "dependencies.tmp"done查找java类所在当前目录内的jar包1$ FOUND="com.xiongyingqi.Test" &amp;&amp; ls *.jar | while read jar; do jar tf $jar | grep `echo "$&#123;FOUND&#125;" | awk '&#123;gsub(/\./,"/"); print $0&#125;'` | awk -v jar="$jar" '&#123;if (length($1) &gt; 0) print jar&#125;'; done将目录内的文件转换为classpath需要的参数123456789101112131415ls lib/*.jar | xargs | awk -v d="$&#123;delete&#125;" '&#123; str=""; is_in=0; for(i=1;i&lt;=NF;i++)&#123; if($i!=d)&#123; if(is_in == 1)&#123; str=str":"$i; &#125;else&#123; str=str""$i; is_in=1; &#125; &#125; &#125; print str &#125;'查找某个目录下所有的jar包里面有哪些class是冲突的shell脚本1234567891011121314151617181920212223242526#!bin/bashecho "Find out conflict class in the given path";if [ $# != 1 ] ; then echo "Usage: sh findconflictclass.sh $1 ,first param means the path you want to find,eg: sh findconflictclass.sh lib";exit 1;fifindconflictclass.shecho "Please wait ...";jarpath=$1;function unjarclass()&#123; for i in `find $jarpath -name *.jar`; do jar -tvf "$i" |grep .class$ | awk '&#123;print $8&#125;' ; # if [[ $? == 0 ]]; then echo $i; fi; done&#125;unjarclass 1&gt;temp.txt;echo 'unjar class in the given path has done';sleep 10sfunction findclassinjar()&#123;echo -e "\033[47;31m 'The class $1 exists in multi-place below:' \033[0m" ; for i in `find $2 -name *.jar`; do jar -tvf "$i" | grep --color -i "$1" ; if [[ $? == 0 ]]; then echo -e "\033[33m 'The jar path is: $i' \033[0m" ; fi; done&#125;sort temp.txt | uniq -d | cat | while read line; do a=$line; findclassinjar $a $jarpath;donerm -rf temp.txt替换字符串1$ data="a" &amp;&amp; newdata="c" &amp;&amp; echo "aaabbba"|awk -v var=$&#123;1&#125; -v var1=$&#123;data&#125; -v var2=$&#123;newdata&#125; '$0 ~ var &#123;gsub(var1,var2); print&#125;'输出1cccbbbc文件内容替换替换当前目录下的所有文件内容中的hello为helloworld1find . -type f | while read file; do sed -i 's/hello/helloworld/g' $file;done测试curl1$ size=1000;i=0; while [ $i -lt $size ];do i=$((i+1)); curl "http://baidu.com" &amp; done获取从开始日期到结束日期所经历过的季度123456789101112131415161718192021222324252627282930313233343536373839404142FROM_DATE="$1"TO_DATE="$2"FROM_SEASON=`echo "$&#123;FROM_DATE&#125;" | awk -F "-" '&#123;print $2&#125;'| awk '&#123;season_least=$1%3&#125; &#123;season=$1/3&#125; &#123;if(season_least&gt;0) season+=1&#125; &#123;printf("%d\n",season)&#125;'`TO_SEASON=`echo "$&#123;TO_DATE&#125;" | awk -F "-" '&#123;print $2&#125;'| awk '&#123;season_least=$1%3&#125; &#123;season=$1/3&#125; &#123;if(season_least&gt;0) season+=1&#125; &#123;printf("%d\n",season)&#125;'`echo "FROM_SEASON: $&#123;FROM_SEASON&#125;"echo "TO_SEASON: $&#123;TO_SEASON&#125;"FROM_YEAR=`echo "$&#123;FROM_DATE&#125;" | awk -F "-" '&#123;print $1&#125;'`TO_YEAR=`echo "$&#123;TO_DATE&#125;" | awk -F "-" '&#123;print $1&#125;'`year_season_file="year_season.tmp"if [ -f $&#123;year_season_file&#125; ];then echo "delete file: $&#123;year_season_file&#125;" rm -f $&#123;year_season_file&#125;fiif [ $&#123;FROM_YEAR&#125; -eq $&#123;TO_YEAR&#125; ]; then for season in `seq $&#123;FROM_SEASON&#125; $&#123;TO_SEASON&#125;`; do echo "$&#123;FROM_YEAR&#125;Q$&#123;season&#125;" &gt;&gt; $&#123;year_season_file&#125; doneelse for season in `seq $&#123;FROM_SEASON&#125; 4`; do echo "$&#123;FROM_YEAR&#125;Q$&#123;season&#125;" &gt;&gt; $&#123;year_season_file&#125; done #FROM_YEAR if [ $((TO_YEAR-FROM_YEAR)) -ge 2 ]; then for year in `seq $((FROM_YEAR+1)) $((TO_YEAR-1))`; do for season in `seq 1 4`; do echo "$&#123;year&#125;Q$&#123;season&#125;" &gt;&gt; $&#123;year_season_file&#125; done done fi for season in `seq 1 $&#123;TO_SEASON&#125;`; do echo "$&#123;TO_YEAR&#125;Q$&#123;season&#125;" &gt;&gt; $&#123;year_season_file&#125; doneficat $&#123;year_season_file&#125;多线程访问1234567for ((i=0;i&lt;10;)); do for j in `seq 1 100`; do curl "http://baidu.com" &amp; done; wait; i=$((i+1)); done按列合并1cat filtsoort | awk '&#123;sum[$1]+=$2&#125;END&#123;for (i in sum) print i" "sum[i]&#125;'转换编码1find . -name "*.java" | while read file; do iconv -f gbk -t utf-8 $file &gt; $&#123;file&#125;.bak; mv -f $&#123;file&#125;.bak $file; doneword转换为markdown需要先安装w2m: benbalter/word-to-markdown1234567find doc -name "*.doc" | while read file; do folder_tmp="markdown/$file"; folder=$&#123;folder_tmp%/*&#125;; target_file="$&#123;folder_tmp%%.*&#125;".md mkdir -p $folder; w2m $file &gt; $target_file; done移除base64图像1sed -i 's-\!\[\](data:image\/\*;base64,.*)--g' $file判断是否为asccii字符串（英文字符）1echo "呵呵" | awk '&#123; print (length($0)&gt;NF)&#125;' #1输出带颜色的字符shell脚本中echo显示内容带颜色显示,echo显示带颜色，需要使用参数-e格式如下：1echo -e "\033[字背景颜色；文字颜色m字符串\033[0m"例如：1echo -e "\033[41;36m something here \033[0m"其中41的位置代表底色， 36的位置是代表字的颜色注：1、字背景颜色和文字颜色之间是英文的””2、文字颜色后面有个m3、字符串前后可以没有空格，如果有的话，输出也是同样有空格下面是相应的字和背景颜色，可以自己来尝试找出不同颜色搭配例1234echo -e "\033[31m 红色字 \033[0m"echo -e "\033[34m 黄色字 \033[0m"echo -e "\033[41;33m 红底黄字 \033[0m"echo -e "\033[41;37m 红底白字 \033[0m"字颜色：30—–3712345678echo -e "\033[30m 黑色字 \033[0m"echo -e "\033[31m 红色字 \033[0m"echo -e "\033[32m 绿色字 \033[0m"echo -e "\033[33m 黄色字 \033[0m"echo -e "\033[34m 蓝色字 \033[0m"echo -e "\033[35m 紫色字 \033[0m"echo -e "\033[36m 天蓝字 \033[0m"echo -e "\033[37m 白色字 \033[0m"字背景颜色范围：40—–4712345678echo -e "\033[40;37m 黑底白字 \033[0m"echo -e "\033[41;37m 红底白字 \033[0m"echo -e "\033[42;37m 绿底白字 \033[0m"echo -e "\033[43;37m 黄底白字 \033[0m"echo -e "\033[44;37m 蓝底白字 \033[0m"echo -e "\033[45;37m 紫底白字 \033[0m"echo -e "\033[46;37m 天蓝底白字 \033[0m"echo -e "\033[47;30m 白底黑字 \033[0m"最后面控制选项说明\33[0m 关闭所有属性\33[1m 设置高亮度\33[4m 下划线\33[5m 闪烁\33[7m 反显\33[8m 消隐\33[30m — \33[37m 设置前景色\33[40m — \33[47m 设置背景色\33[nA 光标上移n行\33[nB 光标下移n行\33[nC 光标右移n行\33[nD 光标左移n行\33[y;xH设置光标位置\33[2J 清屏\33[K 清除从光标到行尾的内容\33[s 保存光标位置\33[u 恢复光标位置\33[?25l 隐藏光标\33[?25h 显示光标1234567891011function echoGreen()&#123; echo -e "\033[32m$1\033[0m"&#125;function echoRed()&#123; echo -e "\033[31m$1\033[0m"&#125;function echoYellow()&#123; echo -e "\033[33m$1\033[0m"&#125;从第二行开始显示1cat file | awk 'NR&gt;2&#123;print p&#125;&#123;p=$0&#125;'批量导出db数据123456for y in `seq 2015 2025`; do for m in `seq 1 12`; do db=`echo gateway$y``printf "%02d" $m`; mysqldump -uroot -ppass -hhost -d $db --lock-tables=false &gt;&gt; gateway.sql; donedone获取被执行脚本所在路径12cur_script_dir="`cd $(dirname $0) &amp;&amp; pwd`"echo $cur_script_dirawk获取第1列之后的列值1awk '&#123; $1=""; print $0 &#125;' ur_file另外， 如果我要打印某列以后的所有列的， 可以使用循环把， 把前N列都赋值为空：1awk '&#123; for(i=1; i&lt;=2; i++)&#123; $i="" &#125;; print $0 &#125;' urfile]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java分段锁示例]]></title>
    <url>%2F2016%2F04%2F17%2Fjava-multiple-segment-lock%2F</url>
    <content type="text"><![CDATA[Why读ConcurrentHashMap的时候，我们遇到的一个很大的概念就是Segment（java8之后只有在调用writeObject方法的方法的时候才会用到segment），该类继承了ReentrantLock，用于实现分段锁（乐观锁）。处于心痒痒的目的，我也尝试写了个简陋版的分段锁。How该Demo实现的比较简单：根据key获取或者创建Lock（获取锁的时候使用double check），然后使用该锁来同步put或者read（ConcurrentHashMap的读操作使用的volatile，这里不深入）。不足之处还请指正~Whatjava实现： github123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162package com.xiongyingqi.concurrent;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * @author xiongyingqi * @version 2016-04-18 16:51 */public class MultipleSegmentLock &#123; private Map&lt;String, ReentrantLock&gt; lockMap = new ConcurrentHashMap&lt;String, ReentrantLock&gt;(); public void write(String key, String value) &#123; Lock lock = checkLock(key); lock.lock(); try &#123; System.out.println("writing... " + key + "=" + value); try &#123; // Random random = new Random(); // long time = random.nextInt(10) + 10; // Thread.sleep(time); Thread.sleep(10L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("write complete... " + key + "=" + value); &#125; finally &#123; lock.unlock(); &#125; &#125; public void read(String key) &#123; Lock lock = checkLock(key); lock.lock(); try &#123; System.out.println("reading... " + key); try &#123; Thread.sleep(10L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("read complete... " + key); &#125; finally &#123; lock.unlock(); &#125; &#125; /** * Getting the lock of the key. Create a &#123;@link ReentrantLock&#125; when not exists. * &lt;p&gt;Implements with double check&lt;/p&gt; * * @param key Segment by the key * @return &#123;@link ReentrantLock&#125; */ private Lock checkLock(String key) &#123; ReentrantLock reentrantLock = lockMap.get(key); if (reentrantLock == null) &#123; synchronized (this) &#123; reentrantLock = lockMap.get(key); if (reentrantLock == null) &#123; reentrantLock = new ReentrantLock(); System.out.println( "lock for " + key + " not exists! so create a lock: " + reentrantLock); lockMap.put(key, reentrantLock); return reentrantLock; &#125; return reentrantLock; &#125; &#125; return reentrantLock; &#125; public static void main(String[] args) &#123; MultipleSegmentLock multipleSegmentLock = new MultipleSegmentLock(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; multipleSegmentLock.write("key", "" + i); // synchronous with 'key' and asynchronous with 'key2' &#125; &#125;).start(); new Thread(() -&gt; &#123; for (int i = 100; i &lt; 200; i++) &#123; multipleSegmentLock.write("key", "" + i); // synchronous with 'key' and asynchronous with 'key2' &#125; &#125;).start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; multipleSegmentLock.write("key2", "" + i); // synchronous with 'key2' and asynchronous with 'key' &#125; &#125;).start(); new Thread(() -&gt; &#123; for (int i = 100; i &lt; 200; i++) &#123; multipleSegmentLock.write("key2", "" + i); // synchronous with 'key2' and asynchronous with 'key' &#125; &#125;).start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; multipleSegmentLock.read("key"); &#125; &#125;).start(); // Console out may be: // ---------------------------------------------------- //lock for key not exists! so create a lock: null //lock for key2 not exists! so create a lock: null //writing... key=0 //writing... key2=0 //write complete... key=0 //write complete... key2=0 //writing... key=1 //writing... key2=1 //write complete... key=1 //write complete... key2=1 //writing... key2=2 //writing... key=2 //write complete... key2=2 //write complete... key=2 //writing... key2=3 //writing... key=3 //write complete... key2=3 //write complete... key=3 //... ... //reading... key //write complete... key2=49 //read complete... key //reading... key //writing... key2=50 //read complete... key //write complete... key2=50 //reading... key //writing... key2=51 //read complete... key //write complete... key2=51 //reading... key //writing... key2=109 //read complete... key //write complete... key2=109 //reading... key //writing... key2=110 //read complete... key //... ... //writing... key=194 //write complete... key=194 //writing... key=195 //write complete... key=195 //writing... key=196 //write complete... key=196 //writing... key=197 //write complete... key=197 //writing... key=198 //write complete... key=198 //writing... key=199 //write complete... key=199 // ---------------------------------------------------- &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>segment</tag>
        <tag>lock</tag>
        <tag>ReentrantLock</tag>
        <tag>锁</tag>
        <tag>分段锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jackson解析json为指定泛型的集合]]></title>
    <url>%2F2016%2F03%2F28%2Fjackson-deserialize-collection%2F</url>
    <content type="text"><![CDATA[问题在日常开发中，当使用ObjectMapper进行解析json时，我们时常需要将json解析成我们指定泛型的集合类型Collection&lt;type&gt;。但是如果直接使用objectMapper.readValue(json, Collection.class)的话，那么就会解析为Collection&lt;Map&gt;的类型，这个明显不是我们想要的。方案在jackson内，如果要反序列化为Collection或者Map，我们可以使用CollectionType construct = CollectionType.construct(LinkedList.class, SimpleType.construct(clazz));MapType construct = MapType.construct(HashMap.class, SimpleType.construct(keyType), SimpleType.construct(valueType))12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package com.xiongyingqi.json;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.JavaType;import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.type.CollectionType;import com.fasterxml.jackson.databind.type.MapType;import com.fasterxml.jackson.databind.type.SimpleType;import java.io.IOException;import java.util.*;/** * @author xiongyingqi * @version 2016-03-29 11:23 */public class JacksonDemo &#123; public static ObjectMapper getMapper() &#123; return new ObjectMapper(); &#125; public String writeAsString(Object o) throws JsonProcessingException &#123; ObjectMapper mapper = new ObjectMapper(); return mapper.writeValueAsString(o); &#125; /** * 获取反序列化的集合类型JavaType * * @param clazz 元素类型 * @return &#123;@link JavaType&#125; */ public static JavaType getListType(Class&lt;?&gt; clazz) &#123; CollectionType construct = CollectionType .construct(LinkedList.class, SimpleType.construct(clazz)); return construct; &#125; /** * 获取反序列化的map类型JavaType * * @param keyType 键类型 * @param valueType 值类型 * @return &#123;@link JavaType&#125; */ public static JavaType getMapType(Class&lt;?&gt; keyType, Class&lt;?&gt; valueType) &#123; MapType construct = MapType.construct(HashMap.class, SimpleType.construct(keyType), SimpleType.construct(valueType)); return construct; &#125; public static void main(String[] args) throws IOException &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add("hello"); list.add("world"); list.add("!"); JacksonDemo jacksonDemo = new JacksonDemo(); String listJson = jacksonDemo.writeAsString(list); System.out.println(listJson); JavaType listType = getListType(String.class); ObjectMapper mapper = getMapper(); List&lt;String&gt; result = mapper.readValue(listJson, listType); System.out.println(result); System.out.println(result.getClass()); // LinkedList Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put("one", "hello"); map.put("two", "world"); String mapJson = jacksonDemo.writeAsString(map); System.out.println(mapJson); JavaType mapType = getMapType(String.class,String.class); Map&lt;String, String&gt; result2 = mapper.readValue(mapJson, mapType); System.out.println(result2); System.out.println(result2.getClass()); // HashMap &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jackson</tag>
        <tag>fasterxml</tag>
        <tag>collection</tag>
        <tag>deserialize</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scala根据Class获取单例（孤立）对象]]></title>
    <url>%2F2015%2F10%2F30%2Fscala-object-reflect-get%2F</url>
    <content type="text"><![CDATA[开发中遇到的问题在scala开发过程中，有需要使用Class获取scala单例（孤立）对象的需求，但是直接使用Class.newInstance()是无法获取单例对象的。发现google之后，在一篇博客：http://blog.csdn.net/zhangjg_blog/article/details/23376465 其中有一个例子：1234object Test &#123; val a = "a string"; def printString = println(a)&#125;编译之后可以看到有两个class文件：Test$.classTest.class也就是说， 这个孤立对象也被编译成一个同名类Test 。 除此之外， 还有一个叫做Test$的类， 这个以$结尾的类就是所谓的虚构类（synthetic class， 《Scala编程》中将之翻译为虚构类） 。单例对象原理下面使用javap反编译Test.class , 得到如下结果（去掉了常量池等信息）：12345678910111213141516171819202122232425262728public final class Test SourceFile: "Test.scala" RuntimeVisibleAnnotations: 0: #6(#7=s#8) ScalaSig: length = 0x3 05 00 00 minor version: 0 major version: 50 flags: ACC_PUBLIC, ACC_FINAL, ACC_SUPER&#123; public static void printString(); flags: ACC_PUBLIC, ACC_STATIC Code: stack=1, locals=0, args_size=0 0: getstatic #16 // Field Test$.MODULE$:LTest$; 3: invokevirtual #18 // Method Test$.printString:()V 6: return public static java.lang.String a(); flags: ACC_PUBLIC, ACC_STATIC Code: stack=1, locals=0, args_size=0 0: getstatic #16 // Field Test$.MODULE$:LTest$; 3: invokevirtual #22 // Method Test$.a:()Ljava/lang/String; 6: areturn&#125;由反编译的结果可以看出：源码中的属性a对应一个静态的同名方法a()源码中的方法printString也对应一个静态的同名方法printString()静态方法a()调用Test$类中的静态字段MODULE$的a方法静态方法printString()调用Test$类中的静态字段MODULE$的printString方法如果用java来描述的话， Test类的逻辑是这样的：1234567891011public final class Test&#123; public static java.lang.String a()&#123; return Test$.MODULE$.a() &#125; public static void printString()&#123; Test$.MODULE$.printString() &#125;&#125;下面再看Test类的虚构类Test$的javap反编译结果：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public final class Test$ SourceFile: "Test.scala" Scala: length = 0x0 minor version: 0 major version: 50 flags: ACC_PUBLIC, ACC_FINAL, ACC_SUPER&#123; public static final Test$ MODULE$; flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL private final java.lang.String a; flags: ACC_PRIVATE, ACC_FINAL public static &#123;&#125;; flags: ACC_PUBLIC, ACC_STATIC Code: stack=1, locals=0, args_size=0 0: new #2 // class Test$ 3: invokespecial #12 // Method "&lt;init&gt;":()V 6: return public java.lang.String a(); flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #17 // Field a:Ljava/lang/String; 4: areturn public void printString(); flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: getstatic #24 // Field scala/Predef$.MODULE$:Lscala/Predef$; 3: aload_0 4: invokevirtual #26 // Method a:()Ljava/lang/String; 7: invokevirtual #30 // Method scala/Predef$.println:(Ljava/lang/Object;)V 10: return private Test$(); flags: ACC_PRIVATE Code: stack=2, locals=1, args_size=1 0: aload_0 1: invokespecial #31 // Method java/lang/Object."&lt;init&gt;":()V 4: aload_0 5: putstatic #33 // Field MODULE$:LTest$; 8: aload_0 9: ldc #35 // String a string 11: putfield #17 // Field a:Ljava/lang/String; 14: return&#125;看一下这个类里的内容：首先， 该类中有一个常量字段MODULE$， 它的类型就是当前的虚构类Test$ 。12public static final Test$ MODULE$; flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL编译器在Test$中默认添加了静态初始化方法， 用于对静态字段MODULE$初始化：1234567public static &#123;&#125;; flags: ACC_PUBLIC, ACC_STATIC Code: stack=1, locals=0, args_size=0 0: new #2 // class Test$ 3: invokespecial #12 // Method "&lt;init&gt;":()V 6: return源码中的字段a在Test$中对应一个非静态的字段a ， 由于源码中的a是val的， 所以在Test$中对应的a字段是final的12private final java.lang.String a; flags: ACC_PRIVATE, ACC_FINAL在Test$中还有一个成员方法a()与字段a对应， 这个方法的逻辑是返回a的值1234567public java.lang.String a(); flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #17 // Field a:Ljava/lang/String; 4: areturn源码中的方法printString对应Test$中的printString方法。 这个方法的逻辑是调用方法a()获取字段a的值， 并打印a的值。123456789public void printString(); flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: getstatic #24 // Field scala/Predef$.MODULE$:Lscala/Predef$; 3: aload_0 4: invokevirtual #26 // Method a:()Ljava/lang/String; 7: invokevirtual #30 // Method scala/Predef$.println:(Ljava/lang/Object;)V 10: return此外， 编译器在Test$中还加入默认的构造方法， 不过这个构造方法是私有的。 无法为外部调用。如下：123456789101112private Test$(); flags: ACC_PRIVATE Code: stack=2, locals=1, args_size=1 0: aload_0 1: invokespecial #31 // Method java/lang/Object."&lt;init&gt;":()V 4: aload_0 5: putstatic #33 // Field MODULE$:LTest$; 8: aload_0 9: ldc #35 // String a string 11: putfield #17 // Field a:Ljava/lang/String; 14: return如果用java代码描述的话，Test$的逻辑是这样的：123456789101112131415public final class Test$&#123; public static final Test$ MODULE$ = new Test$(); private final String a = "a string"; public String a()&#123; return a; &#125; public void printString()&#123; println(a()); &#125; private Test$()&#123;&#125;&#125;由此可见这个虚构类Test$是单例的。一方面， 这个类是编译器默认生成的，在Scala代码中无法访问到。另一方面， Test$构造器私有了， 只在内部创建了一个对象赋给了静态引用MODULE$ 。所以， 在Scala里面称用object关键字修饰的对象是单例对象， 在实现的角度上看， 并不是十分确切。 虽然称之为对象， 但是编译器确实为他生成了一个类， 如上面例子中的object Test ， 编译器确实生成了类Test。 但是这个类中只有静态方法， 即使是一个Scala中的字段， 也对应一个静态方法， 如上例中的字段a 。 这个类中的静态方法会访问虚构类Test$中的静态成员Test$ MODULE$ ，使用这个对象可以调用Test$中的其他成员方法，Test$中的成员和源码中的成员相对应， 只是会为源码中的字段添加同名方法。 主要的处理逻辑实际上是在虚构类Test$中完成的， Test类只是作为一个入口。下面是看一下Scala是如何实现对单例对象的调用的。 首先写一个Scala的入口类：123456object Main &#123; //scala main def main(args : Array[String])&#123; Test.printString &#125;&#125;相同的原理， 入口类Main也是单例对象， 实现原理和Test是相同的。 大部分的逻辑都在虚构类Main$中的成员方法main中实现的。反编译 Main$后的结果如下：12345678910111213141516171819202122232425262728293031323334353637public final class Main$ SourceFile: "Main.scala" Scala: length = 0x0 minor version: 0 major version: 50 flags: ACC_PUBLIC, ACC_FINAL, ACC_SUPER&#123; public static final Main$ MODULE$; flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL public static &#123;&#125;; flags: ACC_PUBLIC, ACC_STATIC Code: stack=1, locals=0, args_size=0 0: new #2 // class Main$ 3: invokespecial #12 // Method "&lt;init&gt;":()V 6: return public void main(java.lang.String[]); flags: ACC_PUBLIC Code: stack=1, locals=2, args_size=2 0: getstatic #19 // Field Test$.MODULE$:LTest$; 3: invokevirtual #22 // Method Test$.printString:()V 6: return private Main$(); flags: ACC_PRIVATE Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #26 // Method java/lang/Object."&lt;init&gt;":()V 4: aload_0 5: putstatic #28 // Field MODULE$:LMain$; 8: return&#125;用Java代码实现如下：12345678public final class Main$&#123; public static final Main$ MODULE$ = new Main$(); public void main(String[] args)&#123; Test$.MODULE$.printString(); &#125; private Main$()&#123;&#125;&#125;由此可见， 在Main$中的成员方法main中， 直接调用了Test$.MODULE$.printString()方法， 而绕过了Test类， 这也是合理的， 因为只有Test$才处理相关逻辑。而Main.class用java代码表示如下：12345public final class Main&#123; public static void main(String[] args)&#123; Main$.MODULE$.main(args); &#125;&#125;做一下总结：Main.class提供JVM的入口函数， 在入口函数中调用Main$的成员方法main， 而Main$的成员方法main又调用了Test$的成员方法printString来处理相关逻辑， 即打印字符串。单例对象的调用方式如下图所示：解决问题原理根据上面的scala单例原理说明，我们可以知道，单例对象的类名是以$结束的，并且单例对象是在类定义下面的MODULE$字段下。因此，我们只需判断Class是不是以$结束，并且在此类下获取MODULE$字段值即可实现代码ReflectionUtil.scala1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 反射工具 * @author &lt;a href="http://xiongyingqi.com"&gt;qi&lt;/a&gt; * @version 2015-10-21 21:01 */object ReflectionUtil &#123; val SINGLETON_END_NAME = "$" val SINGLETON_FIELD_NAME = "MODULE$" /** * 根据class获取单例对象（必须是object关键字） * @param clazz Class * @tparam T 泛型 * @return T * @see http://blog.csdn.net/zhangjg_blog/article/details/23376465 */ def getSingleton[T](clazz: Class[T]): Option[T] = &#123; if (!clazz.getSimpleName.endsWith(SINGLETON_END_NAME)) &#123; println("class name not end with: '" + SINGLETON_END_NAME + "', it's not a singleton object!" + "Must declared with 'object'. e.g., object A &#123;&#125;") return None &#125; val field = clazz.getDeclaredField(SINGLETON_FIELD_NAME) if (field == null) &#123; return None &#125; val fieldType = field.getType if (!fieldType.equals(clazz)) &#123; println("fieldType: " + fieldType + " not equals " + clazz) return None &#125; val module: T = field.get(null).asInstanceOf[T] Some(module) &#125; /** * test * @param args */ def main(args: Array[String]) &#123; val o = getSingleton(ReflectionUtil.getClass) println(s"ReflectionUtil getSingleton(ReflectionUtil.getClass) =========== $&#123;o.get&#125;") println(s"ReflectionUtil =========== $ReflectionUtil") assert(getSingleton(ReflectionUtil.getClass).get == ReflectionUtil) &#125;&#125;]]></content>
      <categories>
        <category>scala</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>scala</tag>
        <tag>object</tag>
        <tag>reflect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决springmvcjson循环依赖问题：Spring MVC中使用jackson的MixInAnnotations方法动态过滤JSON字段]]></title>
    <url>%2F2015%2F10%2F13%2F2014-06-30-spring-mvc-jackson-enhance%2F</url>
    <content type="text"><![CDATA[问题描述项目使用SpringMVC框架，并用jackson库处理JSON和POJO的转换。在POJO转化成JSON时，有些属性我们不需要输出或者有些属性循环引用会造成无法输出。例如：实体User其中包括用户名、密码、邮箱等，但是我们在输出用户信息不希望输出密码、邮箱信息;例如：实体user和department是多对一的关系，user内保存着department的信息，那么json输出时会导致这两个实体数据的循环输出;jackson默认可以使用JsonIgnoreProperties接口来定义要过滤的属性,然后使用ObjectMapper#addMixInAnnotations来设置对应实体对应的JsonIgnoreProperties接口,这样就能达到过滤的目的。可是这样很不爽,因为如果你对n个实体对应有m种过滤需求就至少要建n*m个JsonIgnoreProperties接口。解决方案主要逻辑如下图大致处理流程:使用自定义注解controller方法然后定义aop捕获所有controller方法当aop捕获到controller方法时调用JavassistFilterPropertyHandler#filterProperties方法filterProperties读取注解并根据自定义注解使用javassist创建JsonIgnoreProperties临时实现类(同时缓存到map内,下次可直接取出)并存入当前线程内(ThreadJacksonMixInHolder, 使用threadlocal实现),在springmvc输出json的类内自定义ObjectMapper, 从当前线程内取出JsonIgnoreProperties临时类, 调用ObjectMapper# addMixInAnnotations使之起效最后使用ObjectMapper输出用法:定义aop, 用来捕获springmvc的controller方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.xiongyingqi.json.filter.aop;import com.xiongyingqi.jackson.FilterPropertyHandler;import com.xiongyingqi.jackson.impl.JavassistFilterPropertyHandler;import org.apache.log4j.Logger;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.AfterThrowing;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;import org.aspectj.lang.reflect.MethodSignature;import java.lang.reflect.Method;/** * @author 瑛琪 &lt;a href="http://xiongyingqi.com"&gt;xiongyingqi.com&lt;/a&gt; * @version 2013-9-27 下午5:41:12 */@Aspectpublic class IgnorePropertyAspect &#123; public static final Logger LOGGER = Logger.getLogger(IgnorePropertyAspect.class); @Pointcut("execution(* com.kingray.web.*.*(..))") private void anyMethod() &#123; &#125; @Around("anyMethod()") public Object around(ProceedingJoinPoint pjp) throws Throwable &#123; Object returnVal = pjp.proceed(); // 返回源结果 try &#123; FilterPropertyHandler filterPropertyHandler = new JavassistFilterPropertyHandler(true); Method method = ((MethodSignature) pjp.getSignature()).getMethod(); returnVal = filterPropertyHandler.filterProperties(method, returnVal); &#125; catch (Exception e) &#123; LOGGER.error(e); e.printStackTrace(); &#125; return returnVal; &#125; @AfterThrowing(pointcut = "anyMethod()", throwing = "e") public void doAfterThrowing(Exception e) &#123; System.out.println(" -------- AfterThrowing -------- "); &#125;&#125;spring配置123&lt;!-- 启动mvc对aop的支持,使用aspectj代理 --&gt;&lt;aop:aspectj-autoproxyproxy-target-class="true" /&gt;&lt;beanid="ignorePropertyAspect" class="com.xiongyingqi.json.filter.aop.IgnorePropertyAspect"&gt;&lt;/bean&gt;配置spring-mvc的messageconverter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;bean class="org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter"&gt; &lt;property name="cacheSeconds" value="0"/&gt; &lt;!--日期格式转换 --&gt; &lt;property name="webBindingInitializer"&gt; &lt;bean class="com.kingray.spring.http.convert.DateConverter"/&gt; &lt;/property&gt; &lt;property name="messageConverters"&gt; &lt;list&gt; &lt;bean class="com.xiongyingqi.spring.http.convert.json.Jackson2HttpMessageConverter"&gt; &lt;/bean&gt; &lt;bean class="com.xiongyingqi.spring.http.convert.json.JacksonHttpMessageConverter"&gt; &lt;/bean&gt; &lt;bean class="org.springframework.http.converter.BufferedImageHttpMessageConverter"&gt; &lt;/bean&gt; &lt;bean class="org.springframework.http.converter.ResourceHttpMessageConverter"&gt; &lt;/bean&gt; &lt;bean class="org.springframework.http.converter.FormHttpMessageConverter"&gt; &lt;/bean&gt; &lt;bean class="org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter"&gt; &lt;/bean&gt; &lt;bean class="org.springframework.http.converter.xml.Jaxb2RootElementHttpMessageConverter"&gt; &lt;/bean&gt; &lt;bean class="org.springframework.http.converter.feed.AtomFeedHttpMessageConverter"&gt; &lt;/bean&gt; &lt;bean class="org.springframework.http.converter.feed.RssChannelHttpMessageConverter"&gt; &lt;/bean&gt; &lt;bean class="org.springframework.http.converter.xml.Jaxb2CollectionHttpMessageConverter"&gt; &lt;/bean&gt; &lt;bean class="org.springframework.http.converter.xml.SourceHttpMessageConverter"&gt; &lt;/bean&gt; &lt;bean class="org.springframework.http.converter.ByteArrayHttpMessageConverter"&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;重写spring的MappingJackson2HttpMessageConverter类,这样输出的json内容就能自定义12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package com.xiongyingqi.spring.http.convert.json;import java.io.IOException;import com.xiongyingqi.jackson.helper.ThreadJacksonMixInHolder;import org.springframework.http.HttpOutputMessage;import org.springframework.http.converter.HttpMessageNotWritableException;import org.springframework.http.converter.json.MappingJackson2HttpMessageConverter;import com.fasterxml.jackson.core.JsonEncoding;import com.fasterxml.jackson.core.JsonGenerator;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.SerializationFeature;/** * @author 瑛琪 &lt;a href="http://xiongyingqi.com"&gt;xiongyingqi.com&lt;/a&gt; * @version 2013-9-27 下午4:05:46 */public class Jackson2HttpMessageConverter extends MappingJackson2HttpMessageConverter &#123; private ObjectMapper objectMapper = new ObjectMapper(); private boolean prefixJson = false; /** * &lt;br&gt; * 2013-9-27 下午4:10:28 * * @see org.springframework.http.converter.json.MappingJacksonHttpMessageConverter#writeInternal(Object, * org.springframework.http.HttpOutputMessage) */ @Override protected void writeInternal(Object object, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException &#123; // super.writeInternal(object, outputMessage); // 判断是否需要重写objectMapper ObjectMapper objectMapper = this.objectMapper;// 本地化ObjectMapper，防止方法级别的ObjectMapper改变全局ObjectMapper if (ThreadJacksonMixInHolder.isContainsMixIn()) &#123; objectMapper = ThreadJacksonMixInHolder.builderMapper(); &#125; JsonEncoding encoding = getJsonEncoding(outputMessage.getHeaders().getContentType()); JsonGenerator jsonGenerator = objectMapper.getFactory().createGenerator( outputMessage.getBody(), encoding); // A workaround for JsonGenerators not applying serialization features // https://github.com/FasterXML/jackson-databind/issues/12 if (objectMapper.isEnabled(SerializationFeature.INDENT_OUTPUT)) &#123; jsonGenerator.useDefaultPrettyPrinter(); &#125; try &#123; if (this.prefixJson) &#123; jsonGenerator.writeRaw("&#123;&#125; &amp;&amp; "); &#125; objectMapper.writeValue(jsonGenerator, object); &#125; catch (JsonProcessingException ex) &#123; throw new HttpMessageNotWritableException("Could not write JSON: " + ex.getMessage(), ex); &#125; // JsonEncoding encoding = // getJsonEncoding(outputMessage.getHeaders().getContentType()); // JsonGenerator jsonGenerator = // this.objectMapper.getJsonFactory().createJsonGenerator(outputMessage.getBody(), // encoding); // // // A workaround for JsonGenerators not applying serialization // features // // https://github.com/FasterXML/jackson-databind/issues/12 // if (this.objectMapper.isEnabled(SerializationFeature.INDENT_OUTPUT)) // &#123; // jsonGenerator.useDefaultPrettyPrinter(); // &#125; // // try &#123; // if (this.prefixJson) &#123; // jsonGenerator.writeRaw("&#123;&#125; &amp;&amp; "); // &#125; // this.objectMapper.writeValue(jsonGenerator, object); // &#125; // catch (JsonProcessingException ex) &#123; // throw new HttpMessageNotWritableException("Could not write JSON: " + // ex.getMessage(), ex); // &#125; &#125; public boolean isPrefixJson() &#123; return prefixJson; &#125; public void setPrefixJson(boolean prefixJson) &#123; this.prefixJson = prefixJson; &#125;&#125;在方法上注解Controller方法的示例，yxResourceSelfRelationsForSuperiorResourceId是YxResource内要过滤的属性:12345678910 @IgnoreProperties(value= &#123; @IgnoreProperty(pojo = YxResource.class, name = &#123; "yxResourceSelfRelationsForSuperiorResourceId"&#125;)&#125;)@RequestMapping(value = "/&#123;resourceId&#125;", method = RequestMethod.GET)@ResponseBodypublic Object getResourceByResourceId(@PathVariable Integer resourceId) &#123; YxResource resource = resourceService.getResource(resourceId); return resource; &#125;主要类说明自定义注解类：这些类是用于注解实体类输出json时要注解过滤的属性IgnoreProperties.java 用于同时注解IgnoreProperty和AllowProperty12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package com.xiongyingqi.jackson.annotation;import java.lang.annotation.*;/** * json属性过滤注解，对于同一个pojo来说 @AllowProperty 是与 @IgnoreProperty 是冲突的，如果这两个注解注解了&lt;br&gt; * 例如以下代码YxResource实体只会显示resourceName和resourceDescribe属性 * &lt;p/&gt; * &lt;pre&gt; * @IgnoreProperties( * value = &#123; * @IgnoreProperty( * pojo = YxResource.class, * name = &#123; * "yxResourceDataRelations", * "yxResourceSelfRelationsForSublevelResourceId", * "yxPermisionResourceRelations" &#125;), * @IgnoreProperty( * pojo = YxResourceSelfRelation.class, * name = &#123; * "yxResourceBySuperiorResourceId", * "id" &#125;) * &#125;, * allow = &#123; * @AllowProperty( * pojo = YxResource.class, * name = &#123; "&lt;b&gt;&lt;i&gt;resourceName&lt;/i&gt;&lt;/b&gt;" &#125;) &#125;) * @AllowProperty( * pojo = YxResource.class, * name = &#123; "&lt;b&gt;&lt;i&gt;resourceDescribe&lt;/i&gt;&lt;/b&gt;" &#125;) * &lt;/pre&gt; * &lt;p/&gt; * &lt;p/&gt; * 但是，对于同一个pojo的同一属性来说@AllowProperty是与@IgnoreProperty则会按照@IgnoreProperty过滤的属性名过滤 * 例如以下代码YxResource实体不会显示resourceName属性的值 * &lt;p/&gt; * &lt;pre&gt; * @IgnoreProperties( * value = &#123; * @IgnoreProperty( * pojo = YxResource.class, * name = &#123; "&lt;b&gt;&lt;i&gt;resourceName&lt;/i&gt;&lt;/b&gt;", * "yxResourceDataRelations", * "yxResourceSelfRelationsForSublevelResourceId", * "yxPermisionResourceRelations" &#125;), * @IgnoreProperty( * pojo = YxResourceSelfRelation.class, * name = &#123; * "yxResourceBySuperiorResourceId", * "id" &#125;) * &#125;, * allow = &#123; * @AllowProperty( * pojo = YxResource.class, * name = &#123; "&lt;b&gt;&lt;i&gt;resourceName&lt;/i&gt;&lt;/b&gt;" &#125;) &#125;) * &lt;/pre&gt; * * @author 瑛琪 &lt;a href="http://xiongyingqi.com"&gt;xiongyingqi.com&lt;/a&gt; * @version 2013-9-27 下午4:18:39 */@Documented@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface IgnoreProperties &#123; /** * 要过滤的属性 * * @return */ IgnoreProperty[] value() default @IgnoreProperty(pojo = Object.class, name = ""); /** * 允许的属性 * * @return */ AllowProperty[] allow() default @AllowProperty(pojo = Object.class, name = "");&#125;IgnoreProperty.java：过滤指定对象内的指定字段名123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.xiongyingqi.jackson.annotation;import java.lang.annotation.*;/** * 用于注解json过滤pojo内的属性，其他的属性都会被序列化成字符串 * * @author 瑛琪 &lt;a href="http://xiongyingqi.com"&gt;xiongyingqi.com&lt;/a&gt; * @version 2013-9-27 下午4:24:33 */@Documented@Target(&#123;ElementType.TYPE, ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface IgnoreProperty &#123; /** * 要忽略字段的POJO &lt;br&gt; * 2013-9-27 下午4:27:08 * * @return */ Class&lt;?&gt; pojo(); /** * 要忽略的字段名 &lt;br&gt; * 2013-9-27 下午4:27:12 * * @return */ String[] name(); /** * 字段名，无论是哪种 &lt;br&gt; * 2013-9-27 下午4:27:15 * * @return */ // String value() default ""; /** * 最大迭代层次&lt;br&gt; * 当注解了pojo和name值时，该值表示遍历bean属性的最大曾次数，此注解一般用于自关联的bean类， * 如果循环层次大于等于maxLevel时则不再读取属性&lt;br&gt; * 如果maxIterationLevel为0，则不限制迭代层次&lt;br&gt; * 如果maxIterationLevel为1，则迭代读取属性一次&lt;br&gt; * 2013-10-21 下午2:16:26 * * @return */ // int maxIterationLevel() default 0;&#125;AllowProperty.java：注解实体类允许的字段12345678910111213141516171819202122232425262728293031package com.xiongyingqi.jackson.annotation;import java.lang.annotation.*;/** * 只允许pojo内的属性序列化成json，对于同一个pojo该注解是与IgnoreProperty是冲突的&lt;br&gt; * * @author 瑛琪 &lt;a href="http://xiongyingqi.com"&gt;xiongyingqi.com&lt;/a&gt; * @version 2013-10-30 下午3:57:35 */@Documented@Target(&#123;ElementType.TYPE, ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface AllowProperty &#123; /** * 目标POJO &lt;br&gt; * 2013-9-27 下午4:27:08 * * @return */ Class&lt;?&gt; pojo(); /** * 允许序列化的属性名 &lt;br&gt; * 2013-9-27 下午4:27:12 * * @return */ String[] name();&#125;核心处理类，用于处理自定义注解并将生成的类存入当前线程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474package com.xiongyingqi.jackson.impl;import com.fasterxml.jackson.annotation.JsonIgnoreProperties;import com.fasterxml.jackson.core.JsonEncoding;import com.fasterxml.jackson.databind.ObjectMapper;import com.xiongyingqi.jackson.FilterPropertyHandler;import com.xiongyingqi.jackson.annotation.AllowProperty;import com.xiongyingqi.jackson.annotation.IgnoreProperties;import com.xiongyingqi.jackson.annotation.IgnoreProperty;import com.xiongyingqi.jackson.helper.ThreadJacksonMixInHolder;import com.xiongyingqi.util.EntityHelper;import com.xiongyingqi.util.StringHelper;import javassist.CannotCompileException;import javassist.ClassPool;import javassist.CtClass;import javassist.bytecode.AnnotationsAttribute;import javassist.bytecode.ClassFile;import javassist.bytecode.ConstPool;import javassist.bytecode.annotation.*;import org.apache.log4j.Logger;import org.springframework.http.MediaType;import org.springframework.web.bind.annotation.ResponseBody;import java.lang.reflect.Method;import java.nio.charset.Charset;import java.util.*;import java.util.Map.Entry;//@IgnoreProperty(pojo = YxUserRoleRelation.class, name = &#123; "id", "yxUser" &#125;)/** * 使用代理来创建jackson的MixInAnnotation注解接口&lt;br&gt; * 如果使用本实现方法，一定要配置在web.xml中配置过滤器WebContextFilter，否则无法输出json到客户端 * * @author 瑛琪 &lt;a href="http://xiongyingqi.com"&gt;xiongyingqi.com&lt;/a&gt; * @version 2013-10-25 下午2:31:21 */public class JavassistFilterPropertyHandler implements FilterPropertyHandler &#123; public static final Logger LOGGER = Logger.getLogger(JavassistFilterPropertyHandler.class); /** * 注解的方法对应生成的代理类映射表 */ private static Map&lt;Method, Map&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt; proxyMethodMap = new HashMap&lt;Method, Map&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt;(); /** * String数组的hashCode与生成的对应的代理类的映射表 */ private static Map&lt;Integer, Class&lt;?&gt;&gt; proxyMixInAnnotationMap = new HashMap&lt;Integer, Class&lt;?&gt;&gt;(); private static String[] globalIgnoreProperties = new String[]&#123;"hibernateLazyInitializer", "handler" &#125;; /** * 如果是标注的SpringMVC中的Controller方法，则应判断是否注解了@ResponseBody */ private boolean isResponseBodyAnnotation; /** * 创建代理接口的唯一值索引 */ private static int proxyIndex; public JavassistFilterPropertyHandler() &#123; &#125; public JavassistFilterPropertyHandler(String[] globalIgnoreProperties) &#123; JavassistFilterPropertyHandler.globalIgnoreProperties = globalIgnoreProperties; &#125; /** * @param isResponseBodyAnnotation 如果是标注的SpringMVC中的Controller方法，则应判断是否注解了@ResponseBody */ public JavassistFilterPropertyHandler(boolean isResponseBodyAnnotation) &#123; this.isResponseBodyAnnotation = isResponseBodyAnnotation; &#125; /** * &lt;br&gt; * 2013-10-28 上午11:11:24 * * @param collection * @param names * @return */ private Collection&lt;String&gt; checkAndPutToCollection(Collection&lt;String&gt; collection, String[] names) &#123; if (collection == null) &#123; collection = new HashSet&lt;String&gt;(); &#125; Collections.addAll(collection, names); return collection; &#125; private Collection&lt;String&gt; putGlobalIgnoreProperties(Collection&lt;String&gt; collection) &#123; if (globalIgnoreProperties != null) &#123; if (collection == null) &#123; collection = new HashSet&lt;String&gt;(); &#125; for (int i = 0; i &lt; globalIgnoreProperties.length; i++) &#123; String name = globalIgnoreProperties[i]; collection.add(name); &#125; &#125; return collection; &#125; /** * 处理IgnoreProperties注解 &lt;br&gt; * 2013-10-30 下午6:15:41 * * @param properties * @param pojoAndNamesMap */ private void processIgnorePropertiesAnnotation(IgnoreProperties properties, Map&lt;Class&lt;?&gt;, Collection&lt;String&gt;&gt; pojoAndNamesMap) &#123; IgnoreProperty[] values = properties.value(); AllowProperty[] allowProperties = properties.allow(); if (allowProperties != null) &#123; for (AllowProperty allowProperty : allowProperties) &#123; processAllowPropertyAnnotation(allowProperty, pojoAndNamesMap); &#125; &#125; if (values != null) &#123; for (IgnoreProperty property : values) &#123; processIgnorePropertyAnnotation(property, pojoAndNamesMap); &#125; &#125; &#125; /** * 处理IgnoreProperty注解 &lt;br&gt; * 2013-10-30 下午6:16:08 * * @param property * @param pojoAndNamesMap */ private void processIgnorePropertyAnnotation(IgnoreProperty property, Map&lt;Class&lt;?&gt;, Collection&lt;String&gt;&gt; pojoAndNamesMap) &#123; String[] names = property.name(); Class&lt;?&gt; pojoClass = property.pojo(); // Class&lt;?&gt; proxyAnnotationInterface = createMixInAnnotation(names);// // 根据注解创建代理接口 Collection&lt;String&gt; nameCollection = pojoAndNamesMap.get(pojoClass); nameCollection = checkAndPutToCollection(nameCollection, names); pojoAndNamesMap.put(pojoClass, nameCollection); &#125; /** * 处理AllowProperty注解 &lt;br&gt; * 2013-10-30 下午6:16:08 * * @param property * @param pojoAndNamesMap */ private void processAllowPropertyAnnotation(AllowProperty property, Map&lt;Class&lt;?&gt;, Collection&lt;String&gt;&gt; pojoAndNamesMap) &#123; String[] allowNames = property.name(); Class&lt;?&gt; pojoClass = property.pojo(); Collection&lt;String&gt; ignoreProperties = EntityHelper .getUnstaticClassFieldNameCollection(pojoClass); Collection&lt;String&gt; allowNameCollection = new ArrayList&lt;String&gt;(); Collections.addAll(allowNameCollection, allowNames); Collection&lt;String&gt; nameCollection = pojoAndNamesMap.get(pojoClass); if (nameCollection != null) &#123; nameCollection.removeAll(allowNameCollection); &#125; else &#123; ignoreProperties.removeAll(allowNameCollection); nameCollection = ignoreProperties; &#125; pojoAndNamesMap.put(pojoClass, nameCollection); &#125; /** * 根据方法获取过滤映射表 &lt;br&gt; * 2013-10-25 下午2:47:34 * * @param method 注解了 @IgnoreProperties 或 @IgnoreProperty 的方法（所在的类） * @return Map&lt;Class&lt;?&gt;, Collection&lt;Class&lt;?&gt;&gt;&gt; pojo与其属性的映射表 */ public Map&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt; getProxyMixInAnnotation(Method method) &#123; if (isResponseBodyAnnotation &amp;&amp; !method.isAnnotationPresent(ResponseBody.class)) &#123; return null; &#125; Map&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt; map = proxyMethodMap.get(method);// 从缓存中查找是否存在 if (map != null &amp;&amp; map.entrySet().size() &gt; 0) &#123;// 如果已经读取该方法的注解信息，则从缓存中读取 return map; &#125; else &#123; map = new HashMap&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;(); &#125; Class&lt;?&gt; clazzOfMethodIn = method.getDeclaringClass();// 方法所在的class Map&lt;Class&lt;?&gt;, Collection&lt;String&gt;&gt; pojoAndNamesMap = new HashMap&lt;Class&lt;?&gt;, Collection&lt;String&gt;&gt;(); IgnoreProperties classIgnoreProperties = clazzOfMethodIn .getAnnotation(IgnoreProperties.class); IgnoreProperty classIgnoreProperty = clazzOfMethodIn.getAnnotation(IgnoreProperty.class); AllowProperty classAllowProperty = clazzOfMethodIn.getAnnotation(AllowProperty.class); IgnoreProperties ignoreProperties = method.getAnnotation(IgnoreProperties.class); IgnoreProperty ignoreProperty = method.getAnnotation(IgnoreProperty.class); AllowProperty allowProperty = method.getAnnotation(AllowProperty.class); if (allowProperty != null) &#123;// 方法上的AllowProperty注解 processAllowPropertyAnnotation(allowProperty, pojoAndNamesMap); &#125; if (classAllowProperty != null) &#123; processAllowPropertyAnnotation(classAllowProperty, pojoAndNamesMap); &#125; if (classIgnoreProperties != null) &#123;// 类上的IgnoreProperties注解 processIgnorePropertiesAnnotation(classIgnoreProperties, pojoAndNamesMap); &#125; if (classIgnoreProperty != null) &#123;// 类上的IgnoreProperty注解 processIgnorePropertyAnnotation(classIgnoreProperty, pojoAndNamesMap); &#125; if (ignoreProperties != null) &#123;// 方法上的IgnoreProperties注解 processIgnorePropertiesAnnotation(ignoreProperties, pojoAndNamesMap); &#125; if (ignoreProperty != null) &#123;// 方法上的IgnoreProperties注解 processIgnorePropertyAnnotation(ignoreProperty, pojoAndNamesMap); &#125; Set&lt;Entry&lt;Class&lt;?&gt;, Collection&lt;String&gt;&gt;&gt; entries = pojoAndNamesMap.entrySet(); for (Iterator&lt;Entry&lt;Class&lt;?&gt;, Collection&lt;String&gt;&gt;&gt; iterator = entries.iterator(); iterator .hasNext(); ) &#123; Entry&lt;Class&lt;?&gt;, Collection&lt;String&gt;&gt; entry = (Entry&lt;Class&lt;?&gt;, Collection&lt;String&gt;&gt;) iterator .next(); Collection&lt;String&gt; nameCollection = entry.getValue(); nameCollection = putGlobalIgnoreProperties(nameCollection);// 将全局过滤字段放入集合内 String[] names = nameCollection.toArray(new String[]&#123;&#125;); // EntityHelper.print(entry.getKey()); // for (int i = 0; i &lt; names.length; i++) &#123; // String name = names[i]; // EntityHelper.print(name); // &#125; Class&lt;?&gt; clazz = createMixInAnnotation(names); map.put(entry.getKey(), clazz); &#125; proxyMethodMap.put(method, map); return map; &#125; /** * 创建jackson的代理注解接口类 &lt;br&gt; * 2013-10-25 上午11:59:50 * * @param names 要生成的字段 * @return 代理接口类 */ private Class&lt;?&gt; createMixInAnnotation(String[] names) &#123; Class&lt;?&gt; clazz = null; clazz = proxyMixInAnnotationMap.get(StringHelper.hashCodeOfStringArray(names)); if (clazz != null) &#123; return clazz; &#125; ClassPool pool = ClassPool.getDefault(); // 创建代理接口 CtClass cc = pool.makeInterface("ProxyMixInAnnotation" + System.currentTimeMillis() + proxyIndex++); ClassFile ccFile = cc.getClassFile(); ConstPool constpool = ccFile.getConstPool(); // create the annotation AnnotationsAttribute attr = new AnnotationsAttribute(constpool, AnnotationsAttribute.visibleTag); // 创建JsonIgnoreProperties注解 Annotation jsonIgnorePropertiesAnnotation = new Annotation( JsonIgnoreProperties.class.getName(), constpool); BooleanMemberValue ignoreUnknownMemberValue = new BooleanMemberValue(false, constpool); ArrayMemberValue arrayMemberValue = new ArrayMemberValue(constpool);// value的数组成员 Collection&lt;MemberValue&gt; memberValues = new HashSet&lt;MemberValue&gt;(); for (int i = 0; i &lt; names.length; i++) &#123; String name = names[i]; StringMemberValue memberValue = new StringMemberValue(constpool);// 将name值设入注解内 memberValue.setValue(name); memberValues.add(memberValue); &#125; arrayMemberValue.setValue(memberValues.toArray(new MemberValue[]&#123;&#125;)); jsonIgnorePropertiesAnnotation.addMemberValue("value", arrayMemberValue); jsonIgnorePropertiesAnnotation.addMemberValue("ignoreUnknown", ignoreUnknownMemberValue); attr.addAnnotation(jsonIgnorePropertiesAnnotation); ccFile.addAttribute(attr); // generate the class try &#123; clazz = cc.toClass(); proxyMixInAnnotationMap.put(StringHelper.hashCodeOfStringArray(names), clazz); // JsonIgnoreProperties ignoreProperties = (JsonIgnoreProperties) // clazz // .getAnnotation(JsonIgnoreProperties.class); // EntityHelper.print(ignoreProperties); // // EntityHelper.print(clazz); // try &#123; // Object instance = clazz.newInstance(); // EntityHelper.print(instance); // // &#125; catch (InstantiationException e) &#123; // e.printStackTrace(); // &#125; catch (IllegalAccessException e) &#123; // e.printStackTrace(); // &#125; &#125; catch (CannotCompileException e) &#123; e.printStackTrace(); &#125; // right // mthd.getMethodInfo().addAttribute(attr); return clazz; &#125; @Override public Object filterProperties(Method method, Object object) &#123; Map&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt; map = getProxyMixInAnnotation(method); if (map == null || map.entrySet().size() == 0) &#123;// 如果该方法上没有注解，则返回原始对象 return object; &#125;// Set&lt;Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt; entries = map.entrySet();// for (Iterator&lt;Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt; iterator = entries.iterator(); iterator.hasNext();) &#123;// Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt; entry = (Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;) iterator.next();// // EntityHelper.print(entry.getKey());// Class&lt;?&gt; clazz = entry.getValue();// // EntityHelper.print(clazz.getAnnotation(JsonIgnoreProperties.class));// &#125;// ObjectMapper mapper = createObjectMapper(map); ThreadJacksonMixInHolder.addMixIns(getEntries(map));// try &#123;// HttpServletResponse response = WebContext.getInstance().getResponse();// writeJson(mapper, response, object);// &#125; catch (WebContextAlreadyClearedException e) &#123;// e.printStackTrace();// &#125; return object; &#125; public Set&lt;Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt; getEntries(Map&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt; map) &#123; Set&lt;Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt; entries = map.entrySet(); return entries; &#125; /** * 根据指定的过滤表创建jackson对象 &lt;br&gt; * 2013-10-25 下午2:46:43 * * @param map 过滤表 * @return ObjectMapper */ private ObjectMapper createObjectMapper(Map&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt; map) &#123; ObjectMapper mapper = new ObjectMapper(); Set&lt;Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt; entries = map.entrySet(); for (Iterator&lt;Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt; iterator = entries.iterator(); iterator.hasNext(); ) &#123; Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt; entry = iterator.next(); mapper.addMixInAnnotations(entry.getKey(), entry.getValue()); &#125; return mapper; &#125; /** * 根据方法上的注解生成objectMapper * * @param method * @return */ public ObjectMapper createObjectMapper(Method method) &#123; return createObjectMapper(getProxyMixInAnnotation(method)); &#125;// /**// * 将结果输出到response &lt;br&gt;// * 2013-10-25 下午2:28:40// *// * @param objectMapper// * @param response// * @param object// */// private void writeJson(ObjectMapper objectMapper, HttpServletResponse response, Object object) &#123;// response.setContentType("application/json");//// JsonEncoding encoding = getJsonEncoding(response.getCharacterEncoding());// JsonGenerator jsonGenerator = null;// try &#123;// jsonGenerator = objectMapper.getJsonFactory().createJsonGenerator(// response.getOutputStream(), encoding);// &#125; catch (IOException e1) &#123;// e1.printStackTrace();// &#125;//// // A workaround for JsonGenerators not applying serialization features// // https://github.com/FasterXML/jackson-databind/issues/12// if (objectMapper.isEnabled(SerializationFeature.INDENT_OUTPUT)) &#123;// jsonGenerator.useDefaultPrettyPrinter();// &#125;//// try &#123;// objectMapper.writeValue(jsonGenerator, object);// &#125; catch (JsonProcessingException ex) &#123;// LOGGER.error(ex);//// throw new HttpMessageNotWritableException("Could not write JSON: " + ex.getMessage(),// ex);// &#125; catch (IOException e) &#123;// LOGGER.error(e);// // e.printStackTrace();// &#125;//// &#125; /** * &lt;br&gt; * 2013-10-25 下午12:29:58 * * @param characterEncoding * @return */ private JsonEncoding getJsonEncoding(String characterEncoding) &#123; for (JsonEncoding encoding : JsonEncoding.values()) &#123; if (characterEncoding.equals(encoding.getJavaName())) &#123; return encoding; &#125; &#125; return JsonEncoding.UTF8; &#125; /** * Determine the JSON encoding to use for the given content type. * * @param contentType the media type as requested by the caller * @return the JSON encoding to use (never &#123;@code null&#125;) */ protected JsonEncoding getJsonEncoding(MediaType contentType) &#123; if (contentType != null &amp;&amp; contentType.getCharSet() != null) &#123; Charset charset = contentType.getCharSet(); for (JsonEncoding encoding : JsonEncoding.values()) &#123; if (charset.name().equals(encoding.getJavaName())) &#123; return encoding; &#125; &#125; &#125; return JsonEncoding.UTF8; &#125;&#125;线程持有类，用于在当前线程内保存核心类处理过的自定义注解生成的MixIn注解，并且能提供ObjectMapper的生成123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125package com.xiongyingqi.jackson.helper;import com.fasterxml.jackson.databind.ObjectMapper;import java.util.HashSet;import java.util.Map;import java.util.Set;/** * 在当前线程内保存ObjectMapper供Jackson2HttpMessageConverter使用 * Created by 瑛琪&lt;a href="http://xiongyingqi.com"&gt;xiongyingqi.com&lt;/a&gt; on 2014/4/1 0001. */public class ThreadJacksonMixInHolder &#123; private static ThreadLocal&lt;ThreadJacksonMixInHolder&gt; holderThreadLocal = new ThreadLocal&lt;ThreadJacksonMixInHolder&gt;(); private Set&lt;Map.Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt; mixIns; private ObjectMapper mapper; private org.codehaus.jackson.map.ObjectMapper codehausMapper; /** * 根据当前MixIn集合生成objectMapper&lt;p&gt; * &lt;p/&gt; * &lt;b&gt;注意：该方法在返回mapper对象之后调用clear方法，如果再次调用builderMapper()肯定会保存&lt;/b&gt; * * @return */ public static ObjectMapper builderMapper() &#123; ThreadJacksonMixInHolder holder = holderThreadLocal.get(); if (holder.mapper == null &amp;&amp; isContainsMixIn()) &#123; holder.mapper = new ObjectMapper(); for (Map.Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt; mixIn : holder.mixIns) &#123; holder.mapper.addMixInAnnotations(mixIn.getKey(), mixIn.getValue()); &#125; &#125; clear();// 如果不调用clear可能导致线程内的数据是脏的！ return holder.mapper; &#125; /** * 根据当前MixIn集合生成objectMapper * * @return */ public static org.codehaus.jackson.map.ObjectMapper builderCodehausMapper() &#123; ThreadJacksonMixInHolder holder = holderThreadLocal.get(); if (holder.codehausMapper == null &amp;&amp; isContainsMixIn()) &#123; holder.codehausMapper = new org.codehaus.jackson.map.ObjectMapper(); for (Map.Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt; mixIn : holder.mixIns) &#123; holder.codehausMapper.getDeserializationConfig().addMixInAnnotations(mixIn.getKey(), mixIn.getValue()); holder.codehausMapper.getSerializationConfig().addMixInAnnotations(mixIn.getKey(), mixIn.getValue()); &#125; &#125; clear();// 如果不调用clear可能导致线程内的数据是脏的！ return holder.codehausMapper; &#125; /** * 清除当前线程内的数据 */ public static void clear() &#123; holderThreadLocal.set(null);// holderThreadLocal.remove(); &#125; /** * 设置MixIn集合到线程内，如果线程内已经存在数据，则会先清除 * * @param resetMixIns */ public static void setMixIns(Set&lt;Map.Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt; resetMixIns) &#123; ThreadJacksonMixInHolder holder = holderThreadLocal.get(); if (holder == null) &#123; holder = new ThreadJacksonMixInHolder(); holderThreadLocal.set(holder); &#125; holder.mixIns = resetMixIns; &#125; /** * 不同于setMixIns，addMixIns为增加MixIn集合到线程内，即不会清除已经保存的数据 * &lt;br&gt;2014年4月4日 下午12:08:15 * * @param toAddMixIns */ public static void addMixIns(Set&lt;Map.Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt; toAddMixIns) &#123; ThreadJacksonMixInHolder holder = holderThreadLocal.get(); if (holder == null) &#123; holder = new ThreadJacksonMixInHolder(); holderThreadLocal.set(holder); &#125; if (holder.mixIns == null) &#123; holder.mixIns = new HashSet&lt;Map.Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt;(); &#125; holder.mixIns.addAll(toAddMixIns); &#125; /** * 获取线程内的MixIn集合&lt;p&gt;&lt;/p&gt; * &lt;b&gt;注意：为了防止线程执行完毕之后仍然存在有数据，请务必适时调用clear()方法&lt;/b&gt; * * @return * @see com.xiongyingqi.jackson.helper.ThreadJacksonMixInHolder#builderMapper() * @see com.xiongyingqi.jackson.helper.ThreadJacksonMixInHolder#builderCodehausMapper() * @see com.xiongyingqi.jackson.helper.ThreadJacksonMixInHolder#clear() */ public static Set&lt;Map.Entry&lt;Class&lt;?&gt;, Class&lt;?&gt;&gt;&gt; getMixIns() &#123; ThreadJacksonMixInHolder holder = holderThreadLocal.get(); return holder.mixIns; &#125; /** * 判断当前线程是否存在MixIn集合 * * @return */ public static boolean isContainsMixIn() &#123; if (holderThreadLocal.get() == null) &#123; return false; &#125; if (holderThreadLocal.get().mixIns != null &amp;&amp; holderThreadLocal.get().mixIns.size() &gt; 0) &#123; return true; &#125; return false; &#125;&#125;测试测试代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package com.xiongyingqi.jackson;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.xiongyingqi.jackson.annotation.IgnoreProperties;import com.xiongyingqi.jackson.annotation.IgnoreProperty;import com.xiongyingqi.jackson.helper.ThreadJacksonMixInHolder;import com.xiongyingqi.jackson.impl.JavassistFilterPropertyHandler;import com.xiongyingqi.jackson.pojo.Group;import com.xiongyingqi.jackson.pojo.User;import com.xiongyingqi.util.Assert;import com.xiongyingqi.util.EntityHelper;import org.junit.Test;import java.util.ArrayList;import java.util.Collection;/** * Created by 瑛琪&lt;a href="http://xiongyingqi.com"&gt;xiongyingqi.com&lt;/a&gt; on 2014/6/4 0004. */public class JsonFilterPropertyTest &#123; @IgnoreProperties(@IgnoreProperty(pojo = User.class, name = "id")) public Collection&lt;User&gt; listUsers() &#123; Group group1 = new Group(); group1.setId(1); group1.setName("分组1"); User user1 = new User(); user1.setId(1); user1.setGroup(group1); user1.setName("用户1"); User user2 = new User(); user2.setId(1); user2.setGroup(group1); user2.setName("用户1"); User user3 = new User(); user3.setId(1); user3.setName("用户1"); user3.setGroup(group1); Group group2 = new Group(); group2.setId(2); group2.setName("分组2"); User user4 = new User(); user4.setId(4); user4.setGroup(group2); user4.setName("用户4"); User user5 = new User(); user5.setId(5); user5.setGroup(group2); user5.setName("用户5"); User user6 = new User(); user6.setId(6); user6.setName("用户6"); user6.setGroup(group2); Collection&lt;User&gt; users = new ArrayList&lt;User&gt;(); users.add(user1); users.add(user2); users.add(user3); users.add(user4); users.add(user5); users.add(user6); return users; &#125; @Test public void jsonTest() throws NoSuchMethodException, JsonProcessingException &#123; FilterPropertyHandler filterPropertyHandler = new JavassistFilterPropertyHandler(false); Object object = listUsers(); object = filterPropertyHandler.filterProperties(JsonFilterPropertyTest.class.getMethod("listUsers"), object); ObjectMapper mapper = ThreadJacksonMixInHolder.builderMapper(); String json = mapper.writeValueAsString(object); EntityHelper.print(json); Assert.hasText(json); &#125;&#125;测试结果at com.xiongyingqi.jackson.JsonFilterPropertyTest.jsonTest(JsonFilterPropertyTest.java:80) String =============== [{&quot;name&quot;:&quot;用户1&quot;,&quot;group&quot;:{&quot;id&quot;:1,&quot;name&quot;:&quot;分组1&quot;}},{&quot;name&quot;:&quot;用户1&quot;,&quot;group&quot;:{&quot;id&quot;:1,&quot;name&quot;:&quot;分组1&quot;}},{&quot;name&quot;:&quot;用户1&quot;,&quot;group&quot;:{&quot;id&quot;:1,&quot;name&quot;:&quot;分组1&quot;}},{&quot;name&quot;:&quot;用户4&quot;,&quot;group&quot;:{&quot;id&quot;:2,&quot;name&quot;:&quot;分组2&quot;}},{&quot;name&quot;:&quot;用户5&quot;,&quot;group&quot;:{&quot;id&quot;:2,&quot;name&quot;:&quot;分组2&quot;}},{&quot;name&quot;:&quot;用户6&quot;,&quot;group&quot;:{&quot;id&quot;:2,&quot;name&quot;:&quot;分组2&quot;}}] 性能与缺陷主要是在map内存储了Javassist的临时类，每个注解(IgnoreProperties等)的方法的调用，对应在FilterPropertyHandler会处理一次注解并在内存内产生一个Javassist临时类，但是访问过一次之后该类就会读取map缓存ThreadJacksonMixInHolder：这个类的原理就是使用ThreadLocal在当前线程内存储处理过的annotation注解，java的容器或框架都是使用了该类，导致的效率问题应该不大未知的bug其他说明其他框架内使用如果不是spring-mvc框架也能使用这些代码来解决，只是必须要修改aop的捕获方法、使用new JavassistFilterPropertyHandler(false)禁用ResponseBody，以及在ObjectMapper输出使用自己定义的输出源代码地址代码已上传到maven中央库：http://mvnrepository.com/artifact/com.xiongyingqi/common_helperMaven Usage:12345&lt;dependency&gt; &lt;groupId&gt;com.xiongyingqi&lt;/groupId&gt; &lt;artifactId&gt;common_helper&lt;/artifactId&gt; &lt;version&gt;$&#123;common_utils.version&#125;&lt;/version&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>javassist</tag>
        <tag>spring-mvc</tag>
        <tag>jackson</tag>
        <tag>循环</tag>
        <tag>springmvc</tag>
        <tag>spring</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux安装Samba文件共享服务器]]></title>
    <url>%2F2014%2F01%2F05%2F2014-01-06-samba-linux-attentions%2F</url>
    <content type="text"><![CDATA[#Linux安装Samba文件共享服务器Samba相对于Windows服务器来说具有更灵活的配置、高效等特点。个人认为是共享服务器的最佳选择。安装samba：1yum install sambaubuntu下yum对应命令为：1apt-get install sambasamba主要配置文件在/etc/samba/smb.conf中123456789101112131415161718192021[global] realm = 192.168.0.2 netbios name = SAMBA-SERVER netbios aliases = SAMBA-SERVER server string = Samba-Server security = SHARE log file = /var/log/samba/%m.log max log size = 50 os level = 0 wins proxy = Yes wins support = Yes idmap config * : backend = tdb hosts allow = 127., 192. cups options = raw[test] comment = test path = /home/share/test read only = No create mask = 0777 directory mask = 0777注意其中比较要注意的是global中的security和hosts allow两个选项：security代表验证权限的机制，我一般使用share和user级别，这两种方式其实没多大区别~无非是先登录再查看还是先查看再登录的区别而已（注意：Linux的目录）如果服务器共享了哪些文件夹是不怕公布并且多个部门使用同一个服务器以及各部门需要相互查看的话，建议使用share的方式，这样会极大的方便公司同事在windows中切换帐号。hosts allow代表了哪些前缀的ip地址能访问服务器。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Samba</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux使用shell脚本定时备份文件（夹）并删除一定日期之前的备份和日志]]></title>
    <url>%2F2014%2F01%2F03%2F2014-01-04-linux-backup-shell%2F</url>
    <content type="text"><![CDATA[备份的原理使用Linux的Cron程序定时执行该脚本从而达到备份和删除备份历史的目的。主要参数脚本主要需要设置参数有三个：ORIGIN_FOLDER：要备份的目录，必须以\结尾DES_FOLDER：备份文件存储路径（可以是网络路径，前提是必须要有权限管理该路径下的文件夹）DAYS_AGO：该参数表示要删除多少天之前的备份（比如今天是2012年12月31日，那么20121221的文件不会被删除，20121220或比之小的文件夹将会被删除）脚本BackUpTask.shell12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#!/bin/sh#---------------------------------------------------------------------# shell自动备份文件夹同时检查一定日期前的文件夹并删除# 部署好本脚本后应当在linux中设置cron自动执行：# 1、在linux的/etc/cron.d/目录下新建空文件# 2、使用"crontab -e"编辑新的定时任务并保存# 3、chkconfig crond on# （注意：在cron模式下文件操作必须使用绝对路径）# --by: Blademainer#---------------------------------------------------------------------#设置要备份的目录，多个文件夹以逗号分隔ORIGIN_FOLDER=test,testlog#设置备份文件的存储目录，可以是绝对路径DES_FOLDER=bak#设置删除多少天之前的备份DAYS_AGO=10#定义日期变量，时间戳的单位以秒为单位SECOND=1MINUTE=$((60*$SECOND))HOUR=$((60*$MINUTE))DAY=$((24*$HOUR))WEEK=$((7*$DAY))#time1=$(($(date +%s -d '2010-01-01') - $(date +%s -d '2009-01-01')));# 计算时间戳，以秒为单位#time2=$(($(date +%s -d '2013-12-30 11:57:39')));# 计算时间戳，以秒为单位#time3=$(($(date +%s -d "$(date +'%Y-%m-%d %H:%M:%S')")));# 计算时间戳，以秒为单位#echo $time3#echo $time2#echo $(($time1/$DAY))#当前日期的字符串表达形式NOW=$(date +'%Y-%m-%d_%H%M%S')#echo $NOW#TEN_DAYS_AGO=$(($(date -d '-10 day' "+%Y%m%d%H%M%S")))#echo 十天之前$TEN_DAYS_AGO#计算当前时间的时间戳表达方法TIME_NOW=$(($(date +%s -d "$(date +'%Y-%m-%d %H:%M:%S')")))SECONDS_OF_DAYS_AGO=$(($DAYS_AGO * $DAY))#计算指定天数前的时间戳表达方法TIME_AGO=$(($TIME_NOW - $SECONDS_OF_DAYS_AGO))#echo $TIME_NOW#echo TIME_AGO============$TIME_AGO#判断传入的日期是否在设置的日期之前function isDaysBefore()&#123; DATE=$(($(date +%s -d $1))) if [[ $DATE &lt; $TIME_AGO ]] then echo 1 else echo 0 fi&#125;#检验文件夹if [ ! -d "$DES_FOLDER" ]; then echo `mkdir $DES_FOLDER`fiDES_PATH=$DES_FOLDER/$NOW/if [ ! -d "$DES_PATH" ]; then echo `mkdir $DES_PATH`fiif [ ! -f "$DES_FOLDER/$NOW/$NOW.log" ]; then echo `touch $DES_FOLDER/$NOW/$NOW.log`fi#拷贝文件夹var=`echo "$ORIGIN_FOLDER"|awk -F ',' '&#123;print $0&#125;' | sed "s/,/ /g"`for VAR_ORIGIN_FOLDER in $var; do command=`cp -rf $VAR_ORIGIN_FOLDER $DES_PATH`done#删除备份文件夹for FOLDER in `ls $DES_FOLDER`; do #截取年月日 folder_date=`expr substr $FOLDER 1 10` if [[ $(isDaysBefore $folder_date) == 1 ]] then echo `rm -fr $DES_FOLDER/$FOLDER` fidone]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows使用bat脚本定时备份文件（夹）并删除一定日期之前的备份和日志]]></title>
    <url>%2F2014%2F01%2F03%2F2014-01-04-windows-backup-bat%2F</url>
    <content type="text"><![CDATA[备份的原理使用windows的任务计划程序定时执行该脚本从而达到备份和删除备份历史的目的。主要参数脚本主要需要设置参数有四个：bakPath：要备份的目录，必须以\结尾bakTargetPath：备份文件存储路径（可以是网络路径，前提是必须要有权限管理该路径下的文件夹）DaysAgo：该参数表示要删除多少天之前的备份（比如今天是2012年12月31日，那么20121221的文件不会被删除，20121220或比之小的文件夹将会被删除）logDaysAgo：该参数表示要删除多少天之前的日志文件脚本BackUpTask.bat123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174:: ------------------------------------------------------------------------ :: 自动备份及清除文件夹脚本说明:: 本脚本能备份指定文件夹下的所有文件夹并以日期的形式来存放每次备份的文件夹，:: 同时，能删除指定时间之前的备份文件夹。如果要使本脚本能按一定间隔时间来执行:: 此脚本，那么请在系统定时任务内创建一个任务，并设置好执行时间，然后指定执行:: 此脚本即可。:: 注意：由于定时任务执行的方式与直接点击执行脚本的方式有很大差别（对于定时任:: 务来说，脚本的相对路径其实就是相对于cmd.exe来说的路径），所以必须使用绝对:: 路径的方式来进行拷贝。:: 具体设置的参数：（所有的目录路径必须以\结尾）:: bakPath 要备份的目录，必须以\结尾:: bakTargetPath 备份文件存储路径（可以是网络路径，前提是必须要有权限管理该路径下的文件夹）:: DaysAgo 该参数表示要删除多少天之前的备份（比如今天是2012年12月31日，那么20121221的文件不会被删除，20121220或比之小的文件夹将会被删除）:: logDaysAgo 该参数表示要删除多少天之前的日志文件:: --by Blademainer:: ------------------------------------------------------------------------ @echo off:: for /f "tokens=1-3 delims=- " %%1 in ("%date%") do set ttt=%%1%%2%%3:: for /f "tokens=1-3 delims=.: " %%1 in ("%time%") do set ttt=%ttt%-%%1%%2%%3:: 要备份的目录，必须以\结尾set bakPath=C:\Users\blademainer\Desktop\test\:: 备份文件存储路径（可以是网络路径，前提是必须要有权限管理该路径下的文件夹）set bakTargetPath=C:\Users\blademainer\Desktop\bak\:: 该参数表示要删除多少天之前的备份（比如今天是2012年12月31日，那么20121221的文件不会被删除，20121220或比之小的文件夹将会被删除）set DaysAgo=10:: 该参数表示要删除多少天之前的日志文件set logDaysAgo=%DaysAgo%:: ----------------------------------- 注意：除非你有足够的自信，否则不要变动以下参数 ----------------------------------- :: 日志存放路径set logDir=%bakTargetPath%\log\:: 截取日期函数set dateStr=%date:~0,4%%date:~5,2%%date:~8,2%:: 时间戳set timeStr=%time:~0,2%%time:~3,2%%time:~6,2%%time:~9,2%:: 得出的索引set indexStr=%dateStr%_%timeStr%:: 设置时间格式for /f "tokens=1-3 delims=- " %%1 in ("%time%") do set beautyTime=%%1%%2%%3:: 日志文件名set logFile=%logDir%%indexStr%.log:: 获取最后一个文件夹名称call :LastFolder %bakPath% bakName:: 备份所在文件夹（按日期分）set bakDataFolder=%bakTargetPath%%indexStr%\:: 备份后的路径set bakDataPath=%bakDataFolder%%bakName%\echo bakDataPath======%bakDataPath%:: 创建日志目录if not exist %logDir% mkdir %logDir%echo 开始备份文件夹echo ------------------ %date% %beautyTime% ------------------ &gt;&gt; %logFile%if not exist %bakDataPath% mkdir %bakDataPath%xcopy %bakPath%* %bakDataPath% /c/s/e/y/r &gt;&gt; %logFile%IF ERRORLEVEL 1 ECHO ------------------ 文件拷贝失败 ------------------ &gt;&gt; %logFile%IF ERRORLEVEL 0 ECHO ------------------ 文件拷贝成功 ------------------ &gt;&gt; %logFile%:: ------------------- 计算指定DaysAgo天之前的日期 ------------------- :: 日期的格式为yyyymmddcall :DateToDays %date:~0,4% %date:~5,2% %date:~8,2% PassDaysset /a PassDays-=%DaysAgo%call :DaysToDate %PassDays% DstYear DstMonth DstDayset DstDate=%DstYear%%DstMonth%%DstDay%echo %DaysAgo%天前的日期是%DstDate%:: ------------------- 计算指定logDaysAgo天之前的日期 ------------------- :: 日期的格式为yyyymmddcall :DateToDays %date:~0,4% %date:~5,2% %date:~8,2% logPassDaysset /a logPassDays-=%logDaysAgo%call :DaysToDate %logPassDays% DstYear DstMonth DstDayset logDstDate=%DstYear%%DstMonth%%DstDay%echo %logDaysAgo%天前的日期是%logDstDate%:: ------------------- 删除文件夹 ------------------- echo 开始删除数据文件夹echo 开始删除数据文件夹 &gt;&gt; %logFile%setlocal enabledelayedexpansionfor /f "delims=" %%s in ('dir /b /ad "%bakTargetPath%"') do ( set d=%%s set dateParse=!d:~0,8! echo 截取的日期为：!dateParse! set stDate=%DstDate% :: 如果该文件夹的日期小于该删除的备份日期，则删除该文件夹 set path=%bakTargetPath%!d! echo 当前的路径!path! if !dateParse! lss !stDate! call :DeleteDirectory !path!)echo 开始删除日志文件夹%logDir%echo 开始删除日志文件夹 &gt;&gt; %logFile%for /f "delims=" %%s in ('dir /a-d /b "%logDir%"') do ( set d=%%s set dateParse=!d:~0,8! echo 截取的日期为：!dateParse! set stDate=%logDstDate% :: 如果该文件夹的日期小于该删除的备份日期，则删除该文件夹 set path=%logDir%!d! echo 当前的路径!path! if !dateParse! lss !stDate! call :DeleteFile !path!)endlocal:: --------------------------- 结束--------------------------- goto :eof:: 根据路径计算最后一个文件夹:LastFolder %1 folderNameSetlocal ENABLEDELAYEDEXPANSIONset string=%1::定义路径分隔符set ch=\set last=%string:~-1%if "%last%"=="%ch%" (set "string=%string:~0,-1%")set str=%string%:nextif not "%str%"=="" ( if "!str:~-1!"=="%ch%" goto last set rsString=!str:~-1!%rsString% ::比较首字符是否为要求的字符，如果是则跳出循环 set "str=%str:~0,-1%" goto next):last::将空格去掉set rsString=%rsString: =%echo 结果：%rsString%endlocal&amp;set %2=%rsString%&amp;goto :EOF:: 删除文件夹:DeleteDirectory %1setlocal ENABLEEXTENSIONSecho ------------------ %1 ------------------rd /s /q %1echo ------------------ 成功删除文件夹: %1 ------------------ &gt;&gt; %logFile%endlocal&amp;goto :EOF:: 删除文件:DeleteFile %1setlocal ENABLEEXTENSIONSecho ------------------ %1 ------------------del /f /s /q /a %1echo ------------------ 成功删除文件: %1 ------------------ &gt;&gt; %logFile%endlocal&amp;goto :EOF::以下是计算日期使用:DateToDays %yy% %mm% %dd% dayssetlocal ENABLEEXTENSIONSset yy=%1&amp;set mm=%2&amp;set dd=%3if 1%yy% LSS 200 if 1%yy% LSS 170 (set yy=20%yy%) else (set yy=19%yy%)set /a dd=100%dd%%%100,mm=100%mm%%%100set /a z=14-mm,z/=12,y=yy+4800-z,m=mm+12*z-3,j=153*m+2set /a j=j/5+dd+y*365+y/4-y/100+y/400-2472633endlocal&amp;set %4=%j%&amp;goto :EOF:DaysToDate %days% yy mm ddsetlocal ENABLEEXTENSIONSset /a a=%1+2472632,b=4*a+3,b/=146097,c=-b*146097,c/=4,c+=aset /a d=4*c+3,d/=1461,e=-1461*d,e/=4,e+=c,m=5*e+2,m/=153,dd=153*m+2,dd/=5set /a dd=-dd+e+1,mm=-m/10,mm*=12,mm+=m+3,yy=b*100+d-4800+m/10(if %mm% LSS 10 set mm=0%mm%)&amp;(if %dd% LSS 10 set dd=0%dd%)endlocal&amp;set %2=%yy%&amp;set %3=%mm%&amp;set %4=%dd%&amp;goto :EOF:: 结束goto使用： goto :eof]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>bat</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java String对象的经典问题]]></title>
    <url>%2F2013%2F12%2F29%2F2013-12-30-java-string%2F</url>
    <content type="text"><![CDATA[先来看一个例子，代码如下：123456789101112131415public class Test &#123; public static void main(String[] args) &#123; String str = "abc"; String str1 = "abc"; String str2 = new String("abc"); System.out.println(str == str1); System.out.println(str1 == "abc"); System.out.println(str2 == "abc"); System.out.println(str1 == str2); System.out.println(str1.equals(str2)); System.out.println(str1 == str2.intern()); System.out.println(str2 == str2.intern()); System.out.println(str1.hashCode() == str2.hashCode()); &#125; &#125;如果您能对这8个输出结果直接判断出来，下面的分析就不用看了。但是我想还是有很多人对这个String对象这个问题只是表面的理解，下面就来分析一下Java语言String类和对象及其运行机制的问题。做个基础的说明，堆(heap)内存和栈(Stack)内存的问题。堆和栈的数据结构这里就不解释了。Java语言使用内存的时候，栈内存主要保存以下内容：基本数据类型和对象的引用，而堆内存存储对象，栈内存的速度要快于堆内存。总结成一句话就是：引用在栈而对象在堆。#Java中的比较有两种，是==和equals()方法，equals()是Object类的方法，定义在Object类中的equals()方法是如下实现的：123public boolean equals(Object obj)&#123; return (this==obj); &#125;String类重写了equals()方法，改变了这些类型对象相等的原则，即判断对象是否相等依据的原则为判断二者的内容是否相等。了解以上内容后我们来说说String，String类的本质是字符数组char[]，其次String类是final的，是不可被继承的，这点可能被大多数人忽略，再次String是特殊的封装类型，使用String时可以直接赋值，也可以用new来创建对象，但是这二者的实现机制是不同的。还有一个String池的概念，Java运行时维护一个String池，池中的String对象不可重复，没有创建，有则作罢。String池不属于堆和栈，而是属于常量池。下面分析上方代码的真正含义12String str = "abc"; String str1= "abc";第一句的真正含义是在String池中创建一个对象”abc”，然后引用时str指向池中的对象”abc”。第二句执行时，因为”abc”已经存在于String池了，所以不再创建，则str==str1返回true就明白了。str1==”abc”肯定正确了，在String池中只有一个”abc”，而str和str1都指向池中的”abc”，就是这个道理。1String str2 = new String("abc");这个是Java SE的热点问题，众所周知，单独这句话创建了2个String对象，而基于上面两句，只在栈内存创建str2引用，在堆内存上创建一个String对象，内容是”abc”，而str2指向堆内存对象的首地址。下面就是str2==”abc”的问题了，显然不对，”abc”是位于String池中的对象，而str2指向的是堆内存的String对象，==判断的是地址，肯定不等了。str1.equals(str2)，这个是对的，前面说过，String类的equals重写了Object类的equals()方法，实际就是判断内容是否相同了。下面说下intern()方法，在JavaDoc文档中，这样描述了intern()方法：返回字符串对象的规范化表示形式。怎么理解这句话？实际上过程是这样进行的：该方法现在String池中查找是否存在一个对象，存在了就返回String池中对象的引用。那么本例中String池存在”abc”，则调用intern()方法时返回的是池中”abc”对象引用，那么和str/str1都是等同的，和str2就不同了，因为str2指向的是堆内存。hashCode()方法是返回字符串内容的哈希码，既然内容相同，哈希码必然相同，那他们就相等了，这个容易理解。再看下面的例子：public class Test { private static String str = "abc"; public static void main(String[] args) { String str1 = "a"; String str2 = "bc"; String combo = str1 + str2; System.out.println(str == combo); System.out.println(str == combo.intern()); } } 这个例子用来说明用+连接字符串时，实际上是在堆内容创建对象，那么combo指向的是堆内存存储”abc”字符串的空间首地址，显然str==combo是错误的，而str==combo.intern()是正确的，在String池中也存在”abc”，那就直接返回了，而str也是指向String池中的”abc”对象的。此例说明任何重新修改String都是重新分配内存空间，这就使得String对象之间互不干扰。也就是String中的内容一旦生成不可改变，直至生成新的对象。同时问题也来了，使用+连接字符串每次都生成新的对象，而且是在堆内存上进行，而堆内存速度比较慢(相对而言)，那么再大量连接字符串时直接+是不可取的，当然需要一种效率高的方法。Java提供的StringBuffer和StringBuilder就是解决这个问题的。区别是前者是线程安全的而后者是非线程安全的，StringBuilder在JDK1.5之后才有。不保证安全的StringBuilder有比StringBuffer更高的效率。自JDK1.5之后，Java虚拟机执行字符串的+操作时，内部实现也是StringBuilder，之前采用StringBuffer实现。欢迎交流，希望对使用者有用。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[励志的鸡蛋]]></title>
    <url>%2F2013%2F12%2F27%2F2013-12-28-motivational-eggs%2F</url>
    <content type="text"><![CDATA[励志的鸡蛋]]></content>
      <categories>
        <category>philosophy</category>
      </categories>
      <tags>
        <tag>motivational</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BPMN2.0之使用Event Base Gateway启动流程]]></title>
    <url>%2F2013%2F11%2F28%2F2013-11-29-BPMN-2-Event-Base-Gateway-start%2F</url>
    <content type="text"><![CDATA[在上篇BPMN 2.0之Event Base Gateway（基于事件的网关）说了Event Base Gateway在流程流转中间的使用，Event Base Gateway的另一个用途是可以启动流程。当Event Base Gateway被设置成启动流程时，它的图标会改变同时上游也不允许有流入的Sequence Flow。下面是个例子：当上图的流程部署后，就会等待Email或电话请求。如果Email来了，就实例化一个流程实例，并从Task1开始执行。如果电话请求来了就再实例化一个流程实例从Task2开始执行。缺省设置下，启动流程的Event Base Gateway是互斥的。可以用多个Start Event达到同样效果：本人认为这种情况下，使用Start Event更直观也省画面空间。另外我们也可以设置启动流程的Event Base Gateway是并行的，如下图（注意Event Base Gateway图标的变化）：并行的Event Base Gateway在一个分支被激活并启动流程实例后，其他分支在启动的同一个流程实例中继续等待，如果在流程实例运行完成之前，其他分支也被激活，流程实例就多一条并行的流转分支。这种情况真还一时半会还想不出对应的业务情景，很复杂？！]]></content>
      <categories>
        <category>jbpm</category>
      </categories>
      <tags>
        <tag>BPMN</tag>
        <tag>Gateway</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 github 上建立 pages 的过程]]></title>
    <url>%2F2013%2F11%2F13%2F2013-11-14-create-github-page%2F</url>
    <content type="text"><![CDATA[建立项目-Repository首先在 GitHub 上建立自己库，例如一个 test 库;接着在本地建立 test 库的连接：Global Setup:Set up git git config --global user.name &quot;yourname&quot; git config --global user.email &quot;yourmail&quot; Next steps:mkdir Test cd Test git init touch README git add README git commit -m &apos;first commit&apos; git remote add origin git@github.com:yourname/Test.git git push -u origin master 通过在本地建立一个和 github 上相应的库，然后 push 上去，你随后可以在 github 上自己的 test 库里面看到你建立了一个 README 文件。这时候你的本地就和 github 连接上了。创建页面-pages进入 test 库，点击 Admin 菜单进入设置。这时候你就可以创建一个 page 了。创建的page 是一个页面，其路径为 http://yourname.github.com/testpages是怎么样的一个概念，你可以参考pages.github.com接着在本地创建相应的 pages 分支cd /path/to/fancypantsgit symbolic-ref HEAD refs/heads/gh-pagesrm .git/indexgit clean -fdx紧接着创建 gh-pages 分支并将内容提交到分支上echo “My GitHub Page” &gt; index.htmlgit add .git commit -a -m “First pages commit”git push origin gh-pages因为我们在 github 上系统已经为我们生成了一个好的 index.html,但我们在本地建立了一个，所以需要将本地的版本和线上的版本同步起来。//在本地：cd test//查看本地分支情况git branch//切换分支git checkout gh-pages//当你再次查看分支的时候，＊号就会在 gh-pages 前面//更新本地git pull origin gh-pages更新到本地之后，你就会看到你在 github 上的 index.html 文件//尝试着编辑，上传，更新看看vi index.html一些其他的内容简单的更新本地代码到 githubgit add . git commit -m &apos;test&apos; git push origin gh-pages jekyll 基本目录test |--- _layouts/ |--- default.html |--- post.html |--- _posts/ |--- 2011-09-22-title1 |--- 2011-09-22-title2 |--- css/ |--- base.css |--- sytle.css |--- _config.yml |--- index.html 一些函数数//页面相关 page.title page.content //内容 content //文章相关 post.title post.url post.date post.id post.categories post.tags post.tags post.content 一些对应的//一般都要 --- layout: post title: Hello world --- 有待补充的]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git/SVN常用命令笔记]]></title>
    <url>%2F2013%2F11%2F13%2F2013-11-14-github-notes%2F</url>
    <content type="text"><![CDATA[很久没有更新 GitHub 了，以至于那些熟悉的命令也忘记了。今天更新一下，最基础的一些命令，以备以后翻阅。加之最近工作团队需要，经常使用 SVN ，所有将 SVN 的常用命令也记在后面。以备后用。下载源码git clone xx@xx:/xxx.git 更新源码git pull 分支相关git branch --查看分支 git checkout -b name --创建分支 更新相关git add . -- 增加新的内容 git commit -m &apos;修改的信息&apos; -- 提交的内容的信息 git push -u origin master -- 将内容提交到主分支 Git状态git status 查看提交内容的差异git log -p -1(1是最新的一条) SVN相关将文件下载到本地svn checkout path(服务器上的目录) //简写 svn co 往版本库添加新文件svn add file(文件名) 提交文件到版本库svn commit -m &apos;logMassage&apos; (文件名) 加锁／解锁svn lock -m &apos;lockMessage&apos; (文件名) svn unlock path 更新到某个版本svn update -r m path -- m是版本号，path为文件名 //简写 svn up 查看文件或者目录状态svn status path 删除文件svn delete path -m &apos;delete message&apos; //简写 svn (del, remove, rm) 查看日志svn log path 比较差异svn diff 文件名 //简写 svn di]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 mac 上使用 Git 和 GitHub 连接]]></title>
    <url>%2F2013%2F11%2F13%2F2013-11-14-mac-git-and-github%2F</url>
    <content type="text"><![CDATA[记得之前写过一篇 win 下面使用 Git 的文章，今天写下一篇在 mac 下面的。首先，需要在 mac 下安装 git.mac git 的地址: http://code.google.com/p/git-osx-installer/ 由于可能这个网址访问不了，所以需要使用源码安装。安装好了 Git 之后，就开始设置 GitHub 连接了。1, 检查是否存在 ssh keys $ cd ~/.ssh 如果没有 .ssh 目录，请跳到第 3 步。 ##### 2, 如果有 .ssh 目录，请备份好你的 ssh key $ ls $ mkdir key_backup //创建备份文件夹 $ cp id_rsa* key_backup //移动你的 key 文件到备份文件夹 $ mr id_rsa* 3, 创建一个新的 ssh key $ ssh-keygen -t rsa -C "your_email@youremail.com" //记得输入你的github账号的 邮箱 //会输出下面语句 Generating public/private rsa key pair. Enter file in which to save the keys (/Users/your_user_directory/.ssh/id_rsa): //这里需要按下 enter 键就好 按下 enter 之后，又会出现下面的提示： Enter passphrase(empty for no passphrase): //输入一个密 码 Enter same passphrase again: 随后，你会收到一大串的提示，大概的意思是告诉你创建好了 id_rsa 和 id_rsa.pub 文件。4, 在 GitHub 上添加你的 ssh key到刚刚的 .ssh 目录下，找到 id_rsa.pub 文件，拷贝里面的内容，输入到你的GitHub 账户中的 Add key 区域。创建成功会有相应的提示。5, 验证你的 GitHub 连接 $ ssh -T git@github.com 如果验证成功，会有下面的提示： Hi username! You have successfully authenticated, but GitHub does not provide shell access.]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac 上安装 wget]]></title>
    <url>%2F2013%2F11%2F13%2F2013-11-14-mac-wget%2F</url>
    <content type="text"><![CDATA[1, 官网下载 wget, http://ftp.gnu.org/pub/gnu/wget/2, 解压，终端到文件目录下执行 ./configure3, sudo make install 完成注：需要在有 xcode 的前提下。]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>wget</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[css 背景透明解决方案]]></title>
    <url>%2F2013%2F11%2F13%2F2013-11-14-sl-alpha%2F</url>
    <content type="text"><![CDATA[废话一下：通常在网上搜索到的 CSS 透明的代码入下：.transparent {filter: alpha(opacity=50);/ IE6 /-moz-opacity: 0.5; / firefox /-khtml-opacity: 0.5; / safari /opacity: 0.5; / normal /}这段代码可以很轻松地解决透明的问题，只需要更改透明度就好了。CSS 中的 opactity 是有继承问题的。例如你的 Dom 结构如下：&lt;div class=”body”&gt;&lt;div class=”cnt”&gt;&lt;/div&gt;&lt;/div&gt;假如你为 body 增加了如上 1 的透明样式之后，.body 的确透明了。而这个时候，你会发现 .cnt 的块也变得 50% 透明了。假如你想通过重置样式来达到目的，不妨试试，你的100% 的不透明，将会基于父节点的 50%的，也就是 50％*100%=50% 。常见的解决方法，就是通过兄弟节点来解决继承的问题，并使用 position 属性来改变层次。具体不多说。解决方案:原理：使用 CSS3 的 rgb，rgba 来解决现代浏览器中的背景透明问题，使用 ie 中的渐变滤镜来解决 ie 中的透明问题。具体代码如下： .sl-alpha { background-color: rgb( 0, 0, 0 ); background-color: rgba( 0, 0, 0, 0.3 ); filter:progid:DXImageTransform.Microsoft.gradient(startColorstr=#88ff0000, endColorstr=#88ff00000); -ms-filter:"progid:DXImageTransform.Microsoft.gradient(startColorstr=#88ff0000, endColorstr=#88ff00000)"; }]]></content>
      <categories>
        <category>Css</category>
      </categories>
      <tags>
        <tag>css</tag>
        <tag>html</tag>
        <tag>opacity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub API v2 笔记]]></title>
    <url>%2F2013%2F11%2F13%2F2013-11-14-some-github-api%2F</url>
    <content type="text"><![CDATA[基本1.所有的 API 链接采用 http 协议而且开始于下面的格式: http://github.com/api/v2/:format 注：":format" 是指 "json","xml" 或者 "yaml" 中的一个。但现在基本是 json。 2.使用 GitHub 的 API 是有所限制的，使用 v2 版本，是每分钟 60 次请求。如果你在一分钟内访问了 60 次，它会提示您“拒绝访问”的错误。 ### 分支相关 1.一个分支提交的信息列表 commits/list/:user_id/:repository/:branch 2.一个文件提交的信息列表 commits/list/:user_id/:repository/:branch/*path 3.一个特殊的提交信息 commits/list/:user_id/:repository/:sha Repositories 相关1.搜索repos/search/:q2.Repo 信息repos/show/:user/:repo3.列出所有的 Reporepos/show/:user注：这个 API 每一页只列出 30 个结果]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[window下建立github 连接]]></title>
    <url>%2F2013%2F11%2F13%2F2013-11-14-start-github-on-window%2F</url>
    <content type="text"><![CDATA[在 window 下搭建 github 连接。前提这个前提还是比较简单的，你需要有一个 email，然后在 GitHub 上注册一个账户。工具在 window 建立 ssh 连接的工具挺多的。GitHub 也有自己的一个工具来帮助用户建立 Git连接–Git。哈哈，这儿下载Git,具体的安装方法参考这里输入命令，建立连接安装好 Git 之后，可别把它丢在一边不理了。这里有一些命令需要你手动输入。检查是否含有 SSH keys。（如果有的话，直接跳到第 4 步）不要太急哈，你刚刚才注册，怎么会有呢？$ cd ~/.ssh如果你在这里显示 “No such file or dirdectory” 请先跳到第 3 步，然后再跳回第 2 步，挺好玩的哈。备份和删除已经存在的 SSH keys$ ls //这里大概会显示出你的几个文件，如下： config id_rsa id_rsa.pub know_hosts $ mkdir key_backup //创建一个备份目录 $ cp id_rsa* key_backup //将 keys 保存到 key_backup, *号表示各种后缀 $ rm id_rsa* //删除啦 新建一个 SSH keys输入下面的代码哈。到了需要路径的时候，点击 enter 就好。$ ssh-keygen -t rsa -C &quot;your_email@yourmail.com&quot; //引号部分是你的刚刚申请的 github 帐号的邮箱噢,这个时候会输出如下内容： Generating public/private rsa key pair. Enter file in which to save the key //让你输入要保存 key 的路径 (/users/your_user_directory/.ssh/id_rsa): //你只需要 enter 就好 接着还要输入 ssh 密码Enter passphrase (empty for no passphrase): //输入密码 Enter same passphrase again: //再次输入密码 紧接着你会看到如下的输出：Your identification has been saved in /Users/your_user_directory/.ssh/id_rsa. Your public key has been saved in /User/your_user_directory/.ssh/id_rsa.pub. The key fingerpring is: 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db user_name@username.com +--[ RSA 2048]----+ | | | | | | | | | | +-----------------+ 注：是不是你没看到下面那个框框呢？只看到一串这样格式的字符01:0f:f4…?这没关系，待会你按照下面说的做就好了。把 SSH key 加到你的 GitHub嘿嘿，登录 GitHub，然后点击 “Account Setting” &gt; “SSH Public Keys” &gt; “Add another public key”然后打开 id_rsa.pub 文件（用 txt 打开就好，或者 vim ）。这就是你的公钥。注：id_rsa.pub 的路径是 C:\Documents and Settings\Administrator.ssh\ ，如果你刚刚按上面的做的话。测试啦现在可以尝试使用 SSH 连接到 GitHub 啦。输入下面命令：$ ssh -T git@github.com 接着会出现这样的代码：The authenticity of host &apos;github.com(207.97.227.239)&apos; can not be established. RSA key fingerprint is 10:10:10:.... //省略后面那一串 Are you sure you want to connitnue connecting(yes/no)? 别当心，输入 yes，成功的话，会显示这样：Hi username! ... 如果显示 fail 的话，请检查一下你刚刚在 GitHub 上的公钥，是否少了空格或者换行之类的。后续的工作现在你已经可以通过使用 Git 设置 SSH keys 来连接到你的 GitHub 上面了。接下来你可以设置你的个人信息，token 或者其他等。这里不列举了。万事开头难，加油。参考文章GitHub 上的帮助文档]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>github</tag>
      </tags>
  </entry>
</search>
